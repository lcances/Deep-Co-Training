{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to all tensorboard log file\n",
    "# logs_directory = \"../../tmp/tensorboard\"\n",
    "logs_directory = \"../tensorboard/standalone_tensorboard_10_supervised/\"\n",
    "\n",
    "all_log_dir = os.listdir(logs_directory)\n",
    "\n",
    "all_log_path = []\n",
    "for log_dir in all_log_dir:\n",
    "    log_dir_path = os.path.join(logs_directory, log_dir)\n",
    "    all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"train/acc\", \"val/acc\"]\n",
    "\n",
    "def get_log_data(path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "# for path in all_log_path:\n",
    "for path in all_log_path:\n",
    "    all_logs[path] = get_log_data(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the stats for all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "for path in all_log_path:\n",
    "    for tag in all_logs[path]:\n",
    "        try: \n",
    "            all_logs_stats[path][tag] = {\"max\": None, \"min\": None, \"mean\": None, \"std\": None}\n",
    "            all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "            all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "            all_logs_stats[path][tag][\"mean\"] = np.asarray(all_logs[path][tag]).mean()\n",
    "            all_logs_stats[path][tag][\"std\"] = np.asarray(all_logs[path][tag]).std()\n",
    "        except ValueError as e:\n",
    "            print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "            print(\"continue...\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(tag, key, search: str = None) -> list:\n",
    "    output = []\n",
    "    \n",
    "    for path in all_logs_stats.keys():\n",
    "        if search is not None:\n",
    "            if search in path:\n",
    "                output.append(all_logs_stats[path][tag][key])\n",
    "        else:\n",
    "            output.append((path, all_logs_stats[path][tag][key]))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  0.4946961611509323\n",
      "std:   0.04288830309045337\n",
      "min:   0.42551183700561523\n",
      "max:   0.5684915781021118\n",
      "\n",
      "max values --------\n",
      "0.5684915781021118\n",
      "0.500372052192688\n",
      "0.5055803656578064\n",
      "0.4393814206123352\n",
      "0.5496571063995361\n",
      "0.42551183700561523\n",
      "0.46339288353919983\n",
      "0.48882147669792175\n",
      "0.4830966293811798\n",
      "0.522656261920929\n"
     ]
    }
   ],
   "source": [
    "target = \"max\"\n",
    "response = get_of(\"val/acc\", target)\n",
    "\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[2], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# order by run\n",
    "# response = sorted(response, key=lambda x: x[0].split(\"/\")[4].split(\"_\")[2])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean())\n",
    "print(\"std:  \", values.std())\n",
    "print(\"min:  \", values.min())\n",
    "print(\"max:  \", values.max())\n",
    "print(\"\")\n",
    "print(\"%s values --------\" % target)\n",
    "for p, v in response:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
