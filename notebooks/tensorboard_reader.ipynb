{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to all tensorboard log file\n",
    "# logs_directory = \"../../tmp/tensorboard\"\n",
    "logs_directory = \"../tensorboard/osirim_scallableCnn/scallable2\"\n",
    "\n",
    "all_log_dir = os.listdir(logs_directory)\n",
    "\n",
    "all_log_path = []\n",
    "for log_dir in all_log_dir:\n",
    "    log_dir_path = os.path.join(logs_directory, log_dir)\n",
    "    all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"train/acc\", \"validation/acc\"]\n",
    "\n",
    "def get_log_data(path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "# for path in all_log_path:\n",
    "for path in all_log_path:\n",
    "    all_logs[path] = get_log_data(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the stats for all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "for path in all_log_path:\n",
    "    for tag in all_logs[path]:\n",
    "        try: \n",
    "            all_logs_stats[path][tag] = {\"max\": None, \"min\": None, \"mean\": None, \"std\": None}\n",
    "            all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "            all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "            all_logs_stats[path][tag][\"mean\"] = np.asarray(all_logs[path][tag]).mean()\n",
    "            all_logs_stats[path][tag][\"std\"] = np.asarray(all_logs[path][tag]).std()\n",
    "        except ValueError as e:\n",
    "            print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "            print(\"continue...\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(tag, key, search: str = None) -> list:\n",
    "    output = []\n",
    "    \n",
    "    for path in all_logs_stats.keys():\n",
    "        if search is not None:\n",
    "            if search in path:\n",
    "                output.append(all_logs_stats[path][tag][key])\n",
    "        else:\n",
    "            output.append((path, all_logs_stats[path][tag][key]))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  77.19404983520508\n",
      "std:   4.480183431459999\n",
      "min:   71.0\n",
      "max:   84.32221221923828\n",
      "\n",
      "max values --------\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_11:22:47_ScalableCnn1_run6_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578997367.co2-slurm-ng04.162690.0 84.32221221923828\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_12:51:15_ScalableCnn1_run10_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1579002675.co2-slurm-ng02.34637.0 79.4779281616211\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_10:37:59_ScalableCnn1_run3_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578994679.co2-slurm-ng02.186109.0 75.0\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_11:22:54_ScalableCnn1_run5_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578997374.co2-slurm-ng02.4668.0 75.6231918334961\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_12:07:20_ScalableCnn1_run8_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1579000040.co2-slurm-ng04.180640.0 71.0\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_09:53:14_ScalableCnn1_run1_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578991994.co2-slurm-ng04.130525.0 82.7988052368164\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_09:53:15_ScalableCnn1_run2_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578991995.co2-slurm-ng02.171205.0 81.6388931274414\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_12:51:13_ScalableCnn1_run9_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1579002673.co2-slurm-ng04.811.0 71.73736572265625\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_10:38:26_ScalableCnn1_run4_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1578994706.co2-slurm-ng04.145504.0 77.39765930175781\n",
      "../tensorboard/osirim_scallableCnn/scallable2/2020-01-14_12:07:17_ScalableCnn1_run7_Cosd-0.05lr_200e_1a_1b_1g_noaugment/events.out.tfevents.1579000037.co2-slurm-ng02.19912.0 72.94444274902344\n"
     ]
    }
   ],
   "source": [
    "target = \"max\"\n",
    "response = get_of(\"validation/acc\", target)\n",
    "\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[2], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# order by run\n",
    "# response = sorted(response, key=lambda x: x[0].split(\"/\")[4].split(\"_\")[2])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean())\n",
    "print(\"std:  \", values.std())\n",
    "print(\"min:  \", values.min())\n",
    "print(\"max:  \", values.max())\n",
    "print(\"\")\n",
    "print(\"%s values --------\" % target)\n",
    "for p, v in response:\n",
    "    print(p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
