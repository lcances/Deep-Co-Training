{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to all tensorboard log file\n",
    "# logs_directory = \"../../tmp/tensorboard\"\n",
    "logs_directory = \"../standalone/tensorboard/cross_validation/\"\n",
    "\n",
    "all_log_dir = os.listdir(logs_directory)\n",
    "\n",
    "all_log_path = []\n",
    "for log_dir in all_log_dir:\n",
    "    log_dir_path = os.path.join(logs_directory, log_dir)\n",
    "    all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"train/acc_1\", \"val/acc_1\"]\n",
    "\n",
    "def get_log_data(path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "# for path in all_log_path:\n",
    "for path in all_log_path:\n",
    "    all_logs[path] = get_log_data(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the stats for all the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for tag train/acc_1 in path ../standalone/tensorboard/cross_validation/2019-12-21_02:42:03_run9_0.01lr_0.1e_5lcm_0.25ldm_160.0wl/events.out.tfevents.1576892523.lcances.20741.0\n",
      "continue...\n",
      "Error for tag val/acc_1 in path ../standalone/tensorboard/cross_validation/2019-12-21_02:42:03_run9_0.01lr_0.1e_5lcm_0.25ldm_160.0wl/events.out.tfevents.1576892523.lcances.20741.0\n",
      "continue...\n"
     ]
    }
   ],
   "source": [
    "all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "for path in all_log_path:\n",
    "    for tag in all_logs[path]:\n",
    "        try: \n",
    "            all_logs_stats[path][tag] = {\"max\": None, \"min\": None}\n",
    "            all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "            all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "        except ValueError as e:\n",
    "            print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "            print(\"continue...\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(tag, key, search: str = None) -> list:\n",
    "    output = []\n",
    "    \n",
    "    for path in all_logs_stats.keys():\n",
    "        if search is not None:\n",
    "            if search in path:\n",
    "                output.append(all_logs_stats[path][tag][key])\n",
    "        else:\n",
    "            output.append((path, all_logs_stats[path][tag][key]))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  0.5571969217724271\n",
      "std:   0.04676416538156036\n",
      "min:   0.5131264925003052\n",
      "max:   0.6397058963775635\n",
      "\n",
      "max values --------\n",
      "run1 0.59617680311203\n",
      "run10 0.517754852771759\n",
      "run2 0.6397058963775635\n",
      "run3 0.6203473806381226\n",
      "run4 0.5131264925003052\n",
      "run5 0.5249088406562805\n",
      "run6 0.561965823173523\n",
      "run7 0.5272727012634277\n",
      "run8 0.5135135054588318\n",
      "run9 None\n"
     ]
    }
   ],
   "source": [
    "target = \"max\"\n",
    "response = get_of(\"val/acc_1\", target)\n",
    "\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[2], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# order by run\n",
    "response = sorted(response, key=lambda x: x[0].split(\"/\")[4].split(\"_\")[2])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean())\n",
    "print(\"std:  \", values.std())\n",
    "print(\"min:  \", values.min())\n",
    "print(\"max:  \", values.max())\n",
    "print(\"\")\n",
    "print(\"%s values --------\" % target)\n",
    "for p, v in response:\n",
    "    print(p.split(\"/\")[4].split(\"_\")[2], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
