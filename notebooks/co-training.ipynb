{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from advertorch.attacks import GradientSignAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "from ubs8k.datasetManager import DatasetManager\n",
    "from ubs8k.datasets import Dataset\n",
    "\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage, Ratio\n",
    "from DCT.util.checkpoint import CheckPoint\n",
    "from DCT.util.utils import reset_seed, get_datetime, ZipCycle\n",
    "from DCT.util.model_loader import get_model_from_name\n",
    "from DCT.util.dataset_loader import load_dataset\n",
    "\n",
    "from DCT.ramps import Warmup, sigmoid_rampup\n",
    "from DCT.losses import loss_cot, loss_diff, loss_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8dcnkz1kYQlbCDuKEUFChAAWrfZWoCpuKCCiIARUrNree2vbe9ve2l9ve2sXF5S9iLJ5FRW9XtdqBSGQsMkOYZOwBtnXEPL9/TFjb5oGGCHJmZm8n4/HPDJzzvfMfD4P5Z2TM+d8jznnEBGRyBXldQEiIlKzFPQiIhFOQS8iEuEU9CIiEU5BLyIS4aK9LqAqjRo1cq1bt/a6DBGRsLF06dL9zrn0qtaFZNC3bt2awsJCr8sQEQkbZrb9XOt06EZEJMIp6EVEIpyCXkQkwinoRUQinIJeRCTCBRX0ZtbXzDaYWZGZPVnF+o5mtsjMTpvZP3+TbUVEpGZdMOjNzAeMA/oBWcBgM8uqNOwA8H3g6YvYVkREalAw59F3B4qcc1sAzGw2MABY+/UA59w+YJ+Zfe+bbludnv14E+XOEeOLIjrKiPZFERsdRUp8NKkJMaQmxJCSEEN6chwp8TE1UYKISMgJJugzgB0VXhcDPYJ8/6C3NbM8IA+gZcuWQb793xv/182cKD0b1Nh6cdE0S42neVoCzdMSaJeeRLvG9ejQuB7NUxOIirKLqkFEJNQEE/RVJV6wdysJelvn3ERgIkBOTs5F3Q1l7S/7Ul7uKCt3lJWXc+as43TZWY6cLOPwyTMcOXmGQydLKTl6ml2HTrHr0El2Hz7FF8WHOHjizN/eJyHGx2VNk7m6RSqdW6TRJTONto2SFP4iEpaCCfpiILPC6xbAriDf/1K2vShRUUZslBH7t68fYmicfOHtDhwvpWjfMTbtO8qmvcdYt/sI/720mJcW+a8qTo6PJqdVfXq1a0TPdg25olkKPgW/iISBYIK+AOhgZm2AncAgYEiQ738p29aqBkmxdG/TgO5tGvxt2dlyx+aSY6zYcYgVOw6Rv+UrPtmwDoCU+Gh6tmvIjVc04YaOjWlUL86r0kVEzuuCQe+cKzOzscD7gA+Y6pxbY2ZjAuvHm1lToBBIAcrN7HEgyzl3pKpta6qZ6uaLMi5rksxlTZK5O8f/h8neI6dYtPkrFm3+is82lfD+mr2YwdWZaXzniib069SUtun1PK5cROT/WCjeHDwnJ8eFw+yVzjnW7DrCx+v28dG6vazaeRiAqzJSubVLc27u0oxmqQkeVykidYGZLXXO5VS5TkFffXYfPsn/fLGbeSt38UXxYcyge+sG3NmtBTd3bkZibEjOCi0iEUBB74EtJcd4e+Vu3lqxky37j5McF81tXTMY0qMlVzRL8bo8EYkwCnoPOeco2HaQWUu+5H9W7aa0rJyrM9O4L7cVt3RpTmy0phsSkUunoA8Rh06UMnfZTmYu+ZKifcdonBzH/b1ac2+PlqQlxnpdnoiEMQV9iHHO8dmm/Uyev4X5m/aTEONjYE4LHry2Da0aJnldnoiEIQV9CFu/5wiT52/lrRU7KXcw4OrmjP12e52iKSLfiII+DOw7coqJn23hlcXbKS0r59YuzRl7QwfaN1bgi8iFKejDSMnR00yav4WXF23nVNlZBnRpzg+/ezmZDRK9Lk1EQpiCPgztP+YP/JcWbuNsuWNobivGfrs9DTXVgohUQUEfxvYcPsUzH29kTsEOEmOjGXNdW0Zc20YXX4nI3zlf0Osk7hDXNDWe/7yjMx880Yde7Rry9Acb+fbTn/Lm8p2E4i9pEQk9Cvow0b5xMhOH5fDamJ40TYnn8TkrGDh+EasD8+uIiJyLgj7M5LRuwBsP9+a/7uzM1v3HueX5BfzkjVUcOF7qdWkiEqIU9GEoKsq4+5pM/vLP1zO8VxvmFOzg209/yozF2ykv1+EcEfl7CvowlpoQw89uyeJ/H/sWWc1S+Okbq7ln4iKK9h31ujQRCSEK+ghwWZNkZo7qwe/u6symfcfo98x8/vjhRk6XBXejdBGJbAr6CGFmDMzJ5KMfXEf/q5rxzMeb6P/MfJZsPeB1aSLiMQV9hGlUL45nBnVl2vBrOF1Wzt0TFvGLeWs4Waq9e5G6SkEfoa6/vDEfPNGHB3q1ZtrCbfR/dj5Ltx/0uiwR8YCCPoIlxkbzi1uvZObIHpSWlTNw/EJ++956HbsXqWMU9HVAr/aNeO/xbzGwWyYvfrqZAc9/zppdutBKpK5Q0NcRyfEx/Pauzkx9IIcDx0u5fdxCpizYqmkUROoABX0dc0PHJrz3eB/6XJbOU++sZfi0AvYfO+11WSJSgxT0dVCDpFgmDevGUwOuZOHmr+j7p/l8trHE67JEpIYo6OsoM+O+nq2ZN7Y3DZJiGDZ1Cb9+dx2lZeVelyYi1UxBX8d1bJrCvLHXMjS3JRM/28Jd4xey48AJr8sSkWqkoBfiY3z86rarGD+0G1v3H+fm5xbwl/V7vS5LRKqJgl7+pm+nprzz6LVkpCUwYlohT7+/gbOaDVMk7Cno5e+0apjE3Id7MeiaTJ7/pIj7piym5KjOyhEJZwp6+QfxMT5+c2dnfndXZ5ZuP8jNz82nYJsmRxMJVwp6OaeBOZm88XBvEmJ8DJ6Yz8v523WBlUgYCirozayvmW0wsyIze7KK9WZmzwbWf2Fm2RXWPWFma8xstZnNMrP46mxAalZW8xTmPXotfS5L59/fXM1P3liluXJEwswFg97MfMA4oB+QBQw2s6xKw/oBHQKPPODFwLYZwPeBHOdcJ8AHDKq26qVWpMTHMGlYDo98ux2zluxgyKTF7Dt6yuuyRCRIwezRdweKnHNbnHOlwGxgQKUxA4Dpzi8fSDOzZoF10UCCmUUDicCuaqpdapEvyviXmzoybkg2a3cd4dbnPmfljkNelyUiQQgm6DOAHRVeFweWXXCMc24n8DTwJbAbOOyc+6CqDzGzPDMrNLPCkhJdjh+qvte5Ga8/1ItonzFwwiJeX1rsdUkicgHBBL1VsazyN3JVjjGz+vj39tsAzYEkMxta1Yc45yY653Kccznp6elBlCVeyWruv5q2W8v6/PC/V/Lrd9fpfHuREBZM0BcDmRVet+AfD7+ca8x3gK3OuRLn3BlgLtDr4suVUNEgKZbpD3ZnWM9WTPxsC2NeWcqJ0jKvyxKRKgQT9AVABzNrY2ax+L9MnVdpzDxgWODsm1z8h2h24z9kk2tmiWZmwI3AumqsXzwU44vilwM68Ytbsvh43V7unrCIPYf1Ja1IqLlg0DvnyoCxwPv4Q/pV59waMxtjZmMCw94FtgBFwCTg4cC2i4HXgGXAqsDnTazuJsRbD/Ruw5T7r2FryXFuG/c5q3fq7lUiocRC8QKYnJwcV1hY6HUZ8g2t232EB6cVcOjkGZ4d1JXvZDXxuiSROsPMljrncqpapytjpdpc0SyFNx/pTfvG9Rj1cqFuVSgSIhT0Uq0ap8QzJ68nN2U15al31vKzt9bojBwRjynopdolxPp44d5sRvdpy8v523nolaWcOqNpE0S8oqCXGhEVZfy4/xX8/JYsPly3l3snL+bg8VKvyxKpkxT0UqOG927DuCHZrNp5mLvGL6T4oG5TKFLbFPRS4/pf1YyXR3Sn5Ohp7nhhIWt26fRLkdqkoJda0aNtQ157qBe+KOOeCfl8XrTf65JE6gwFvdSay5okM/fhXmSkJfDAn5fw5vKdXpckUico6KVWNUtN4NUxPenWqj6Pz1nBlAVbvS5JJOIp6KXWpSbE8NKI7vTr5D/X/vcfbNCFVSI1SEEvnoiL9vH8kGzuycnkub8U8bO31lCuC6tEakS01wVI3eWLMn5z51WkJcYw4bMtHD55ht/f3YUYn/Y/RKqTgl48Zea/sCotMZbfvreeo6fO8MK93UiI9XldmkjE0K6ThISHrm/Hr2+/ik83ljBs6mIOnzzjdUkiEUNBLyFjSI+WPDe4Kyt2HGLwxHxKjp72uiSRiKCgl5Byc+fmTL7/GrbuP85ATZkgUi0U9BJyrrssnVdGdufA8VLuHr+IbfuPe12SSFhT0EtI6taqAbPycjlVVs7dExaxae9Rr0sSCVsKeglZVzZPZXZeLg64Z2K+JkMTuUgKeglplzVJ5tXRPYmPjmLwxHxW7DjkdUkiYUdBLyGvTaMk5ozuSVpiLEMnL2bJ1gNelyQSVhT0EhYyGyTy6uieNE6JY9jUxSzYpGmORYKloJew0TTVf+Px1g2TGPFSAR+v2+t1SSJhQUEvYSU9OY5Zo3Lp2DSZ0S8v5d1Vu70uSSTkKegl7NRPiuWVkT3okpnG2JnLdAMTkQtQ0EtYSomPYfqI7vRo05AnXl3B60uLvS5JJGQp6CVsJcVFM/WBa+jZtiH//NpKXlPYi1RJQS9hLSHWx5T7r6F3u0b8y2srebVwh9cliYQcBb2EvYRYH5Pvz+Ha9o340etfMKfgS69LEgkpCnqJCPExPiYNy+FbHdL50eurmLlYYS/ytaCC3sz6mtkGMysysyerWG9m9mxg/Rdmll1hXZqZvWZm681snZn1rM4GRL4WH+Nj4n3duP7ydH7yxipmLN7udUkiIeGCQW9mPmAc0A/IAgabWValYf2ADoFHHvBihXXPAO855zoCXYB11VC3SJXiY3xMuK8bN3RszE/fWM3L+Qp7kWD26LsDRc65Lc65UmA2MKDSmAHAdOeXD6SZWTMzSwH6AFMAnHOlzjnNSiU1Ki7ax4tDs7mxY2P+/c3VTF+0zeuSRDwVTNBnABVPZSgOLAtmTFugBPizmS03s8lmllTVh5hZnpkVmllhSUlJ0A2IVCUu2scLQ7P5zhVN+Nlba/jz51u9LknEM8EEvVWxzAU5JhrIBl50znUFjgP/cIwfwDk30TmX45zLSU9PD6IskfOLi/bxwr3ZfDerCf/x9lqmLFDYS90UTNAXA5kVXrcAdgU5phgods4tDix/DX/wi9SK2Ogoxt2bTd8rm/LUO2uZPH+L1yWJ1Lpggr4A6GBmbcwsFhgEzKs0Zh4wLHD2TS5w2Dm32zm3B9hhZpcHxt0IrK2u4kWCEeOL4rkhXenXqSm/+p91TNWevdQx0Rca4JwrM7OxwPuAD5jqnFtjZmMC68cD7wL9gSLgBDC8wls8CswI/JLYUmmdSK2I8UXx7OCujJ25jF++s5ZonzGsZ2uvyxKpFeZc5cPt3svJyXGFhYVelyERqLSsnEdmLuPDtXv51W2dGJrbyuuSRKqFmS11zuVUtU5XxkqdEhsdxbgh/lMv/+3N1cxaoitoJfIp6KXOiY2O4oWh2Vx/eTo/nruKVws0EZpENgW91Elx0T7GD+1Gn8vS+dHcLzTFsUQ0Bb3UWV/PjfP1FMdvLFfYS2RS0Eud9vWslz3bNuSHr67krRW6LaFEHgW91Hlfz2ffvU0DnpizgrdXVr4eUCS8KehFgMTYaKbcfw05rRrw+JwVvLtqt9cliVQbBb1IQFJcNFOHX0PXzDS+P2s5763e43VJItVCQS9SQb24aP48/Bo6t0hl7MxlfLBGYS/hT0EvUklyfAzTRnTnyoxUHpm5jI/X7fW6JJFLoqAXqUJKfAzTR3TnimYpPPTKMj7ZsM/rkkQumoJe5BxSE2J4eUQPOjSpx+iXl/LXjbohjoQnBb3IeaQmxvDKgz1ol16PvOmFLNi03+uSRL4xBb3IBdRPimXGyB60aZTEgy8VsLBIYS/hRUEvEoQGgbBv3TCJES8VsGjzV16XJBI0Bb1IkBrWi2PGqB5k1k9kxLQCFm9R2Et4UNCLfAON6sUxc1QuzdPiGT6tgIJtB7wuSeSCFPQi31B6chyzRuXSNCWeB6YuYel2hb2ENgW9yEVonBLPrLxcGqfEc//UApZ9edDrkkTOSUEvcpGapMQza1QujerFcv+UJazYccjrkkSqpKAXuQRNU/179vWTYrlvymK+KFbYS+hR0ItcomapCczKyyUtMYahkxezeudhr0sS+TsKepFqkJGWwKxRuSTHx3Cvwl5CjIJepJq0qJ/I7Lxc6sVFM3TKYtbuOuJ1SSKAgl6kWmU2SGTWqFwSYnzcOzmf9XsU9uI9Bb1INWvZ0B/2cdE+hkxazIY9R70uSeo4Bb1IDWjdKIlZebnE+Iwhk/LZtFdhL95R0IvUkDaNkpg5KpeoKGPwpMUU7TvmdUlSRynoRWpQu/R6zBqVC8DgSflsLlHYS+1T0IvUsPaN6zFrVA+ccwyemM/W/ce9LknqGAW9SC3o0CSZGSNzKSv3h/02hb3UoqCC3sz6mtkGMysysyerWG9m9mxg/Rdmll1pvc/MlpvZO9VVuEi4ubxpMjNH9eB02VkGT8rny69OeF2S1BEXDHoz8wHjgH5AFjDYzLIqDesHdAg88oAXK61/DFh3ydWKhLmOTVOYMTKXk2f8Yb/jgMJeal4we/TdgSLn3BbnXCkwGxhQacwAYLrzywfSzKwZgJm1AL4HTK7GukXCVlbzFGaM7MGx02UMmqiwl5oXTNBnADsqvC4OLAt2zJ+AfwXKz/chZpZnZoVmVlhSUhJEWSLh68rmqcwY2YOjp85oz15qXDBBb1Usc8GMMbObgX3OuaUX+hDn3ETnXI5zLic9PT2IskTCW6eMVGaMzOXoqTLumbCI7V/pC1qpGcEEfTGQWeF1C2BXkGN6A7ea2Tb8h3xuMLNXLrpakQhzVQv/nv3JM2e5Z4JOvZSaEUzQFwAdzKyNmcUCg4B5lcbMA4YFzr7JBQ4753Y7537snGvhnGsd2O4vzrmh1dmASLjrlJHKzFG5lJ4t554Ji3QFrVS7Cwa9c64MGAu8j//MmVedc2vMbIyZjQkMexfYAhQBk4CHa6hekYh0RbMUZuflUu5g0MR8NmpuHKlG5lzlw+3ey8nJcYWFhV6XIVLrivYdY8ikfM6WO2aM6kHHpilelyRhwsyWOudyqlqnK2NFQkj7xvWYnZdLjC+KwRPzWbNLd6qSS6egFwkxbdPrMWe0/+YlQyYtZlWxwl4ujYJeJAS1apjEnNE9SY6PZsjkfFbsOOR1SRLGFPQiISqzgf8etPUTY7lv8mKWbj/odUkSphT0IiGsRf1E5ozOpWG9WIZNWUzBtgNelyRhSEEvEuKapSYwZ3RPmqTGM2zKEj4v2u91SRJmFPQiYaBJSjyz83Jp2SCR4dMK+GjtXq9LkjCioBcJE42T45kzOpcrmiYz5pWlzFtZeSYSkaop6EXCSFpiLK+M7EF2q/o8Nns5s5d86XVJEgYU9CJhJjk+hpeGd6dPh3SenLuKKQu2el2ShDgFvUgYSoj1MXFYN/p1aspT76zl2Y83EYrTmUhoUNCLhKm4aB/PDe7KHdkZ/OHDjfzmf9cr7KVK0V4XICIXL9oXxdN3dSEpNpoJn23h2OkynhrQiaioqu4FJHWVgl4kzEVFGb8ccCVJcdGM/+tmTpSe5b/u6kyMT3+wi5+CXiQCmBlP9utIcnw0v3t/A4dPnmHckGwSYn1elyYhQL/yRSLII99uz69u68QnG/YxdMpiDp8443VJEgIU9CIRZmhuK8YNyWZV8WEGTljInsOnvC5JPKagF4lA/a9qxrTh17Dr0CnufHEhm0t0H9q6TEEvEqF6tW/E7LxcTp05y8Dxi1ipOe3rLAW9SATrlJHKaw/1IjHWx+BJ+czfVOJ1SeIBBb1IhGvTKIm5D/WiZYNERkwr4G1NhlbnKOhF6oDGKfHMGd2Trpn1+f7s5Zofp45R0IvUEakJMUx/sDs3Zfnnx/nFvDWcLdeUCXWBgl6kDomP8THu3mwevLYN0xZu46FXlnKy9KzXZUkNU9CL1DG+KOPfb87i57dk8eG6vQyalM/+Y6e9LktqkIJepI4a3rsN44d2Y8OeI9zxgs61j2QKepE67KYrmzI7rycnSsu488WFFGw74HVJUgMU9CJ13NWZacx9qDcNkmK5d9JinX4ZgRT0IkLLhonMfagXV2em8eis5fzpo42U64yciKGgFxHAf+Pxl0d2587sFvzpo008Omu5zsiJEEEFvZn1NbMNZlZkZk9Wsd7M7NnA+i/MLDuwPNPMPjGzdWa2xsweq+4GRKT6xEX7eHpgZ37SvyPvrt7NwAkL2X34pNdlySW6YNCbmQ8YB/QDsoDBZpZVaVg/oEPgkQe8GFheBvzQOXcFkAs8UsW2IhJCzIy8Pu2Ycn8O2/af4NbnP2f5lwe9LksuQTB79N2BIufcFudcKTAbGFBpzABguvPLB9LMrJlzbrdzbhmAc+4osA7IqMb6RaSG3NCxCXMf7kV8TBT3TMznrRU7vS5JLlIwQZ8B7Kjwuph/DOsLjjGz1kBXYHFVH2JmeWZWaGaFJSWaYU8kFFzWJJm3HrmWqzPTeGz2Cn73/npNmxCGggn6qm4nX/m/9HnHmFk94HXgcefckao+xDk30TmX45zLSU9PD6IsEakNDZJieeXBHgzunsm4TzYzYloBh06Uel2WfAPBBH0xkFnhdQug8om25xxjZjH4Q36Gc27uxZcqIl6JjY7i17dfxf+7vRMLN+/nlucXsGbXYa/LkiAFE/QFQAcza2NmscAgYF6lMfOAYYGzb3KBw8653WZmwBRgnXPuD9VauYjUKjPj3h6tmDO6J2fKHHe8sJC5y4q9LkuCcMGgd86VAWOB9/F/mfqqc26NmY0xszGBYe8CW4AiYBLwcGB5b+A+4AYzWxF49K/uJkSk9mS3rM/bj/qP2//g1ZX8/K3VlJaVe12WnIc5F3pfrOTk5LjCwkKvyxCR8yg7W85v/nc9kxdspVur+rxwbzZNUuK9LqvOMrOlzrmcqtbpylgRuSjRvij+7eYsnhvclXW7j9D/mfn8daPOmAtFCnoRuSS3dGnOvLG9aVQvjvunLuG3763nzFkdygklCnoRuWTtGyfz5iO9Gdw9kxc/3cygifnsPKSpE0KFgl5EqkVCrI//vKMzzwy6mvWBQzkfrt3rdVmCgl5EqtmAqzN45/vfokX9BEZNL+QX89Zw6oxmwfSSgl5Eql2bRknMfbgXD/RqzbSF27jluQWs3qkLrLyioBeRGhEX7eMXt17J9BHdOXLqDLe/8DnjPinSXDkeUNCLSI3qc1k67z/eh+9mNeV372/gngmL+PKrE16XVaco6EWkxqUlxvL8kK788Z4ubNhzlH7PfMacgi8JxQs2I5GCXkRqhZlxe9cWvPdEH65qkcqPXl/FsKlL2HFAe/c1TUEvIrUqIy2BmSNzeeq2TizbfpCb/vQZf/58q25GXoMU9CJS66KijPtyW/HBD67jmtYN+I+31zJwwiKK9h3zurSIpKAXEc9kpCUwbfg1/OHuLmwuOUb/Z+bzxw836rz7aqagFxFPmRl3ZLfgwyeu46ZOTXnm401894+f8cn6fV6XFjEU9CISEtKT43hucFdmjOxBtM8YPq2AvOmFFB/Ul7WXSkEvIiGld/tGvPdYH/617+XM37Sf7/zhrzz/l006nHMJFPQiEnJio6N4+Pr2fPTD67jusnSe/mAjN/7+r7y5fKfOzrkICnoRCVkZaQlMuC+HmSN7kJYYw+NzVnD7C5+zZOsBr0sLKwp6EQl5vdo34u2x1/L7gV3Ye+Q0d09YxOiXC9lcotMxg6F7xopIWDlZepYpC7bw4qebOXnmLLd1zeD7N3SgdaMkr0vz1PnuGaugF5GwtP/YaSZ+toXpi7Zx5qzjzuwMHr2hA5kNEr0uzRMKehGJWPuOnuLFTzczY/GXlJc77sxuQd51bWmXXs/r0mqVgl5EIt6ew6d44dMi5hTsoPRsOf90RRNGX9eObq3qe11arVDQi0idsf/YaaYv3MZLi7Zz+OQZurduwMhvteHGK5rgizKvy6sxCnoRqXOOny5jTsEOpizYys5DJ8lIS2BIj5bcnZNJenKc1+VVOwW9iNRZZWfL+WjdPl7O38bnRV8R4zP6dWrGkB4t6d66AVERspd/vqCPru1iRERqU7Qvir6dmtK3U1OK9h1jxuLtvLa0mHkrd5GRlsAd2Rnc3jWDthH85a326EWkzjlRWsYHa/Yyd/lOFmwqodxBl8w0bru6OTdd2ZTmaQlel/iN6dCNiMg57DtyirdW7OL1ZcWs33MUgM4tUvluVhNuurIp7RvXwyz0D+8o6EVEgrC55BgfrNnLB2v3sPzLQwC0bpjItR0acW37RvRs24jUxBiPq6yagl5E5Bvae+QUH67dyyfr95G/5SuOl54lyuCqjFS6t2lA15b16doyjWapoXGY55KD3sz6As8APmCyc+43ldZbYH1/4ATwgHNuWTDbVkVBLyKh5MzZclbuOMSCov18XrSflcWHKS0rB6BpSjxXZ6bRsVkylzdJ5vKmybRqmFTr5+xfUtCbmQ/YCPwTUAwUAIOdc2srjOkPPIo/6HsAzzjnegSzbVUU9CISykrLylm3+wjLvjzI8i8P8UXxIbYfOMHXcRoXHUXrhkm0qJ8QeCTSPC2BhvViaZAUS/3EWNISY4jxVd8Ewpd6emV3oMg5tyXwZrOBAUDFsB4ATHf+3xr5ZpZmZs2A1kFsKyISVmKjo+iSmUaXzDSG9/YvO1l6lqJ9x1i/5wgb9x5l21cnKD54kiXbDnD0VFmV75MY6yM+xkdcdBRx0VE0To7n1TE9q73eYII+A9hR4XUx/r32C43JCHJbAMwsD8gDaNmyZRBliYiEjoRYH1e1SOWqFqn/sO7wyTPsOnSSA8dLOXiilIPHSzlw/AxHT53hdFk5p8vOcrqsnIQYX43UFkzQV3WgqfLxnnONCWZb/0LnJgITwX/oJoi6RETCQmpCDKkJ3p2tE0zQFwOZFV63AHYFOSY2iG1FRKQGBfNNQAHQwczamFksMAiYV2nMPGCY+eUCh51zu4PcVkREatAF9+idc2VmNhZ4H/8pklOdc2vMbExg/XjgXfxn3BThP71y+Pm2rZFORESkSrpgSkQkApzv9MrqO4lTRERCkoJeRCTCKehFRCKcgl5EJMKF5JexZlYCbL/IzRsB+6uxHC9FSi+R0geol1ClXqCVcy69qhUhGfSXwswKz/XNc7iJlF4ipQ9QL6FKvZyfDvLOmHcAAAO3SURBVN2IiEQ4Bb2ISISLxKCf6HUB1ShSeomUPkC9hCr1ch4Rd4xeRET+XiTu0YuISAUKehGRCBcxQW9mfc1sg5kVmdmTXtdzIWY21cz2mdnqCssamNmHZrYp8LN+hXU/DvS2wcxu8qbqqplZppl9YmbrzGyNmT0WWB5W/ZhZvJktMbOVgT7+I7A8rPqoyMx8ZrbczN4JvA7LXsxsm5mtMrMVZlYYWBauvaSZ2Wtmtj7wb6ZnjffinAv7B/4pkDcDbfHf7GQlkOV1XReouQ+QDayusOy/gCcDz58Efht4nhXoKQ5oE+jV53UPFepuBmQHnifjvyF8Vrj1g/+OaPUCz2OAxUBuuPVRqacfADOBd8L8/7FtQKNKy8K1l5eAkYHnsUBaTfcSKXv0f7uBuXOuFPj6JuQhyzn3GXCg0uIB+P8nIPDztgrLZzvnTjvntuKf9797rRQaBOfcbufcssDzo8A6/PcLDqt+nN+xwMuYwMMRZn18zcxaAN8DJldYHJa9nEPY9WJmKfh38qYAOOdKnXOHqOFeIiXoz3Vz8nDTxPnvzEXgZ+PA8rDpz8xaA13x7w2HXT+BQx0rgH3Ah865sOwj4E/AvwLlFZaFay8O+MDMlppZXmBZOPbSFigB/hw4pDbZzJKo4V4iJeiDvgl5mAqL/sysHvA68Lhz7sj5hlaxLCT6cc6ddc5djf/+xt3NrNN5hodsH2Z2M7DPObc02E2qWBYSvQT0ds5lA/2AR8ysz3nGhnIv0fgP2b7onOsKHMd/qOZcqqWXSAn6YG5gHg72mlkzgMDPfYHlId+fmcXgD/kZzrm5gcVh20/gz+lPgb6EZx+9gVvNbBv+Q5k3mNkrhGcvOOd2BX7uA97Af/giHHspBooDfykCvIY/+Gu0l0gJ+ki5Cfk84P7A8/uBtyosH2RmcWbWBugALPGgviqZmeE/5rjOOfeHCqvCqh8zSzeztMDzBOA7wHrCrA8A59yPnXMtnHOt8f97+Itzbihh2IuZJZlZ8tfPge8CqwnDXpxze4AdZnZ5YNGNwFpquhevv4Guxm+y++M/22Mz8FOv6wmi3lnAbuAM/t/aDwINgY+BTYGfDSqM/2mgtw1AP6/rr9TLtfj/nPwCWBF49A+3foDOwPJAH6uBnwWWh1UfVfR1Pf931k3Y9YL/uPbKwGPN1/++w7GXQG1XA4WB/8/eBOrXdC+aAkFEJMJFyqEbERE5BwW9iEiEU9CLiEQ4Bb2ISIRT0IuIRDgFvYhIhFPQi4hEuP8PrLnJxawtCBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(600)\n",
    "y = 0.05 * (1.0 + np.cos((x - 1) * (np.pi / 600)))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [0.05 * lr_lambda(e) for e in x]\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"cifar10\", type=str, help=\"available [ubs8k | cifar10]\")\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"--model\", default=\"Pmodel\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=0.08, type=float)\n",
    "# parser.add_argument(\"--supervised_mult\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=100, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=600, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.05, type=int)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "\n",
    "group_u = parser.add_argument_group(\"UrbanSound8k parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4, 5, 6, 7, 8, 9], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[10], type=int)\n",
    "\n",
    "group_h = parser.add_argument_group('hyperparameters')\n",
    "group_h.add_argument(\"--lambda_cot_max\", default=10, type=float)\n",
    "group_h.add_argument(\"--lambda_diff_max\", default=0.5, type=float)\n",
    "group_h.add_argument(\"--warmup_length\", default=80, type=int)\n",
    "group_h.add_argument(\"--epsilon\", default=0.02, type=float)\n",
    "\n",
    "group_a = parser.add_argument_group(\"Augmentation\")\n",
    "group_a.add_argument(\"--augment\", action=\"append\", help=\"augmentation. use as if python script\")\n",
    "group_a.add_argument(\"--augment_S\", action=\"store_true\", help=\"Apply augmentation on Supervised part\")\n",
    "group_a.add_argument(\"--augment_U\", action=\"store_true\", help=\"Apply augmentation on Unsupervised part\")\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"deep-co-training\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"deep-co-training\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "we pre-processed the images using ZCA and augmented the dataset using horizontal flips and random translations. The translations\n",
    "were drawn from [âˆ’2, 2] pixels,\n",
    "\"\"\"\n",
    "extra_train_transforms = [\n",
    "    transforms.Pad(4, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "]\n",
    "\n",
    "manager, train_loader, val_loader = load_dataset(\n",
    "    args.dataset,\n",
    "    \"dct\",\n",
    "    \n",
    "    extra_train_transform = extra_train_transforms,\n",
    "    \n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model_func = get_model_from_name(args.model)\n",
    "\n",
    "m1, m2 = model_func(manager=manager), model_func(manager=manager)\n",
    "\n",
    "m1 = m1.cuda()\n",
    "m2 = m2.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tensorboard/cifar10/deep-co-training/2020-08-28_11:41:02_Pmodel_0.1S\n"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "tensorboard_title = \"%s_%s_%.1fS\" % (get_datetime(), model_func.__name__, args.supervised_ratio)\n",
    "checkpoint_title = \"%s_%.1fS\" % (model_func.__name__, args.supervised_ratio)\n",
    "tensorboard = SummaryWriter(log_dir=\"%s/%s\" % (tensorboard_path, tensorboard_title), comment=model_func.__name__)\n",
    "print(os.path.join(tensorboard_path, tensorboard_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar10 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "if args.dataset == \"cifar10\":\n",
    "    params = list(m1.parameters()) + list(m2.parameters())\n",
    "    optimizer = torch.optim.SGD(params, lr=0.05, momentum=0.9, weight_decay=0.0001)\n",
    "    \n",
    "    lr_lambda = lambda epoch: (1.0 + np.cos((epoch-1)*np.pi/args.nb_epoch))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ubs8k optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "if args.dataset == \"ubs8k\":\n",
    "    params = list(m1.parameters()) + list(m2.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=args.learning_rate)\n",
    "    lr_lambda = lambda epoch: (1.0 + numpy.cos((epoch-1)*numpy.pi/args.nb_epoch)) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adversarial generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# adversarial generation\n",
    "adv_generator_1 = GradientSignAttack(\n",
    "    m1, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "    eps=args.epsilon, clip_min=0, clip_max=1, targeted=True\n",
    ")\n",
    "\n",
    "adv_generator_2 = GradientSignAttack(\n",
    "    m2, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "    eps=args.epsilon, clip_min=0, clip_max=1, targeted=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# Losses\n",
    "# see losses.py\n",
    "\n",
    "# define the warmups\n",
    "lambda_cot = Warmup(args.lambda_cot_max, args.warmup_length, sigmoid_rampup)\n",
    "lambda_diff = Warmup(args.lambda_diff_max, args.warmup_length, sigmoid_rampup)\n",
    "\n",
    "# callback\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "callbacks = [lr_scheduler, lambda_cot, lambda_diff]\n",
    "\n",
    "# checkpoints\n",
    "checkpoint_m1 = CheckPoint(m1, optimizer, mode=\"max\", name=\"%s/%s_m1.torch\" % (checkpoint_path, checkpoint_title))\n",
    "\n",
    "# metrics\n",
    "metrics_fn = dict(\n",
    "    ratio_s=[Ratio(), Ratio()],\n",
    "    ratio_u=[Ratio(), Ratio()],\n",
    "    acc_s=[CategoricalAccuracy(), CategoricalAccuracy()],\n",
    "    acc_u=[CategoricalAccuracy(), CategoricalAccuracy()],\n",
    "    f1_s=[FScore(), FScore()],\n",
    "    f1_u=[FScore(), FScore()],\n",
    "    \n",
    "    avg_total=ContinueAverage(),\n",
    "    avg_sup=ContinueAverage(),\n",
    "    avg_cot=ContinueAverage(),\n",
    "    avg_diff=ContinueAverage(),\n",
    ")\n",
    "\n",
    "def reset_metrics():\n",
    "    for item in metrics_fn.values():\n",
    "        if isinstance(item, list):\n",
    "            for f in item:\n",
    "                f.reset()\n",
    "        else:\n",
    "            item.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Can resume previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    checkpoint_m1.load_last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metrics and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def maximum():\n",
    "    def func(key, value):\n",
    "        if key not in func.max:\n",
    "            func.max[key] = value\n",
    "        else:\n",
    "            if func.max[key] < value:\n",
    "                func.max[key] = value\n",
    "        return func.max[key]\n",
    "\n",
    "    func.max = dict()\n",
    "    return func\n",
    "maximum_fn = maximum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Lsup   | Lcot   | Ldiff  | total  - metrics:  acc_s1    | acc_u1   - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} | {:<6.6} | {:<6.6} | {:<6.6} - {:<9.9} {:<9.9} | {:<9.9}- {:<6.6}\"\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} | {:<6.4f} | {:<6.4f} | {:<6.4f} - {:<9.9} {:<9.4f} | {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "header = header_form.format(\n",
    "    \"\", \"Epoch\", \"%\", \"Losses:\", \"Lsup\", \"Lcot\", \"Ldiff\", \"total\", \"metrics: \", \"acc_s1\", \"acc_u1\",\"Time\"\n",
    ")\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    reset_metrics()\n",
    "    m1.train()\n",
    "    m2.train()\n",
    "\n",
    "    for batch, (S1, S2, U) in enumerate(train_loader):\n",
    "        x_s1, y_s1 = S1\n",
    "        x_s2, y_s2 = S2\n",
    "        x_u, y_u = U\n",
    "\n",
    "        x_s1, x_s2, x_u = x_s1.cuda(), x_s2.cuda(), x_u.cuda()\n",
    "        y_s1, y_s2, y_u = y_s1.cuda(), y_s2.cuda(), y_u.cuda()\n",
    "\n",
    "        logits_s1 = m1(x_s1)\n",
    "        logits_s2 = m2(x_s2)\n",
    "        logits_u1 = m1(x_u)\n",
    "        logits_u2 = m2(x_u)\n",
    "\n",
    "        # pseudo labels of U\n",
    "        pred_u1 = torch.argmax(logits_u1, 1)\n",
    "        pred_u2 = torch.argmax(logits_u2, 1)\n",
    "\n",
    "        # ======== Generate adversarial examples ========\n",
    "        # fix batchnorm ----\n",
    "        m1.eval()\n",
    "        m2.eval()\n",
    "\n",
    "        #generate adversarial examples ----\n",
    "        adv_data_s1 = adv_generator_1.perturb(x_s1, y_s1)\n",
    "        adv_data_u1 = adv_generator_1.perturb(x_u, pred_u1)\n",
    "\n",
    "        adv_data_s2 = adv_generator_2.perturb(x_s2, y_s2)\n",
    "        adv_data_u2 = adv_generator_2.perturb(x_u, pred_u2)\n",
    "\n",
    "        m1.train()\n",
    "        m2.train()\n",
    "\n",
    "        # predict adversarial examples ----\n",
    "        adv_logits_s1 = m1(adv_data_s2)\n",
    "        adv_logits_s2 = m2(adv_data_s1)\n",
    "\n",
    "        adv_logits_u1 = m1(adv_data_u2)\n",
    "        adv_logits_u2 = m2(adv_data_u1)\n",
    "\n",
    "        # ======== calculate the differents loss ========\n",
    "        # zero the parameter gradients ----\n",
    "        optimizer.zero_grad()\n",
    "        m1.zero_grad()\n",
    "        m2.zero_grad()\n",
    "\n",
    "        # losses ----\n",
    "        l_sup = loss_sup(logits_s1, logits_s2, y_s1, y_s2)\n",
    "\n",
    "        l_cot = loss_cot(logits_u1, logits_u2)\n",
    "\n",
    "        l_diff = loss_diff(\n",
    "            logits_s1, logits_s2, adv_logits_s1, adv_logits_s2,\n",
    "            logits_u1, logits_u2, adv_logits_u1, adv_logits_u2\n",
    "        )\n",
    "\n",
    "        total_loss = l_sup + lambda_cot() * l_cot + lambda_diff() * l_diff\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ======== Calc the metrics ========\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # accuracies ----\n",
    "            pred_s1 = torch.argmax(logits_s1, dim=1)\n",
    "            pred_s2 = torch.argmax(logits_s2, dim=1)\n",
    "\n",
    "            acc_s1 = metrics_fn[\"acc_s\"][0](pred_s1, y_s1)\n",
    "            acc_s2 = metrics_fn[\"acc_s\"][1](pred_s2, y_s2)\n",
    "            acc_u1 = metrics_fn[\"acc_u\"][0](pred_u1, y_u)\n",
    "            acc_u2 = metrics_fn[\"acc_u\"][1](pred_u2, y_u)\n",
    "\n",
    "            # ratios  ----\n",
    "            adv_pred_s1 = torch.argmax(adv_logits_s1, 1)\n",
    "            adv_pred_s2 = torch.argmax(adv_logits_s2, 1)\n",
    "            adv_pred_u1 = torch.argmax(adv_logits_u1, 1)\n",
    "            adv_pred_u2 = torch.argmax(adv_logits_u2, 1)\n",
    "\n",
    "            ratio_s1 = metrics_fn[\"ratio_s\"][0](adv_pred_s1, y_s1)\n",
    "            ratio_s2 = metrics_fn[\"ratio_s\"][0](adv_pred_s2, y_s2)\n",
    "            ratio_u1 = metrics_fn[\"ratio_s\"][0](adv_pred_u1, y_u)\n",
    "            ratio_u2 = metrics_fn[\"ratio_s\"][0](adv_pred_u2, y_u)\n",
    "            # ========\n",
    "\n",
    "            avg_total = metrics_fn[\"avg_total\"](total_loss.item())\n",
    "            avg_sup = metrics_fn[\"avg_sup\"](l_sup.item())\n",
    "            avg_diff = metrics_fn[\"avg_diff\"](l_diff.item())\n",
    "            avg_cot = metrics_fn[\"avg_cot\"](l_cot.item())\n",
    "\n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (batch + 1) / len(train_loader)),\n",
    "                \"\", avg_sup.mean, avg_cot.mean, avg_diff.mean, avg_total.mean,\n",
    "                \"\", acc_s1.mean, acc_u1.mean,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "\n",
    "    # using tensorboard to monitor loss and acc\\n\",\n",
    "    tensorboard.add_scalar('train/total_loss', avg_total.mean, epoch)\n",
    "    tensorboard.add_scalar('train/Lsup', avg_sup.mean, epoch )\n",
    "    tensorboard.add_scalar('train/Lcot', avg_cot.mean, epoch )\n",
    "    tensorboard.add_scalar('train/Ldiff', avg_diff.mean, epoch )\n",
    "    tensorboard.add_scalar(\"train/acc_1\", acc_s1.mean, epoch )\n",
    "    tensorboard.add_scalar(\"train/acc_2\", acc_s2.mean, epoch )\n",
    "\n",
    "    tensorboard.add_scalar(\"detail_acc/acc_s1\", acc_s1.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_acc/acc_s2\", acc_s2.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_acc/acc_u1\", acc_u1.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_acc/acc_u2\", acc_u2.mean, epoch)\n",
    "\n",
    "    tensorboard.add_scalar(\"detail_ratio/ratio_s1\", ratio_s1.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_ratio/ratio_s2\", ratio_s2.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_ratio/ratio_u1\", ratio_u1.mean, epoch)\n",
    "    tensorboard.add_scalar(\"detail_ratio/ratio_u2\", ratio_u2.mean, epoch)\n",
    "\n",
    "    # Return the total loss to check for NaN\n",
    "    return total_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def test(epoch, msg = \"\"):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    reset_metrics()\n",
    "    m1.eval()\n",
    "    m2.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for batch, (X, y) in enumerate(val_loader):\n",
    "            x = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits_1 = m1(x)\n",
    "            logits_2 = m2(x)\n",
    "\n",
    "            # losses ----\n",
    "            l_sup = loss_sup(logits_1, logits_2, y, y)\n",
    "\n",
    "            # ======== Calc the metrics ========\n",
    "            # accuracies ----\n",
    "            pred_1 = torch.argmax(logits_1, dim=1)\n",
    "            pred_2 = torch.argmax(logits_2, dim=1)\n",
    "\n",
    "            acc_1 = metrics_fn[\"acc_s\"][0](pred_1, y)\n",
    "            acc_2 = metrics_fn[\"acc_s\"][1](pred_2, y)\n",
    "\n",
    "            avg_sup = metrics_fn[\"avg_sup\"](l_sup.item())\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (batch + 1) / len(train_loader)),\n",
    "                \"\", avg_sup.mean, 0.0, 0.0, avg_sup.mean,\n",
    "                \"\", acc_1.mean, 0.0,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"val/acc_1\", acc_1.mean, epoch)\n",
    "    tensorboard.add_scalar(\"val/acc_2\", acc_2.mean, epoch)\n",
    "        \n",
    "    tensorboard.add_scalar(\"max/acc_1\", maximum_fn(\"acc_1\", acc_1.mean), epoch )\n",
    "    tensorboard.add_scalar(\"max/acc_2\", maximum_fn(\"acc_2\", acc_2.mean), epoch )\n",
    "    \n",
    "    tensorboard.add_scalar(\"detail_hyperparameters/lambda_cot\", lambda_cot(), epoch)\n",
    "    tensorboard.add_scalar(\"detail_hyperparameters/lambda_diff\", lambda_diff(), epoch)\n",
    "    tensorboard.add_scalar(\"detail_hyperparameters/learning_rate\", get_lr(optimizer), epoch)\n",
    "\n",
    "    # Apply callbacks\n",
    "    for c in callbacks:\n",
    "        c.step()\n",
    "\n",
    "    # call checkpoint\n",
    "    checkpoint_m1.step(acc_1.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  Lsup   | Lcot   | Ldiff  | total  - metrics:  acc_s1    | acc_u1   - Time  \n",
      "\n",
      "Training 1      - 100    -          4.4859 | 0.0112 | 4.4796 | 6.8377 -           0.1555    | 0.1513   - 237.2291\n",
      "\u001b[1;4mValidati 1      - 20     -          4.3388 | 0.0000 | 0.0000 | 4.3388 -           0.1466    | 0.0000   - 6.4963\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 2      - 100    -          4.3484 | 0.0346 | 4.5440 | 4.3684 -           0.1600    | 0.1728   - 238.6292\n",
      "\u001b[1;4mValidati 2      - 20     -          4.1571 | 0.0000 | 0.0000 | 4.1571 -           0.1867    | 0.0000   - 6.5481\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 3      - 100    -          4.2099 | 0.0424 | 4.4894 | 4.2329 -           0.1833    | 0.1928   - 238.4541\n",
      "\u001b[1;4mValidati 3      - 20     -          3.9201 | 0.0000 | 0.0000 | 3.9201 -           0.2265    | 0.0000   - 6.5269\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 4      - 100    -          4.1224 | 0.0399 | 4.3997 | 4.1477 -           0.2040    | 0.2099   - 238.0742\n",
      "\u001b[1;4mValidati 4      - 20     -          3.9056 | 0.0000 | 0.0000 | 3.9056 -           0.2349    | 0.0000   - 6.5259\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 5      - 100    -          4.0835 | 0.0397 | 4.3467 | 4.1117 -           0.2113    | 0.2303   - 238.5949\n",
      "\u001b[1;4mValidati 5      - 20     -          3.7664 | 0.0000 | 0.0000 | 3.7664 -           0.2673    | 0.0000   - 6.5183\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 6      - 100    -          4.0281 | 0.0410 | 4.3001 | 4.0597 -           0.2335    | 0.2453   - 238.3610\n",
      "\u001b[1;4mValidati 6      - 20     -          3.8271 | 0.0000 | 0.0000 | 3.8271 -           0.2703    | 0.0000   - 6.5433\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 7      - 100    -          3.9696 | 0.0395 | 4.2343 | 4.0044 -           0.2378    | 0.2615   - 238.4473\n",
      "\u001b[1;4mValidati 7      - 20     -          3.7470 | 0.0000 | 0.0000 | 3.7470 -           0.2852    | 0.0000   - 6.5088\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 8      - 100    -          3.9269 | 0.0417 | 4.2020 | 3.9660 -           0.2458    | 0.2779   - 238.3979\n",
      "\u001b[1;4mValidati 8      - 20     -          3.6952 | 0.0000 | 0.0000 | 3.6952 -           0.2968    | 0.0000   - 6.5010\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 9      - 100    -          3.8986 | 0.0452 | 4.2121 | 3.9431 -           0.2618    | 0.2863   - 237.9522\n",
      "\u001b[1;4mValidati 9      - 20     -          3.7387 | 0.0000 | 0.0000 | 3.7387 -           0.3281    | 0.0000   - 6.4960\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 10     - 100    -          3.8613 | 0.0456 | 4.1762 | 3.9109 -           0.2625    | 0.2923   - 237.9242\n",
      "\u001b[1;4mValidati 10     - 20     -          3.5470 | 0.0000 | 0.0000 | 3.5470 -           0.3137    | 0.0000   - 6.5025\u001b[0m\n",
      "Training 11     - 100    -          3.8264 | 0.0460 | 4.1407 | 3.8814 -           0.2753    | 0.3031   - 237.8904\n",
      "\u001b[1;4mValidati 11     - 20     -          3.5838 | 0.0000 | 0.0000 | 3.5838 -           0.3140    | 0.0000   - 6.5535\u001b[0m\n",
      "Training 12     - 100    -          3.7829 | 0.0501 | 4.1324 | 3.8451 -           0.2863    | 0.3057   - 237.7679\n",
      "\u001b[1;4mValidati 12     - 20     -          3.5583 | 0.0000 | 0.0000 | 3.5583 -           0.3324    | 0.0000   - 6.5024\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 13     - 100    -          3.7611 | 0.0484 | 4.1030 | 3.8295 -           0.3038    | 0.3124   - 237.6968\n",
      "\u001b[1;4mValidati 13     - 20     -          3.5091 | 0.0000 | 0.0000 | 3.5091 -           0.3104    | 0.0000   - 6.4837\u001b[0m\n",
      "Training 14     - 100    -          3.7611 | 0.0456 | 4.0850 | 3.8360 -           0.2858    | 0.3194   - 237.7419\n",
      "\u001b[1;4mValidati 14     - 20     -          3.4516 | 0.0000 | 0.0000 | 3.4516 -           0.3360    | 0.0000   - 6.4924\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 15     - 100    -          3.7123 | 0.0479 | 4.0516 | 3.7956 -           0.3045    | 0.3247   - 237.9640\n",
      "\u001b[1;4mValidati 15     - 20     -          3.5056 | 0.0000 | 0.0000 | 3.5056 -           0.3519    | 0.0000   - 6.5638\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 16     - 100    -          3.6716 | 0.0499 | 4.0352 | 3.7644 -           0.3188    | 0.3311   - 238.0033\n",
      "\u001b[1;4mValidati 16     - 20     -          3.4469 | 0.0000 | 0.0000 | 3.4469 -           0.3673    | 0.0000   - 6.4906\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 17     - 100    -          3.6525 | 0.0521 | 4.0356 | 3.7560 -           0.3123    | 0.3303   - 237.6631\n",
      "\u001b[1;4mValidati 17     - 20     -          3.3991 | 0.0000 | 0.0000 | 3.3991 -           0.3647    | 0.0000   - 6.4998\u001b[0m\n",
      "Training 18     - 100    -          3.6320 | 0.0506 | 4.0082 | 3.7450 -           0.3240    | 0.3418   - 238.1533\n",
      "\u001b[1;4mValidati 18     - 20     -          3.3984 | 0.0000 | 0.0000 | 3.3984 -           0.3831    | 0.0000   - 6.5058\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 19     - 100    -          3.6106 | 0.0478 | 3.9527 | 3.7324 -           0.3265    | 0.3564   - 238.2861\n",
      "\u001b[1;4mValidati 19     - 20     -          3.3475 | 0.0000 | 0.0000 | 3.3475 -           0.3571    | 0.0000   - 6.4926\u001b[0m\n",
      "Training 20     - 100    -          3.5860 | 0.0489 | 3.9416 | 3.7204 -           0.3380    | 0.3535   - 238.0888\n",
      "\u001b[1;4mValidati 20     - 20     -          3.4474 | 0.0000 | 0.0000 | 3.4474 -           0.3409    | 0.0000   - 6.5133\u001b[0m\n",
      "Training 21     - 100    -          3.5410 | 0.0544 | 3.9520 | 3.6924 -           0.3555    | 0.3554   - 238.2644\n",
      "\u001b[1;4mValidati 21     - 20     -          3.5470 | 0.0000 | 0.0000 | 3.5470 -           0.3424    | 0.0000   - 6.5308\u001b[0m\n",
      "Training 22     - 100    -          3.5274 | 0.0545 | 3.9264 | 3.6927 -           0.3680    | 0.3686   - 238.0771\n",
      "\u001b[1;4mValidati 22     - 20     -          3.3302 | 0.0000 | 0.0000 | 3.3302 -           0.4039    | 0.0000   - 6.5161\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 23     - 100    -          3.4990 | 0.0536 | 3.8992 | 3.6785 -           0.3638    | 0.3788   - 237.9351\n",
      "\u001b[1;4mValidati 23     - 20     -          3.2963 | 0.0000 | 0.0000 | 3.2963 -           0.4047    | 0.0000   - 6.4711\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 24     - 100    -          3.4677 | 0.0565 | 3.9065 | 3.6666 -           0.3593    | 0.3801   - 237.8531\n",
      "\u001b[1;4mValidati 24     - 20     -          3.2480 | 0.0000 | 0.0000 | 3.2480 -           0.4003    | 0.0000   - 6.5031\u001b[0m\n",
      "Training 25     - 100    -          3.4247 | 0.0569 | 3.8597 | 3.6403 -           0.3698    | 0.3903   - 238.0923\n",
      "\u001b[1;4mValidati 25     - 20     -          3.2328 | 0.0000 | 0.0000 | 3.2328 -           0.3871    | 0.0000   - 6.5462\u001b[0m\n",
      "Training 26     - 100    -          3.4091 | 0.0544 | 3.8370 | 3.6408 -           0.3753    | 0.3978   - 238.2179\n",
      "\u001b[1;4mValidati 26     - 20     -          3.2955 | 0.0000 | 0.0000 | 3.2955 -           0.3876    | 0.0000   - 6.5310\u001b[0m\n",
      "Training 27     - 100    -          3.3823 | 0.0539 | 3.7917 | 3.6317 -           0.3873    | 0.4056   - 238.2467\n",
      "\u001b[1;4mValidati 27     - 20     -          3.1983 | 0.0000 | 0.0000 | 3.1983 -           0.4034    | 0.0000   - 6.5278\u001b[0m\n",
      "Training 28     - 100    -          3.3309 | 0.0545 | 3.7544 | 3.6007 -           0.3898    | 0.4126   - 237.7417\n",
      "\u001b[1;4mValidati 28     - 20     -          3.1215 | 0.0000 | 0.0000 | 3.1215 -           0.4301    | 0.0000   - 6.4964\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 29     - 53     -          3.2944 | 0.0568 | 3.7387 | 3.5891 -           0.4153    | 0.4172   - 126.4982\r"
     ]
    }
   ],
   "source": [
    "print(header)\n",
    "\n",
    "for epoch in range(0, args.nb_epoch):\n",
    "    total_loss = train(epoch)\n",
    "    \n",
    "    if np.isnan(total_loss):\n",
    "        print(\"Losses are NaN, stoping the training here\")\n",
    "        break\n",
    "        \n",
    "    test(epoch)\n",
    "\n",
    "    tensorboard.flush()\n",
    "    \n",
    "tensorboard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dct",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
