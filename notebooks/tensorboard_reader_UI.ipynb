{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils and UI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global request_results\n",
    "\n",
    "all_logs = {}\n",
    "all_logs_stats = {}\n",
    "request_results = []\n",
    "\n",
    "# tag_list = [\"train/acc_1\", \"train_acc2\", \"val/acc_1\", \"val/acc_2\"]\n",
    "tag_list = [\"train/acc\", \"validation/acc\"]\n",
    "target_list = [\"max\", \"min\", \"mean\", \"std\", \"last\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_data(tags, path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(all_logs_stats, tag = tag_list):\n",
    "    global request_results\n",
    "    \n",
    "    def get_of_ui(key = target_list, search = \"\"):\n",
    "        global request_results\n",
    "        request_results = []\n",
    "\n",
    "        for path in all_logs_stats.keys():\n",
    "            if search != \"\":\n",
    "                if search in path:\n",
    "                    request_results.append(all_logs_stats[path][tag][key])\n",
    "            else:\n",
    "                request_results.append((path, all_logs_stats[path][tag][key]))\n",
    "        print(\"done\")\n",
    "            \n",
    "    interact_manual(get_of_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logs(directory, tag):\n",
    "\n",
    "    all_logs = {}\n",
    "    all_logs_stats = {}\n",
    "    request_results = []\n",
    "\n",
    "    # ---- get the path for all logs file ----\n",
    "    all_log_dir = os.listdir(directory)\n",
    "\n",
    "    all_log_path = []\n",
    "    for log_dir in all_log_dir:\n",
    "        log_dir_path = os.path.join(directory, log_dir)\n",
    "        all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))\n",
    "\n",
    "    # ---- recover all the logs ----\n",
    "    all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "    # for path in all_log_path:\n",
    "    for path in all_log_path:\n",
    "        all_logs[path] = get_log_data([tag], path)\n",
    "\n",
    "\n",
    "    # ---- compute the statistics ----\n",
    "    all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "    for path in all_log_path:\n",
    "        for tag in all_logs[path]:\n",
    "            try: \n",
    "                all_logs_stats[path][tag] = {\"max\": None, \"min\": None, \"mean\": None, \"std\": None, \"last\": None}\n",
    "                all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "                all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "                all_logs_stats[path][tag][\"mean\"] = np.asarray(all_logs[path][tag]).mean()\n",
    "                all_logs_stats[path][tag][\"std\"] = np.asarray(all_logs[path][tag]).std()\n",
    "                all_logs_stats[path][tag][\"last\"] = np.asarray(all_logs[path][tag])[-1]\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "                print(\"continue...\")\n",
    "                pass\n",
    "\n",
    "    return all_logs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbe507e495940c2b0d1f69be3abc7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=('../tensorboard/notebook_tensorboard', '../teâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.first_level_directory(directory)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_root = \"../tensorboard/\"\n",
    "\n",
    "def first_level_logs():\n",
    "    list_dir = glob.glob(\"../tensorboard/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    return list_dir\n",
    "\n",
    "def log_fetcher():\n",
    "    first_level_directory = None\n",
    "    second_level_directory = None\n",
    "    selected_tag = None\n",
    "    \n",
    "def first_level_directory(directory):\n",
    "    list_dir = glob.glob(directory + \"/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    interact(second_level_directory, directory=list_dir, tag=\"\")\n",
    "    \n",
    "def second_level_directory(directory, tag):\n",
    "    all_log_stat = fetch_logs(directory, tag)\n",
    "    get_of(all_log_stat, tag)\n",
    "#     print(request_results)\n",
    "    \n",
    "interact(first_level_directory, directory=first_level_logs())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  0.7395459860563278 2\n",
      "std:   0.0014632460147671576 2\n",
      "min:   0.7371565103530884 2\n",
      "max:   0.7407407164573669 2\n",
      "\n",
      "%s values --------\n",
      "../tensorboard/osirim_tensorboard_0.5r_scallable2_grid_search/combination/2020-01-16_22:39:27_scallable_50p_0.1lr_0.02e_2lcm_0.1ldm_120.0wl/events.out.tfevents.1579210767.co2-slurm-ng05.32508.0 0.7371565103530884\n",
      "../tensorboard/osirim_tensorboard_0.5r_scallable2_grid_search/combination/2020-01-16_22:39:25_scallable_50p_0.03lr_0.02e_2lcm_0.1ldm_120.0wl/events.out.tfevents.1579210765.co2-slurm-ng04.162130.0 0.739546000957489\n",
      "../tensorboard/osirim_tensorboard_0.5r_scallable2_grid_search/combination/2020-01-16_22:39:29_scallable_50p_0.01lr_0.02e_2lcm_0.1ldm_120.0wl/events.out.tfevents.1579210769.co2-slurm-ng02.127563.0 0.7407407164573669\n",
      "../tensorboard/osirim_tensorboard_0.5r_scallable2_grid_search/combination/2020-01-16_22:39:27_scallable_50p_0.01lr_0.02e_2lcm_0.5ldm_120.0wl/events.out.tfevents.1579210767.co2-slurm-ng06.20456.0 0.7407407164573669\n"
     ]
    }
   ],
   "source": [
    "response = request_results\n",
    "\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[4][:4], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# order by run\n",
    "response = sorted(response, key=lambda x: x[1])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean(), 2)\n",
    "print(\"std:  \", values.std(), 2)\n",
    "print(\"min:  \", values.min(), 2)\n",
    "print(\"max:  \", values.max(), 2)\n",
    "print(\"\")\n",
    "print(\"%s values --------\")\n",
    "for p, v in response:\n",
    "    print(p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
