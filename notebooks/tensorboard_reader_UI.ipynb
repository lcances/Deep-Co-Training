{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils and UI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global request_results\n",
    "\n",
    "all_logs = {}\n",
    "all_logs_stats = {}\n",
    "request_results = []\n",
    "\n",
    "# tag_list = [\"train/acc_1\", \"train_acc2\", \"val/acc_1\", \"val/acc_2\"]\n",
    "tag_list = [\"train/acc\", \"validation/acc\"]\n",
    "target_list = [\"max\", \"min\", \"mean\", \"std\", \"last\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_data(tags, path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(all_logs_stats, tag = tag_list):\n",
    "    global request_results\n",
    "    \n",
    "    def get_of_ui(key = target_list, search = \"\"):\n",
    "        global request_results\n",
    "        request_results = []\n",
    "\n",
    "        for path in all_logs_stats.keys():\n",
    "            if search != \"\":\n",
    "                if search in path:\n",
    "                    request_results.append(all_logs_stats[path][tag][key])\n",
    "            else:\n",
    "                request_results.append((path, all_logs_stats[path][tag][key]))\n",
    "        print(\"done\")\n",
    "            \n",
    "    interact_manual(get_of_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logs(directory, tag):\n",
    "\n",
    "    all_logs = {}\n",
    "    all_logs_stats = {}\n",
    "    request_results = []\n",
    "\n",
    "    # ---- get the path for all logs file ----\n",
    "    all_log_dir = os.listdir(directory)\n",
    "\n",
    "    all_log_path = []\n",
    "    for log_dir in all_log_dir:\n",
    "        log_dir_path = os.path.join(directory, log_dir)\n",
    "        \n",
    "        if os.path.isdir(log_dir_path):\n",
    "            all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))\n",
    "\n",
    "    # ---- recover all the logs ----\n",
    "    all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "    # for path in all_log_path:\n",
    "    for path in all_log_path:\n",
    "        all_logs[path] = get_log_data([tag], path)\n",
    "\n",
    "\n",
    "    # ---- compute the statistics ----\n",
    "    all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "    for path in all_log_path:\n",
    "        for tag in all_logs[path]:\n",
    "            try: \n",
    "                all_logs_stats[path][tag] = {\"max\": None, \"min\": None, \"mean\": None, \"std\": None, \"last\": None}\n",
    "                all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "                all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "                all_logs_stats[path][tag][\"mean\"] = np.asarray(all_logs[path][tag]).mean()\n",
    "                all_logs_stats[path][tag][\"std\"] = np.asarray(all_logs[path][tag]).std()\n",
    "                all_logs_stats[path][tag][\"last\"] = np.asarray(all_logs[path][tag])[-1]\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "                print(\"continue...\")\n",
    "                pass\n",
    "\n",
    "    return all_logs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e1c448a24b49c0af030b11dbe113a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=('../tensorboard/notebook_tensorboard', '../teâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.first_level_directory(directory)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_root = \"../tensorboard/\"\n",
    "\n",
    "def first_level_logs():\n",
    "    list_dir = glob.glob(\"../tensorboard/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    return list_dir\n",
    "\n",
    "def log_fetcher():\n",
    "    first_level_directory = None\n",
    "    second_level_directory = None\n",
    "    selected_tag = None\n",
    "    \n",
    "def first_level_directory(directory):\n",
    "    list_dir = glob.glob(directory + \"/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    interact(second_level_directory, directory=list_dir, tag=\"\")\n",
    "    \n",
    "def second_level_directory(directory, tag):\n",
    "    all_log_stat = fetch_logs(directory, tag)\n",
    "    get_of(all_log_stat, tag)\n",
    "#     print(request_results)\n",
    "    \n",
    "interact(first_level_directory, directory=first_level_logs())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  76.56342544555665 2\n",
      "std:   4.678080326067919 2\n",
      "min:   69.37141418457031 2\n",
      "max:   85.87500762939453 2\n",
      "\n",
      "%s values --------\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run2_2020-02-26_17:22:14_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582734134.lcances.8994.0 69.37141418457031\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run3_2020-02-26_17:55:28_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582736128.lcances.32115.0 71.40625\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run1_2020-02-26_16:48:34_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582732114.lcances.26193.0 73.82015228271484\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run7_2020-02-26_20:10:17_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582744217.lcances.2186.0 74.69636535644531\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run0_2020-02-26_16:13:07_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582729987.lcances.732.0 75.23954772949219\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run5_2020-02-26_19:02:39_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582740159.lcances.36997.0 75.98558044433594\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run6_2020-02-26_19:36:53_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582742213.lcances.20479.0 77.23214721679688\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run9_2020-02-26_21:19:23_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582748363.lcances.8839.0 80.35714721679688\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run8_2020-02-26_20:45:35_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582746335.lcances.25961.0 81.65064239501953\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation_crossval_ss1.0/run4_2020-02-26_18:28:54_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e/events.out.tfevents.1582738134.lcances.14905.0 85.87500762939453\n"
     ]
    }
   ],
   "source": [
    "response = request_results\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[4][:4], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# remove none\n",
    "response = [(r[0], r[1]) for r in response if r[1] is not None]\n",
    "# order by run\n",
    "response = sorted(response, key=lambda x: x[1])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean(), 2)\n",
    "print(\"std:  \", values.std(), 2)\n",
    "print(\"min:  \", values.min(), 2)\n",
    "print(\"max:  \", values.max(), 2)\n",
    "print(\"\")\n",
    "print(\"%s values --------\")\n",
    "for p, v in response:\n",
    "    print(p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
