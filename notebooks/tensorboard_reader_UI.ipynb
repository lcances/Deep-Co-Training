{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils and UI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global request_results\n",
    "\n",
    "all_logs = {}\n",
    "all_logs_stats = {}\n",
    "request_results = []\n",
    "\n",
    "# tag_list = [\"train/acc_1\", \"train_acc2\", \"val/acc_1\", \"val/acc_2\"]\n",
    "tag_list = [\"train/acc\", \"validation/acc\"]\n",
    "target_list = [\"max\", \"min\", \"mean\", \"std\", \"last\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_data(tags, path):\n",
    "    logs = dict(zip(tags, [[] for _ in range(len(tags))]))\n",
    "\n",
    "    for e in tf.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag in tags:\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in the stat\n",
    "def get_of(all_logs_stats, tag = tag_list):\n",
    "    global request_results\n",
    "    \n",
    "    def get_of_ui(key = target_list, search = \"\"):\n",
    "        global request_results\n",
    "        request_results = []\n",
    "\n",
    "        for path in all_logs_stats.keys():\n",
    "            if search != \"\":\n",
    "                if search in path:\n",
    "                    request_results.append(all_logs_stats[path][tag][key])\n",
    "            else:\n",
    "                request_results.append((path, all_logs_stats[path][tag][key]))\n",
    "        print(\"done\")\n",
    "            \n",
    "    interact_manual(get_of_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logs(directory, tag):\n",
    "\n",
    "    all_logs = {}\n",
    "    all_logs_stats = {}\n",
    "    request_results = []\n",
    "\n",
    "    # ---- get the path for all logs file ----\n",
    "    all_log_dir = os.listdir(directory)\n",
    "\n",
    "    all_log_path = []\n",
    "    for log_dir in all_log_dir:\n",
    "        log_dir_path = os.path.join(directory, log_dir)\n",
    "        \n",
    "        if os.path.isdir(log_dir_path):\n",
    "            all_log_path.append(os.path.join(log_dir_path, os.listdir(log_dir_path)[0]))\n",
    "\n",
    "    # ---- recover all the logs ----\n",
    "    all_logs = dict(zip(all_log_path, [None for _ in range(len(all_log_path))]))\n",
    "\n",
    "    # for path in all_log_path:\n",
    "    for path in all_log_path:\n",
    "        all_logs[path] = get_log_data([tag], path)\n",
    "\n",
    "\n",
    "    # ---- compute the statistics ----\n",
    "    all_logs_stats = dict(zip(all_log_path, [{} for _ in range(len(all_log_path))]))\n",
    "\n",
    "    for path in all_log_path:\n",
    "        for tag in all_logs[path]:\n",
    "            try: \n",
    "                all_logs_stats[path][tag] = {\"max\": None, \"min\": None, \"mean\": None, \"std\": None, \"last\": None}\n",
    "                all_logs_stats[path][tag][\"max\"] = np.asarray(all_logs[path][tag]).max()\n",
    "                all_logs_stats[path][tag][\"min\"] = np.asarray(all_logs[path][tag]).min()\n",
    "                all_logs_stats[path][tag][\"mean\"] = np.asarray(all_logs[path][tag]).mean()\n",
    "                all_logs_stats[path][tag][\"std\"] = np.asarray(all_logs[path][tag]).std()\n",
    "                all_logs_stats[path][tag][\"last\"] = np.asarray(all_logs[path][tag])[-1]\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(\"Error for tag %s in path %s\" % (tag, path))\n",
    "                print(\"continue...\")\n",
    "                pass\n",
    "\n",
    "    return all_logs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c87a98d8ea4280928e88ceecc695c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=('../tensorboard/notebook_tensorboard', '../teâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.first_level_directory(directory)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_root = \"../tensorboard/\"\n",
    "\n",
    "def first_level_logs():\n",
    "    list_dir = glob.glob(\"../tensorboard/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    return list_dir\n",
    "\n",
    "def log_fetcher():\n",
    "    first_level_directory = None\n",
    "    second_level_directory = None\n",
    "    selected_tag = None\n",
    "    \n",
    "def first_level_directory(directory):\n",
    "    list_dir = glob.glob(directory + \"/*\")\n",
    "    list_dir = sorted(list_dir)\n",
    "    interact(second_level_directory, directory=list_dir, tag=\"\")\n",
    "    \n",
    "def second_level_directory(directory, tag):\n",
    "    all_log_stat = fetch_logs(directory, tag)\n",
    "    get_of(all_log_stat, tag)\n",
    "#     print(request_results)\n",
    "    \n",
    "interact(first_level_directory, directory=first_level_logs())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall statistics --------\n",
      "mean:  88.22872044489934 2\n",
      "std:   4.336783182447968 2\n",
      "min:   80.2010498046875 2\n",
      "max:   93.99038696289062 2\n",
      "\n",
      "%s values --------\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/RFD02_2020-02-13_14:17:00_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_RFD1/events.out.tfevents.1581599820.lcances.14720.0 80.2010498046875\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/SN25_2020-02-13_14:24:07_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_N1/events.out.tfevents.1581600247.lcances.32123.0 82.00393676757812\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/RFD01_2020-02-13_14:03:11_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_RFD1/events.out.tfevents.1581598991.lcances.18077.0 83.31512451171875\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/PSC1_2020-02-13_10:06:49_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_PSC1/events.out.tfevents.1581584809.lcances.8083.0 85.402099609375\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/RFD0075_2020-02-13_14:09:58_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_RFD1/events.out.tfevents.1581599398.lcances.35680.0 86.80069732666016\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/RFD005_2020-02-13_14:31:12_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_RFD1/events.out.tfevents.1581600672.lcances.9454.0 87.43444061279297\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/PSC2_2020-02-13_10:28:20_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_PSC1/events.out.tfevents.1581586100.lcances.31208.0 87.77316284179688\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/N2_2020-02-13_10:59:35_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_N1/events.out.tfevents.1581587975.lcances.34123.0 91.1385498046875\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/N1_2020-02-13_10:51:57_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_N1/events.out.tfevents.1581587517.lcances.16421.0 91.70673370361328\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/L2_2020-02-13_11:07:03_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_L1/events.out.tfevents.1581588423.lcances.24695.0 92.07823944091797\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/L1_2020-02-13_11:00:01_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_L1/events.out.tfevents.1581588001.lcances.34921.0 92.3186264038086\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/N3_2020-02-13_11:07:28_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_N1/events.out.tfevents.1581588448.lcances.26193.0 92.81031799316406\n",
      "../tensorboard/standalone_tensorboard/unique_augmentation/E1_2020-02-13_13:34:41_scallable2_Cosd-lr_sgd-0.05lr-wd0.001_200e_E1/events.out.tfevents.1581597281.lcances.4826.0 93.99038696289062\n"
     ]
    }
   ],
   "source": [
    "response = request_results\n",
    "\n",
    "# trim path from everythinfg irelevant\n",
    "# response = [(response[i][0].split(\"/\")[4].split(\"_\")[4][:4], response[i][1]) for i in range(len(response))]\n",
    "\n",
    "# order by run\n",
    "response = sorted(response, key=lambda x: x[1])\n",
    "\n",
    "values = np.array([v[1] for v in response])\n",
    "path = [p[0] for p in response]\n",
    "\n",
    "values = np.array([i for i in values if i is not None])\n",
    "print(\"Overall statistics --------\")\n",
    "print(\"mean: \", values.mean(), 2)\n",
    "print(\"std:  \", values.std(), 2)\n",
    "print(\"min:  \", values.min(), 2)\n",
    "print(\"max:  \", values.max(), 2)\n",
    "print(\"\")\n",
    "print(\"%s values --------\")\n",
    "for p, v in response:\n",
    "    print(p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
