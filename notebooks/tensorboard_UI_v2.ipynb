{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pprint\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox, Button\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lcances/.miniconda3/envs/tensorboard/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "tag_list = []\n",
    "log_list = []\n",
    "file_stats = dict()\n",
    "stat_list = [\"mean\", \"std\", \"maxi\", \"mini\"]\n",
    "\n",
    "os.chdir(\"..\")\n",
    "tensorboard_root = \"tensorboard\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_tag(path):\n",
    "    global tag_list\n",
    "    tag_list = []\n",
    "\n",
    "    for e in tf.compat.v1.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag not in tag_list:\n",
    "                    tag_list.append(value.tag)\n",
    "    \n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Si la list n'est pas vide\n",
    "    - Si le premier element est un fichier: return True\n",
    "    - Si le premier element est un dossier:\n",
    "        - lister le contenue de ce dossier L\n",
    "        - si L n'est pas vide\n",
    "            - Si le premier element est un fichier: return True\n",
    "            - Sinon return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_log(path):\n",
    "    if path:\n",
    "        if os.path.isfile(path[0]):\n",
    "            return True\n",
    "        \n",
    "        if os.path.isdir(path[0]):\n",
    "            if not os.listdir(path[0]): # directory is empty\n",
    "                return False\n",
    "            \n",
    "            sublist = [os.path.join(path[0], p) for p in os.listdir(path[0])]\n",
    "            \n",
    "            if sublist:\n",
    "                if os.path.isfile(sublist[0]):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_list(log_file):\n",
    "    list_file = os.listdir(log_file)\n",
    "    \n",
    "    print(log_file)\n",
    "    print(list_file)\n",
    "    path = os.path.join(log_file, list_file[0])\n",
    "    tag_list = get_all_tag(path)\n",
    "    print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ui_dropdown_dir(directory):\n",
    "    global log_list\n",
    "    \n",
    "    sub_directories = sorted([os.path.join(directory, p) for p in os.listdir(directory) ])\n",
    "        \n",
    "    if not contain_log(sub_directories):\n",
    "        interact(ui_dropdown_dir, directory=sub_directories)\n",
    "        \n",
    "    else:\n",
    "        path_list = [os.path.join(directory, l) for l in os.listdir(directory)]\n",
    "        log_list = path_list\n",
    "        interact_manual(get_tag_list, log_file=path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_stat(stat = \"maxi\"):\n",
    "    global file_stats\n",
    "    \n",
    "    values = [file_stats[l][stat] for l in file_stats.keys()]\n",
    "    \n",
    "    print(\"stat stat\")\n",
    "    print(\"mean: \", np.nanmean(values))\n",
    "    print(\"std : \", np.nanstd(values))\n",
    "    print(\"mini: \", np.nanmin(values))\n",
    "    print(\"maxi: \", np.nanmax(values))\n",
    "    print(\"\")\n",
    "    print(\"%.3f Â± %.3f\" % (np.nanmean(values), np.nanstd(values)))\n",
    "    print(\"\")\n",
    "    print(\"detail \")\n",
    "    pprint.pprint(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tensorboard/ubs8k']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(tensorboard_root + \"/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_dropdown_dir(directory, filters: str = \"\"):\n",
    "    global log_list\n",
    "    \n",
    "    sub_directories = sorted([os.path.join(directory, p) for p in os.listdir(directory) if \"ipynb\" not in p])\n",
    "        \n",
    "    if not contain_log(sub_directories):\n",
    "        print(\"next\")\n",
    "        ui = interact(ui_dropdown_dir, directory=sub_directories, filters=\"\")\n",
    "        \n",
    "    else:\n",
    "        valid_list, path_list = [], []\n",
    "        \n",
    "        # prepare filters\n",
    "        if filters == \"\":\n",
    "            filters = [\"\"]\n",
    "            need_filters = [\"\"]\n",
    "            avoid_filters = []\n",
    "        else:\n",
    "            filters = filters.split(\",\")\n",
    "            need_filters = [f for f in filters if f[0] != \"~\"]\n",
    "            avoid_filters = [f[1:] for f in filters if f[0] == \"~\"]\n",
    "        if not need_filters:\n",
    "            need_filters = [\"\"]\n",
    "            \n",
    "        print(\"need filters: \", need_filters)\n",
    "        print(\"avoid filters: \", avoid_filters)\n",
    "        # need filters\n",
    "        for l in os.listdir(directory):\n",
    "            valid = 0\n",
    "            for f in need_filters:\n",
    "                if f in l:\n",
    "                    valid += 1\n",
    "                    \n",
    "            if valid == len(need_filters):\n",
    "                valid_list.append(l)\n",
    "                    \n",
    "        # avoid filters\n",
    "        for l in valid_list:\n",
    "            valid = True\n",
    "            \n",
    "            for f in avoid_filters:\n",
    "                if f in l:\n",
    "                    valid = False\n",
    "                    break\n",
    "                    \n",
    "            if valid:\n",
    "                path_list.append(os.path.join(directory, l))\n",
    "            \n",
    "        print(\"valid list: \", valid_list[:2])\n",
    "        print(\"path list: \", path_list[:2])\n",
    "        # path_list = [os.path.join(directory, l) for l in os.listdir(directory) if filters in l]\n",
    "        log_list = path_list\n",
    "        interact_manual(get_tag_list, log_file=path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_stat(stat = \"maxi\"):\n",
    "    global file_stats\n",
    "    \n",
    "    values = [file_stats[l][stat] for l in file_stats.keys()]\n",
    "    \n",
    "    print(\"stat stat\")\n",
    "    print(\"mean: \", np.nanmean(values))\n",
    "    print(\"std : \", np.nanstd(values))\n",
    "    print(\"mini: \", np.nanmin(values))\n",
    "    print(\"maxi: \", np.nanmax(values))\n",
    "    print(\"\")\n",
    "    print(\"%.3f Â± %.3f\" % (np.nanmean(values) * 100, np.nanstd(values) * 100))\n",
    "    print(\"\")\n",
    "    print(\"detail \")\n",
    "    pprint.pprint(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_logs(stat = \"maxi\", format_fn = None):\n",
    "    global file_stats\n",
    "    \n",
    "    msg = \"\"\n",
    "    for k, d in file_stats.items():\n",
    "        formated_name = k\n",
    "        \n",
    "        if format_fn is not None:\n",
    "            formated_name = format_fn(k)\n",
    "            \n",
    "        msg += \"%s %.6f\\n\" % (formated_name, d[stat])\n",
    "    return msg.replace(\".\", \",\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-854897249b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mfile_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def statistics(mean=True, std=True, max=False, min=False, tag=tag_list[0]):\n",
    "    global file_stats\n",
    "    \n",
    "    file_log = dict()\n",
    "    \n",
    "    # read all the log files ------------------------------\n",
    "    @functools.lru_cache()\n",
    "    def get_log_data(path):\n",
    "        logs = dict()\n",
    "\n",
    "        for e in tf.compat.v1.train.summary_iterator(path):\n",
    "            for value in e.summary.value:\n",
    "                if value.HasField(\"simple_value\"):\n",
    "                    if value.tag not in logs:\n",
    "                        logs[value.tag] = []\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "        return logs\n",
    "    \n",
    "    for l in log_list:\n",
    "        final_path = os.path.join(l, os.listdir(l)[0])\n",
    "        logs = get_log_data(final_path)\n",
    "        \n",
    "        if logs:\n",
    "            file_log[l] = logs\n",
    "        \n",
    "    # compute the statistics ------------------------------\n",
    "    # ---- file wise ----\n",
    "    file_stats = dict()\n",
    "    \n",
    "    for l in file_log.keys():\n",
    "        file_stats[l] = dict(\n",
    "            mean = np.nanmean(file_log[l][tag]),\n",
    "            std = np.nanstd(file_log[l][tag]),\n",
    "            mini = np.nanmin(file_log[l][tag]),\n",
    "            maxi = np.nanmax(file_log[l][tag]),\n",
    "        )\n",
    "        \n",
    "    interact(stat_stat, stat=stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63aa2e7eae94542ba53771f0bf512c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=('tensorboard/ubs8k',), value='tensorboard/ubsâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ui_dropdown_dir(directory, filters:str='')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(ui_dropdown_dir, directory=glob.glob(tensorboard_root + \"/**\"), filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0389a56dd045a6a103749562ea4d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='mean'), Checkbox(value=True, description='std'), Checkâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.statistics(mean=True, std=True, max=False, min=False, tag='train/total_loss')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(statistics, mean=True, std=True, mini=False, maxi=False, tag=tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:27:20_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:46:15_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:49:40_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:18:55_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:41:13_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:59:55_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:42:48_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:15:34_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:37:49_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:08:47_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:48:09_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:23:57_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:03:18_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:34:17_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:20:36_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:58:27_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:30:54_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:12:09_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:22:18_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:32:27_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:06:54_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:29:03_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:55:06_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:56:31_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:01:51_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:10:16_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:44:45_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:35:54_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:27:26_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:05:25_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:25:41_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_20:51:35_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:39:23_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:17:14_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_21:53:02_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-19_22:13:39_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_2beta_0.0m_plsup\n",
      "\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 16 3 0,0 1000 0,385285\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 12 3 0,0 1000 0,399610\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 16 1 0,0 1000 0,390390\n",
      "cnn03 0,0005 annealing-cosine 5 16 1 0,0 1000 0,388168\n",
      "cnn03 0,0005 annealing-cosine 10 12 2 0,0 1000 0,422613\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 8 1 0,0 1000 0,453063\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 12 2 0,0 1000 0,422613\n",
      "cnn03 0,0005 annealing-cosine 5 12 3 0,0 1000 0,417508\n",
      "cnn03 0,0005 annealing-cosine 10 12 1 0,0 1000 0,418949\n",
      "cnn03 0,0005 annealing-cosine 5 12 1 0,0 1000 0,406727\n",
      "cnn03 0,0005 annealing-cosine 10 16 1 0,0 1000 0,390390\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 16 2 0,0 1000 0,397838\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 8 2 0,0 1000 0,474955\n",
      "cnn03 0,0005 annealing-cosine 10 8 3 0,0 1000 0,454504\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 16 1 0,0 1000 0,388168\n",
      "cnn03 0,0005 annealing-cosine 5 8 1 0,0 1000 0,453063\n",
      "cnn03 0,0005 annealing-cosine 10 8 2 0,0 1000 0,471832\n",
      "cnn03 0,0005 annealing-cosine 5 12 2 0,0 1000 0,422853\n",
      "cnn03 0,0005 annealing-cosine 5 16 2 0,0 1000 0,397838\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 8 2 0,0 1000 0,471832\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 8 3 0,0 1000 0,487057\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 8 1 0,0 1000 0,442823\n",
      "cnn03 0,0005 annealing-cosine 10 16 3 0,0 1000 0,388829\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 16 3 0,0 1000 0,388829\n",
      "cnn03 0,0005 annealing-cosine 5 8 2 0,0 1000 0,474955\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 12 1 0,0 1000 0,406727\n",
      "cnn03 0,0005 annealing-cosine 10 12 3 0,0 1000 0,399610\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 8 3 0,0 1000 0,454504\n",
      "cnn03 0,0005 annealing-cosine 10 8 1 0,0 1000 0,442823\n",
      "cnn03 0,0005 annealing-cosine 5 8 3 0,0 1000 0,487057\n",
      "cnn03 0,0005 annealing-cosine 5 16 3 0,0 1000 0,385285\n",
      "cnn03 0,0005 annealing-cosine 10 16 2 0,0 1000 0,398408\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 12 1 0,0 1000 0,418949\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 12 3 0,0 1000 0,417508\n",
      "cnn03 0,0005 weighted-annealing-cosine 10 16 2 0,0 1000 0,398408\n",
      "cnn03 0,0005 weighted-annealing-cosine 5 12 2 0,0 1000 0,422853\n"
     ]
    }
   ],
   "source": [
    "def format_fn(n):\n",
    "    print(n)\n",
    "    base = n.split(\"/\")[5].split(\"_\")\n",
    "#     print(base)\n",
    "    \n",
    "    model_name = base[2]\n",
    "    ratio = base[3]\n",
    "    epoch = base[4][:-1]\n",
    "    lr = base[5][:-2]\n",
    "    rule = base[6][:-4]\n",
    "    nb_steps = base[7][:-1]\n",
    "    nb_cycle = base[8][:-5]\n",
    "    nb_beta = base[9][:-4]\n",
    "    plsup_mini = base[10][:-1]\n",
    "    \n",
    "#     formated = \"%s %s %s %s %s\" % (model_name, lr, rule, nb_steps, epoch)\n",
    "    formated = \"%s %s %s %s %s %s %s %s\" % (model_name, lr, rule, nb_steps, nb_cycle, nb_beta, plsup_mini, epoch)\n",
    "    return formated\n",
    "\n",
    "detail = format_logs(\"maxi\", format_fn).split(\"\\n\")\n",
    "detail = sorted(detail, key=lambda x: x.split(\" \")[0])\n",
    "print(\"\\n\".join(detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_log(path):\n",
    "    if path:\n",
    "        \n",
    "        if os.path.isfile(path[0]):\n",
    "            return True\n",
    "        \n",
    "        if os.path.isdir(path[0]):\n",
    "            sublist = [os.path.join(path[0], p) for p in os.listdir(path[0])]\n",
    "            \n",
    "            if sublist:\n",
    "                if os.path.isfile(sublist[0]):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/e/sync/Documents_sync/Projet/UrbanSound8K/tensorboard/osirim_tensorboard\"\n",
    "list_dir = os.listdir(root)\n",
    "\n",
    "for name in list_dir:\n",
    "    path = os.path.join(root, name)\n",
    "    \n",
    "    print(contain_log(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e999da1df1f44846a8a52c3b408efdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=(), value=None), Output()), _dom_classes=('widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ui_dropdown_dir(directory)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(ui_dropdown_dir, directory=glob.glob(tensorboard_root + \"/**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorboard",
   "language": "python",
   "name": "tensorboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
