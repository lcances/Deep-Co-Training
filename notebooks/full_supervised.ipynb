{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%0 #\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from advertorch.attacks import GradientSignAttack\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "from datasetManager import DatasetManager\n",
    "from generators import Generator\n",
    "import signal_augmentations as sa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:36:12.973823Z",
     "start_time": "2019-11-12T15:36:12.893994Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        self.value = 0\n",
    "        self.accumulate_value = 0\n",
    "        self.count = 0\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def reset(self):\n",
    "        self.accumulate_value = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.count += 1\n",
    "\n",
    "        \n",
    "class BinaryAccuracy(Metrics):\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        Metrics.__init__(self, epsilon)\n",
    "        \n",
    "    def __call__(self, y_pred, y_true):\n",
    "        super().__call__()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            y_pred = (y_pred>0.5).float()\n",
    "            correct = (y_pred == y_true).float().sum()\n",
    "            self.value = correct/ (y_true.shape[0] * y_true.shape[1])\n",
    "            \n",
    "            self.accumulate_value += self.value\n",
    "            return self.accumulate_value / self.count\n",
    "        \n",
    "        \n",
    "class CategoricalAccuracy(Metrics):\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        Metrics.__init__(self, epsilon)\n",
    "        \n",
    "    def __call__(self, y_pred, y_true):\n",
    "        super().__call__()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            self.value = torch.mean((y_true == y_pred).float())\n",
    "            self.accumulate_value += self.value\n",
    "\n",
    "            return self.accumulate_value / self.count\n",
    "\n",
    "        \n",
    "class Ratio(Metrics):\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        Metrics.__init__(self, epsilon)\n",
    "        \n",
    "    def __call__(self, y_pred, y_adv_pred):\n",
    "        super().__call__()\n",
    "        \n",
    "        results = zip(y_pred, y_adv_pred)\n",
    "        results_bool = [int(r[0] != r[1]) for r in results]\n",
    "        self.value = sum(results_bool) / len(results_bool) * 100\n",
    "        self.accumulate_value += self.value\n",
    "        \n",
    "        return self.accumulate_value / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:36:12.997511Z",
     "start_time": "2019-11-12T15:36:12.975482Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_datetime():\n",
    "    now = datetime.datetime.now()\n",
    "    return str(now)[:10] + \"_\" + str(now)[11:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:36:13.020782Z",
     "start_time": "2019-11-12T15:36:13.000410Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def reset_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:36:34.259332Z",
     "start_time": "2019-11-12T15:36:34.233822Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "https://arxiv.org/pdf/1608.04363.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolReLU(nn.Sequential):\n",
    "    def __init__(self, in_size, out_size, kernel_size, stride, padding):\n",
    "        super(ConvPoolReLU, self).__init__(\n",
    "            nn.Conv2d(in_size, out_size, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)),\n",
    "            nn.BatchNorm2d(out_size),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "        \n",
    "class ConvReLU(nn.Sequential):\n",
    "    def __init__(self, in_size, out_size, kernel_size, stride, padding):\n",
    "        super(ConvReLU, self).__init__(\n",
    "            nn.Conv2d(in_size, out_size, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            ConvPoolReLU(1, 24, 3, 1, 1),\n",
    "            ConvPoolReLU(24, 48, 3, 1, 1),\n",
    "            ConvPoolReLU(48, 48, 3, 1, 1),\n",
    "            ConvReLU(48, 48, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1008, 10),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(64, 10),\n",
    "        )\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, *x.shape[1:])\n",
    "\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultisampleDropout2d(nn.Module):\n",
    "    \"\"\"https://arxiv.org/pdf/1905.09788.pdf\"\"\"\n",
    "    def __init__(self, ratio, nb_sample):\n",
    "        super(MultisampleDropout2d, self).__init__()\n",
    "        self.nb_sample = nb_sample\n",
    "        \n",
    "        self.dropouts = [nn.Dropout2d(ratio) for _ in range(nb_sample)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d = [dropout(x) for dropout in self.dropouts]\n",
    "        return torch.mean(torch.stack(d, dim=0), dim=0)\n",
    "    \n",
    "class MultisampleDropout1d(nn.Module):\n",
    "    \"\"\"https://arxiv.org/pdf/1905.09788.pdf\"\"\"\n",
    "    def __init__(self, ratio, nb_sample):\n",
    "        super(MultisampleDropout1d, self).__init__()\n",
    "        self.nb_sample = nb_sample\n",
    "        \n",
    "        self.dropouts = [nn.Dropout(ratio) for _ in range(nb_sample)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d = [dropout(x) for dropout in self.dropouts]\n",
    "        return torch.mean(torch.stack(d, dim=0), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_size, out_size, t, kernel_size, stride, padding):\n",
    "        super(MBConv, self).__init__()\n",
    "        expand_dim = in_size * t\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_size, expand_dim, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(expand_dim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(expand_dim, expand_dim, kernel_size=kernel_size, stride=stride, padding=padding, groups=expand_dim),\n",
    "            nn.BatchNorm2d(expand_dim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(expand_dim, out_size, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_size),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.stride == 1:\n",
    "            return x + self.conv(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 conv_input_dim: tuple = (64, 431),\n",
    "                 conv_in_size: list = [1, 64, 64],\n",
    "                 conv_out_size: list = [64, 64, 64],\n",
    "                 t = [1, 6, 6],\n",
    "                 s = [1, 2, 2],\n",
    "                 n = [1, 2, 2],\n",
    "                ):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        self.i =0\n",
    "        \n",
    "        self.conv_input_dim = conv_input_dim\n",
    "        self.conv_in_size = conv_in_size\n",
    "        self.conv_out_size = conv_out_size\n",
    "        self.t = t\n",
    "        \n",
    "        conv_layers = []\n",
    "        for i in range(len(conv_in_size)):\n",
    "            if i == 0:\n",
    "                conv_layers.append(nn.Conv2d(conv_in_size[i], conv_out_size[i], 3, 1, 1))\n",
    "                continue\n",
    "            \n",
    "            conv_layers.append( MBConv(conv_in_size[i], conv_out_size[i], t[i], 3, s[i], 1) )\n",
    "            for j in range(n[i]-1):\n",
    "                conv_layers.append( MBConv(conv_out_size[i], conv_out_size[i], t[i], 3, 1, 1) )\n",
    "    \n",
    "        self.features = nn.Sequential(*conv_layers)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            MultisampleDropout2d(0.2, 8),\n",
    "            nn.Conv2d(self.conv_out_size[-1], 10, kernel_size=1, stride=1, padding=0),\n",
    "#             nn.AdaptiveMaxPool2d((1, 1)),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.i == 0:\n",
    "            print(x.shape)\n",
    "            self.i = 1\n",
    "            \n",
    "        x = x.view(-1, 1, self.conv_input_dim[0], self.conv_input_dim[1])\n",
    "\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        x= x.view(-1, x.shape[1])\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======== Training ========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn(\n",
       "  (features): Sequential(\n",
       "    (0): ConvPoolReLU(\n",
       "      (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): ConvPoolReLU(\n",
       "      (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (2): ConvPoolReLU(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (3): ConvReLU(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=1008, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_func = cnn\n",
    "m1 = model_func()\n",
    "\n",
    "m1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "                               Kernel Shape      Output Shape   Params  \\\n",
      "Layer                                                                    \n",
      "0_features.0.Conv2d_0         [1, 24, 3, 3]  [1, 24, 64, 173]    240.0   \n",
      "1_features.0.MaxPool2d_1                  -   [1, 24, 16, 86]        -   \n",
      "2_features.0.BatchNorm2d_2             [24]   [1, 24, 16, 86]     48.0   \n",
      "3_features.0.ReLU6_3                      -   [1, 24, 16, 86]        -   \n",
      "4_features.1.Conv2d_0        [24, 48, 3, 3]   [1, 48, 16, 86]  10.416k   \n",
      "5_features.1.MaxPool2d_1                  -    [1, 48, 4, 43]        -   \n",
      "6_features.1.BatchNorm2d_2             [48]    [1, 48, 4, 43]     96.0   \n",
      "7_features.1.ReLU6_3                      -    [1, 48, 4, 43]        -   \n",
      "8_features.2.Conv2d_0        [48, 48, 3, 3]    [1, 48, 4, 43]  20.784k   \n",
      "9_features.2.MaxPool2d_1                  -    [1, 48, 1, 21]        -   \n",
      "10_features.2.BatchNorm2d_2            [48]    [1, 48, 1, 21]     96.0   \n",
      "11_features.2.ReLU6_3                     -    [1, 48, 1, 21]        -   \n",
      "12_features.3.Conv2d_0       [48, 48, 3, 3]    [1, 48, 1, 21]  20.784k   \n",
      "13_features.3.ReLU6_1                     -    [1, 48, 1, 21]        -   \n",
      "14_classifier.Flatten_0                   -         [1, 1008]        -   \n",
      "15_classifier.Dropout_1                   -         [1, 1008]        -   \n",
      "16_classifier.Linear_2           [1008, 10]           [1, 10]   10.09k   \n",
      "\n",
      "                              Mult-Adds  \n",
      "Layer                                    \n",
      "0_features.0.Conv2d_0         2.391552M  \n",
      "1_features.0.MaxPool2d_1              -  \n",
      "2_features.0.BatchNorm2d_2         24.0  \n",
      "3_features.0.ReLU6_3                  -  \n",
      "4_features.1.Conv2d_0        14.266368M  \n",
      "5_features.1.MaxPool2d_1              -  \n",
      "6_features.1.BatchNorm2d_2         48.0  \n",
      "7_features.1.ReLU6_3                  -  \n",
      "8_features.2.Conv2d_0         3.566592M  \n",
      "9_features.2.MaxPool2d_1              -  \n",
      "10_features.2.BatchNorm2d_2        48.0  \n",
      "11_features.2.ReLU6_3                 -  \n",
      "12_features.3.Conv2d_0         435.456k  \n",
      "13_features.3.ReLU6_1                 -  \n",
      "14_classifier.Flatten_0               -  \n",
      "15_classifier.Dropout_1               -  \n",
      "16_classifier.Linear_2           10.08k  \n",
      "----------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             62.554k\n",
      "Trainable params         62.554k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             20.670168M\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((1, 64, 173), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(m1, input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51a3d340227473dabbf29f2fdf1d50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c91d8c30c9c4e9cab0652c3d22d7448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_root = \"../dataset/audio\"\n",
    "metadata_root = \"../dataset/metadata\"\n",
    "\n",
    "dataset = DatasetManager(metadata_root, audio_root, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using the combination dictionary, several models will be tested. Procedure to follow:**\n",
    "- create feature extract function using *extract feature helper*\n",
    "- change feature extract function from the dataset_manager\n",
    "- if extract parameters change, invalide the validation cache\n",
    "- create the model using the parameters\n",
    "- define criterion and optimizer\n",
    "- generate loader\n",
    "- create tensorboard log name\n",
    "- perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988f1df4856a4300a57e9022283af1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=837), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "m1 = model_func()\n",
    "m1.cuda()\n",
    "\n",
    "# loss and optimizer\n",
    "criterion_bce = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    m1.parameters(),\n",
    "    weight_decay=1e-3,\n",
    "    lr=0.05\n",
    ")\n",
    "\n",
    "# Augmentation to use\n",
    "# ps1 = sa.PitchShift(0.5, DatasetManager.SR, (-2, 3))\n",
    "n = sa.Noise(0.5, (0.05, 0.2))\n",
    "augments = [n]\n",
    "\n",
    "# train and val loaders\n",
    "train_dataset = Generator(dataset, augments=augments)\n",
    "\n",
    "x, y = train_dataset.validation\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "val_dataset = torch.utils.data.TensorDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "nb_batch = len(train_dataset) // batch_size\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# scheduler\n",
    "lr_lambda = lambda epoch: 0.5 * (np.cos(np.pi * epoch / nb_epoch) + 1)\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "callbacks = [lr_scheduler]\n",
    "# callbacks = []\n",
    "\n",
    "# tensorboard\n",
    "title = \"%s_cnn_Cosd-lr_sgd-0.01lr-wd0.001_%de_0.5n\" % ( get_datetime(), nb_epoch )\n",
    "tensorboard = SummaryWriter(log_dir=\"tensorboard/%s\" % title, comment=model_func.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944025c233a6404884a0b950186c43a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, 100% \t ce: 1.8384 - acc: 0.3236 - ce val: 0.9773 - acc val: 0.4914 - took: 16.77s\n",
      "Epoch 2, 100% \t ce: 1.1379 - acc: 0.4770 - ce val: 1.1781 - acc val: 0.5333 - took: 16.27s\n",
      "Epoch 3, 100% \t ce: 1.0323 - acc: 0.5385 - ce val: 1.6864 - acc val: 0.4940 - took: 16.09s\n",
      "Epoch 4, 100% \t ce: 0.8151 - acc: 0.5961 - ce val: 2.1942 - acc val: 0.6301 - took: 15.86s\n",
      "Epoch 5, 100% \t ce: 0.7785 - acc: 0.6356 - ce val: 0.6675 - acc val: 0.6743 - took: 15.20s\n",
      "Epoch 6, 100% \t ce: 0.6803 - acc: 0.6582 - ce val: 0.3549 - acc val: 0.6905 - took: 15.76s\n",
      "Epoch 7, 100% \t ce: 1.1225 - acc: 0.6710 - ce val: 1.3953 - acc val: 0.6218 - took: 16.64s\n",
      "Epoch 8, 100% \t ce: 1.1050 - acc: 0.6960 - ce val: 5.6820 - acc val: 0.6204 - took: 16.25s\n",
      "Epoch 9, 100% \t ce: 1.0140 - acc: 0.6979 - ce val: 1.9994 - acc val: 0.6016 - took: 15.67s\n",
      "Epoch 10, 100% \t ce: 0.5304 - acc: 0.7147 - ce val: 1.8306 - acc val: 0.6924 - took: 16.88s\n",
      "Epoch 11, 100% \t ce: 0.7574 - acc: 0.7197 - ce val: 2.0633 - acc val: 0.5789 - took: 16.49s\n",
      "Epoch 12, 100% \t ce: 0.9417 - acc: 0.7323 - ce val: 4.0320 - acc val: 0.4889 - took: 16.10s\n",
      "Epoch 13, 100% \t ce: 1.1803 - acc: 0.7373 - ce val: 1.2408 - acc val: 0.6917 - took: 16.01s\n",
      "Epoch 14, 100% \t ce: 0.6032 - acc: 0.7453 - ce val: 1.7494 - acc val: 0.7623 - took: 16.09s\n",
      "Epoch 15, 100% \t ce: 1.2292 - acc: 0.7473 - ce val: 0.7397 - acc val: 0.5227 - took: 16.23s\n",
      "Epoch 16, 100% \t ce: 0.6493 - acc: 0.7550 - ce val: 0.1793 - acc val: 0.6458 - took: 16.16s\n",
      "Epoch 17, 100% \t ce: 0.5916 - acc: 0.7558 - ce val: 0.5030 - acc val: 0.5875 - took: 16.46s\n",
      "Epoch 18, 100% \t ce: 1.2733 - acc: 0.7636 - ce val: 0.1911 - acc val: 0.7593 - took: 15.57s\n",
      "Epoch 19, 100% \t ce: 0.6231 - acc: 0.7641 - ce val: 0.0684 - acc val: 0.7882 - took: 16.68s\n",
      "Epoch 20, 100% \t ce: 0.8744 - acc: 0.7723 - ce val: 1.3580 - acc val: 0.6942 - took: 16.18s\n",
      "Epoch 21, 100% \t ce: 0.5101 - acc: 0.7751 - ce val: 1.0647 - acc val: 0.7553 - took: 16.07s\n",
      "Epoch 22, 100% \t ce: 0.5622 - acc: 0.7715 - ce val: 0.2935 - acc val: 0.8009 - took: 16.50s\n",
      "Epoch 23, 100% \t ce: 0.3296 - acc: 0.7823 - ce val: 0.9692 - acc val: 0.7271 - took: 15.64s\n",
      "Epoch 24, 100% \t ce: 0.6021 - acc: 0.7875 - ce val: 0.5178 - acc val: 0.7507 - took: 16.51s\n",
      "Epoch 25, 100% \t ce: 0.5733 - acc: 0.7860 - ce val: 1.7550 - acc val: 0.6479 - took: 16.52s\n",
      "Epoch 26, 100% \t ce: 0.5772 - acc: 0.7980 - ce val: 0.5590 - acc val: 0.7433 - took: 16.60s\n",
      "Epoch 27, 100% \t ce: 0.4530 - acc: 0.7916 - ce val: 1.0365 - acc val: 0.7792 - took: 16.33s\n",
      "Epoch 28, 100% \t ce: 0.4888 - acc: 0.7921 - ce val: 0.7799 - acc val: 0.7692 - took: 16.47s\n",
      "Epoch 29, 100% \t ce: 0.7557 - acc: 0.7980 - ce val: 3.6933 - acc val: 0.7398 - took: 16.09s\n",
      "Epoch 30, 100% \t ce: 0.6815 - acc: 0.8026 - ce val: 3.1220 - acc val: 0.6727 - took: 16.60s\n",
      "Epoch 31, 100% \t ce: 0.4558 - acc: 0.7970 - ce val: 1.1863 - acc val: 0.7433 - took: 16.30s\n",
      "Epoch 32, 100% \t ce: 0.2669 - acc: 0.8016 - ce val: 1.0009 - acc val: 0.7218 - took: 16.21s\n",
      "Epoch 33, 100% \t ce: 0.3155 - acc: 0.8049 - ce val: 0.0779 - acc val: 0.7419 - took: 16.56s\n",
      "Epoch 34, 100% \t ce: 0.6281 - acc: 0.8013 - ce val: 1.7142 - acc val: 0.7519 - took: 16.59s\n",
      "Epoch 35, 100% \t ce: 0.4372 - acc: 0.8120 - ce val: 1.0001 - acc val: 0.6438 - took: 16.20s\n",
      "Epoch 36, 100% \t ce: 0.8002 - acc: 0.8167 - ce val: 5.0108 - acc val: 0.7421 - took: 16.33s\n",
      "Epoch 37, 100% \t ce: 0.4980 - acc: 0.8164 - ce val: 0.1462 - acc val: 0.7650 - took: 16.55s\n",
      "Epoch 38, 100% \t ce: 0.2994 - acc: 0.8124 - ce val: 2.9431 - acc val: 0.7775 - took: 16.48s\n",
      "Epoch 39, 100% \t ce: 0.5551 - acc: 0.8175 - ce val: 0.3017 - acc val: 0.7442 - took: 16.60s\n",
      "Epoch 40, 100% \t ce: 0.7236 - acc: 0.8183 - ce val: 0.2120 - acc val: 0.7188 - took: 16.65s\n",
      "Epoch 41, 100% \t ce: 0.8703 - acc: 0.8237 - ce val: 2.4285 - acc val: 0.6604 - took: 16.50s\n",
      "Epoch 42, 100% \t ce: 0.3291 - acc: 0.8194 - ce val: 0.6047 - acc val: 0.7275 - took: 16.72s\n",
      "Epoch 43, 100% \t ce: 0.7034 - acc: 0.8207 - ce val: 1.0176 - acc val: 0.7437 - took: 17.06s\n",
      "Epoch 44, 100% \t ce: 0.5821 - acc: 0.8233 - ce val: 0.2364 - acc val: 0.7604 - took: 16.03s\n",
      "Epoch 45, 100% \t ce: 0.9411 - acc: 0.8255 - ce val: 2.5048 - acc val: 0.6674 - took: 16.56s\n",
      "Epoch 46, 100% \t ce: 0.5967 - acc: 0.8311 - ce val: 1.6511 - acc val: 0.7306 - took: 16.89s\n",
      "Epoch 47, 100% \t ce: 0.6161 - acc: 0.8291 - ce val: 0.7487 - acc val: 0.7194 - took: 17.16s\n",
      "Epoch 48, 100% \t ce: 0.4671 - acc: 0.8212 - ce val: 1.1112 - acc val: 0.7738 - took: 16.75s\n",
      "Epoch 49, 100% \t ce: 0.3115 - acc: 0.8286 - ce val: 1.8921 - acc val: 0.7565 - took: 16.38s\n",
      "Epoch 50, 100% \t ce: 0.4360 - acc: 0.8254 - ce val: 2.2049 - acc val: 0.7081 - took: 17.08s\n",
      "Epoch 51, 100% \t ce: 0.1546 - acc: 0.8403 - ce val: 2.5440 - acc val: 0.6961 - took: 16.75s\n",
      "Epoch 52, 100% \t ce: 0.3833 - acc: 0.8364 - ce val: 3.0930 - acc val: 0.7403 - took: 16.95s\n",
      "Epoch 53, 100% \t ce: 0.3448 - acc: 0.8339 - ce val: 0.6922 - acc val: 0.7519 - took: 17.05s\n",
      "Epoch 54, 100% \t ce: 0.7074 - acc: 0.8333 - ce val: 1.2663 - acc val: 0.7093 - took: 16.73s\n",
      "Epoch 55, 100% \t ce: 0.4729 - acc: 0.8363 - ce val: 3.4765 - acc val: 0.7220 - took: 16.54s\n",
      "Epoch 56, 100% \t ce: 0.4271 - acc: 0.8402 - ce val: 0.9887 - acc val: 0.7704 - took: 16.84s\n",
      "Epoch 57, 100% \t ce: 0.5645 - acc: 0.8371 - ce val: 0.4703 - acc val: 0.7819 - took: 16.55s\n",
      "Epoch 58, 100% \t ce: 0.5819 - acc: 0.8422 - ce val: 3.6990 - acc val: 0.7178 - took: 16.42s\n",
      "Epoch 59, 100% \t ce: 0.2714 - acc: 0.8444 - ce val: 1.0718 - acc val: 0.7572 - took: 16.15s\n",
      "Epoch 60, 100% \t ce: 0.5058 - acc: 0.8462 - ce val: 1.0672 - acc val: 0.7495 - took: 16.58s\n",
      "Epoch 61, 100% \t ce: 0.3387 - acc: 0.8436 - ce val: 3.1190 - acc val: 0.7537 - took: 16.67s\n",
      "Epoch 62, 100% \t ce: 0.3435 - acc: 0.8466 - ce val: 2.7542 - acc val: 0.6951 - took: 16.72s\n",
      "Epoch 63, 100% \t ce: 0.2092 - acc: 0.8523 - ce val: 2.2298 - acc val: 0.7611 - took: 16.39s\n",
      "Epoch 64, 100% \t ce: 0.4879 - acc: 0.8522 - ce val: 1.3385 - acc val: 0.7132 - took: 16.88s\n",
      "Epoch 65, 100% \t ce: 0.2603 - acc: 0.8474 - ce val: 0.0765 - acc val: 0.7477 - took: 16.84s\n",
      "Epoch 66, 100% \t ce: 0.3434 - acc: 0.8477 - ce val: 0.5244 - acc val: 0.7241 - took: 16.87s\n",
      "Epoch 67, 100% \t ce: 0.3399 - acc: 0.8548 - ce val: 8.0834 - acc val: 0.7447 - took: 16.81s\n",
      "Epoch 68, 100% \t ce: 0.4017 - acc: 0.8523 - ce val: 0.8116 - acc val: 0.7576 - took: 16.70s\n",
      "Epoch 69, 100% \t ce: 0.3104 - acc: 0.8569 - ce val: 1.5037 - acc val: 0.7565 - took: 17.04s\n",
      "Epoch 70, 100% \t ce: 0.3568 - acc: 0.8542 - ce val: 0.3694 - acc val: 0.7692 - took: 16.73s\n",
      "Epoch 71, 100% \t ce: 0.2304 - acc: 0.8630 - ce val: 0.0664 - acc val: 0.7685 - took: 17.01s\n",
      "Epoch 72, 100% \t ce: 0.2554 - acc: 0.8601 - ce val: 0.0047 - acc val: 0.7581 - took: 16.79s\n",
      "Epoch 73, 100% \t ce: 0.5790 - acc: 0.8637 - ce val: 2.9600 - acc val: 0.7502 - took: 16.88s\n",
      "Epoch 74, 100% \t ce: 0.5829 - acc: 0.8591 - ce val: 0.8200 - acc val: 0.7623 - took: 17.04s\n",
      "Epoch 75, 100% \t ce: 0.5324 - acc: 0.8587 - ce val: 1.1444 - acc val: 0.7595 - took: 16.90s\n",
      "Epoch 76, 100% \t ce: 0.2771 - acc: 0.8585 - ce val: 1.2921 - acc val: 0.7514 - took: 16.87s\n",
      "Epoch 77, 100% \t ce: 0.2906 - acc: 0.8641 - ce val: 0.0247 - acc val: 0.7812 - took: 16.53s\n",
      "Epoch 78, 100% \t ce: 0.3616 - acc: 0.8604 - ce val: 0.2177 - acc val: 0.7542 - took: 16.84s\n",
      "Epoch 79, 100% \t ce: 0.2790 - acc: 0.8640 - ce val: 2.6885 - acc val: 0.7560 - took: 16.11s\n",
      "Epoch 80, 100% \t ce: 0.2689 - acc: 0.8633 - ce val: 1.7724 - acc val: 0.7509 - took: 15.94s\n",
      "Epoch 81, 100% \t ce: 0.2157 - acc: 0.8636 - ce val: 0.2592 - acc val: 0.7657 - took: 16.62s\n",
      "Epoch 82, 100% \t ce: 0.4021 - acc: 0.8649 - ce val: 1.5411 - acc val: 0.7565 - took: 16.69s\n",
      "Epoch 83, 100% \t ce: 0.4195 - acc: 0.8633 - ce val: 1.5675 - acc val: 0.7514 - took: 16.81s\n",
      "Epoch 84, 100% \t ce: 0.1580 - acc: 0.8681 - ce val: 0.2356 - acc val: 0.7692 - took: 16.47s\n",
      "Epoch 85, 100% \t ce: 0.3544 - acc: 0.8671 - ce val: 2.4814 - acc val: 0.7444 - took: 17.14s\n",
      "Epoch 86, 100% \t ce: 0.3059 - acc: 0.8610 - ce val: 5.7766 - acc val: 0.7451 - took: 16.31s\n",
      "Epoch 87, 100% \t ce: 0.1718 - acc: 0.8770 - ce val: 1.5357 - acc val: 0.7491 - took: 16.63s\n",
      "Epoch 88, 100% \t ce: 0.2852 - acc: 0.8711 - ce val: 1.7712 - acc val: 0.7456 - took: 16.58s\n",
      "Epoch 89, 100% \t ce: 0.3292 - acc: 0.8740 - ce val: 2.5698 - acc val: 0.7428 - took: 16.79s\n",
      "Epoch 90, 100% \t ce: 0.4714 - acc: 0.8683 - ce val: 1.4193 - acc val: 0.7491 - took: 16.08s\n",
      "Epoch 91, 100% \t ce: 0.5165 - acc: 0.8717 - ce val: 1.4721 - acc val: 0.7600 - took: 16.90s\n",
      "Epoch 92, 100% \t ce: 0.3544 - acc: 0.8673 - ce val: 0.1525 - acc val: 0.7639 - took: 16.78s\n",
      "Epoch 93, 100% \t ce: 0.3350 - acc: 0.8725 - ce val: 2.5872 - acc val: 0.7444 - took: 16.95s\n",
      "Epoch 94, 100% \t ce: 0.3416 - acc: 0.8703 - ce val: 2.0554 - acc val: 0.7456 - took: 17.11s\n",
      "Epoch 95, 100% \t ce: 0.3569 - acc: 0.8782 - ce val: 3.9854 - acc val: 0.7491 - took: 17.43s\n",
      "Epoch 96, 100% \t ce: 0.3522 - acc: 0.8694 - ce val: 1.3550 - acc val: 0.7623 - took: 16.23s\n",
      "Epoch 97, 100% \t ce: 0.3174 - acc: 0.8681 - ce val: 0.2291 - acc val: 0.7530 - took: 16.64s\n",
      "Epoch 98, 100% \t ce: 0.4250 - acc: 0.8705 - ce val: 3.3903 - acc val: 0.7405 - took: 16.56s\n",
      "Epoch 99, 100% \t ce: 0.2675 - acc: 0.8682 - ce val: 0.1068 - acc val: 0.7604 - took: 16.72s\n",
      "Epoch 100, 100% \t ce: 0.3854 - acc: 0.8710 - ce val: 0.3209 - acc val: 0.7542 - took: 16.58s\r"
     ]
    }
   ],
   "source": [
    "acc_func = CategoricalAccuracy()\n",
    "\n",
    "for epoch in tqdm.tqdm_notebook(range(nb_epoch)):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "    \n",
    "    acc_func.reset()\n",
    "\n",
    "    m1.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(training_loader):        \n",
    "        # Transfer to GPU\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        # predict\n",
    "        logits = m1(X)\n",
    "\n",
    "        weak_loss = criterion_bce(logits, y)\n",
    "\n",
    "        total_loss = weak_loss\n",
    "\n",
    "        # calc metrics\n",
    "#         y_pred = torch.log_softmax(logits, dim=1)\n",
    "        _, y_pred = torch.max(logits, 1)\n",
    "        acc = acc_func(y_pred, y)\n",
    "\n",
    "        # ======== back propagation ========\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ======== history ========\n",
    "        print(\"Epoch {}, {:d}% \\t ce: {:.4f} - acc: {:.4f} - took: {:.2f}s\".format(\n",
    "            epoch+1,\n",
    "            int(100 * (i+1) / nb_batch),\n",
    "            total_loss.item(),\n",
    "            acc,\n",
    "            time.time() - start_time\n",
    "        ),end=\"\\r\")\n",
    "\n",
    "    # using tensorboard to monitor loss and acc\n",
    "    tensorboard.add_scalar('train/ce', total_loss.item(), epoch)\n",
    "    tensorboard.add_scalar(\"train/acc\", 100. * acc, epoch )\n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        # reset metrics\n",
    "        acc_func.reset()\n",
    "        m1.eval()\n",
    "\n",
    "        for X_val, y_val in val_loader:\n",
    "            # Transfer to GPU\n",
    "            X_val = X_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "\n",
    "#             y_weak_val_pred, _ = model(X_val)\n",
    "            logits = m1(X_val)\n",
    "\n",
    "            # calc loss\n",
    "            weak_loss_val = criterion_bce(logits, y_val)\n",
    "\n",
    "            # metrics\n",
    "#             y_val_pred =torch.log_softmax(logits, dim=1)\n",
    "            _, y_val_pred = torch.max(logits, 1)\n",
    "            acc_val = acc_func(y_val_pred, y_val)\n",
    "\n",
    "            #Print statistics\n",
    "            print(\"Epoch {}, {:d}% \\t ce: {:.4f} - acc: {:.4f} - ce val: {:.4f} - acc val: {:.4f} - took: {:.2f}s\".format(\n",
    "                epoch+1,\n",
    "                int(100 * (i+1) / nb_batch),\n",
    "                total_loss.item(),\n",
    "                acc,\n",
    "                weak_loss_val.item(),\n",
    "                acc_val,\n",
    "                time.time() - start_time\n",
    "            ),end=\"\\r\")\n",
    "\n",
    "        # using tensorboard to monitor loss and acc\n",
    "        tensorboard.add_scalar('validation/ce', weak_loss_val.item(), epoch)\n",
    "        tensorboard.add_scalar(\"validation/acc\", 100. * acc_val, epoch )\n",
    "\n",
    "    for callback in callbacks:\n",
    "        callback.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}