{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/samova/lcances/.miniconda3/envs/pytorch-dev/bin/python'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from DCT.util.dataset_loader import load_dataset\n",
    "from DCT.util.optimizer_loader import load_optimizer\n",
    "from DCT.util.callbacks_loader import load_callbacks\n",
    "from DCT.util.model_loader import load_model\n",
    "from DCT.util.preprocess_loader import load_preprocesser\n",
    "from DCT.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from DCT.util.utils import reset_seed, get_datetime, track_maximum\n",
    "\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"SpeechCommand\", type=str, help=\"available [ubs8k | cifar10]\")\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"cnn03\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=256, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=200, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.001, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--preload_dataset\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_m = parser.add_argument_group(\"Model parameters\")\n",
    "group_m.add_argument(\"--num_classes\", default=35, type=int)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=256, checkpoint_path='supervised', checkpoint_root='../model_save/', dataset='SpeechCommand', dataset_root='../datasets', from_config='', learning_rate=0.001, model='cnn03', nb_epoch=200, num_classes=35, preload_dataset=False, resume=False, seed=1234, supervised_ratio=1.0, tensorboard_path='supervised', tensorboard_root='../tensorboard/', tensorboard_sufix='', train_folds=[1, 2, 3, 4], val_folds=[5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "reset_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = load_preprocesser(args.dataset, \"supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/SpeechCommands/speech_commands_v0.02\n",
      "Dataset already download and verified\n",
      "../datasets/SpeechCommands/speech_commands_v0.02\n",
      "Dataset already download and verified\n"
     ]
    }
   ],
   "source": [
    "manager, train_loader, val_loader = load_dataset(\n",
    "    args.dataset,\n",
    "    \"supervised\",\n",
    "    \n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "\n",
    "    train_transform=train_transform,\n",
    "    val_transform=val_transform,\n",
    "    \n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tuple(train_loader.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 35\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_func = load_model(args.dataset, args.model)\n",
    "# model_func = get_model_from_name(\"esc_wideresnet28_8\")\n",
    "model = model_func(input_shape=input_shape, num_classes = args.num_classes)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 64, 32]             240\n",
      "         MaxPool2d-2           [-1, 24, 16, 16]               0\n",
      "       BatchNorm2d-3           [-1, 24, 16, 16]              48\n",
      "             ReLU6-4           [-1, 24, 16, 16]               0\n",
      "            Conv2d-5           [-1, 48, 16, 16]          10,416\n",
      "         MaxPool2d-6             [-1, 48, 4, 8]               0\n",
      "       BatchNorm2d-7             [-1, 48, 4, 8]              96\n",
      "             ReLU6-8             [-1, 48, 4, 8]               0\n",
      "            Conv2d-9             [-1, 72, 4, 8]          31,176\n",
      "        MaxPool2d-10             [-1, 72, 2, 4]               0\n",
      "      BatchNorm2d-11             [-1, 72, 2, 4]             144\n",
      "            ReLU6-12             [-1, 72, 2, 4]               0\n",
      "           Conv2d-13             [-1, 72, 2, 4]          46,728\n",
      "        MaxPool2d-14             [-1, 72, 1, 2]               0\n",
      "      BatchNorm2d-15             [-1, 72, 1, 2]             144\n",
      "            ReLU6-16             [-1, 72, 1, 2]               0\n",
      "           Conv2d-17             [-1, 72, 1, 2]          46,728\n",
      "            ReLU6-18             [-1, 72, 1, 2]               0\n",
      "          Flatten-19                  [-1, 144]               0\n",
      "          Dropout-20                  [-1, 144]               0\n",
      "           Linear-21                   [-1, 35]           5,075\n",
      "================================================================\n",
      "Total params: 140,795\n",
      "Trainable params: 140,795\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 0.54\n",
      "Estimated Total Size (MB): 1.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "s = summary(model, input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tensorboard/SpeechCommand/supervised/cnn03/1.0S/2020-09-30_13:11:52_cnn03_1.0S\n"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "title_element = (args.model, args.supervised_ratio, get_datetime(), model_func.__name__, args.supervised_ratio)\n",
    "tensorboard_title = \"%s/%sS/%s_%s_%.1fS\" % title_element\n",
    "\n",
    "title_element = (model_func.__name__, args.supervised_ratio)\n",
    "checkpoint_title = \"%s_%.1fS\" % title_element\n",
    "\n",
    "tensorboard = mSummaryWriter(log_dir=\"%s/%s\" % (tensorboard_path, tensorboard_title), comment=model_func.__name__)\n",
    "print(os.path.join(tensorboard_path, tensorboard_title))\n",
    "\n",
    "# losses\n",
    "loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_params = {}\n",
    "for key, value in args.__dict__.items():\n",
    "    tensorboard_params[key] = str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard.add_hparams(tensorboard_params, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = load_optimizer(args.dataset, \"supervised\", model=model)\n",
    "callbacks = load_callbacks(args.dataset, \"supervised\", optimizer=optimizer, nb_epoch=args.nb_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint = CheckPoint(model, optimizer, mode=\"max\", name=\"%s/%s.torch\" % (checkpoint_path, checkpoint_title))\n",
    "\n",
    "# Metrics\n",
    "fscore_fn = FScore()\n",
    "acc_fn = CategoricalAccuracy()\n",
    "avg = ContinueAverage()\n",
    "\n",
    "maximum_tracker = track_maximum()\n",
    "\n",
    "reset_metrics = lambda : [m.reset() for m in [fscore_fn, acc_fn, avg]]\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Can resume previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".        Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} - {:<9.9} {:<12.12}| {:<9.9}- {:<6.6}\"\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} - {:<9.9} {:<10.4f}| {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "header = header_form.format(\n",
    "    \".               \", \"Epoch\", \"%\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1 \",\"Time\"\n",
    ")\n",
    "\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    reset_metrics()\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(train_loader):        \n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        logits = model(X)        \n",
    "        loss = loss_ce(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=args.num_classes)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(train_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"train/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"train/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"train/acc\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "    reset_metrics()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = model(X)\n",
    "            loss = loss_ce(logits, y)\n",
    "\n",
    "            # metrics\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=args.num_classes)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"val/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"val/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"val/acc\", acc, epoch)\n",
    "    \n",
    "    tensorboard.add_scalar(\"hyperparameters/learning_rate\", get_lr(optimizer), epoch)\n",
    "    \n",
    "    tensorboard.add_scalar(\"max/acc\", maximum_tracker(\"acc\", acc), epoch )\n",
    "    tensorboard.add_scalar(\"max/f1\", maximum_tracker(\"f1\", fscore), epoch )\n",
    "\n",
    "    checkpoint.step(acc)\n",
    "    for c in callbacks:\n",
    "        c.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.preload_dataset = True\n",
    "if args.preload_dataset:\n",
    "    train_loaded = train_loader.dataset.load_cache_from_disk(\"train\")\n",
    "    val_loaded = val_loader.dataset.load_cache_from_disk(\"val\")\n",
    "    \n",
    "    if not train_loaded:\n",
    "        print(\"No disk cache for training set\")\n",
    "        import tqdm\n",
    "\n",
    "        # Training\n",
    "        for i in tqdm.tqdm(range(len(train_loader.dataset))):\n",
    "            _, _ = train_loader.dataset[i]\n",
    "        train_loader.dataset.save_cache_to_disk(\"train\")\n",
    "        \n",
    "    if not val_loaded:\n",
    "        print(\"No disk cache for validation set\")\n",
    "        #val\n",
    "        for i in tqdm.tqdm(range(len(val_loader.dataset))):\n",
    "            _, _ = val_loader.dataset[i]\n",
    "        val_loader.dataset.save_cache_to_disk(\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".        Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n",
      "\n",
      "Training 1      - 100    -          1.4696 -           0.5856    | 0.5308   - 552.8139\n",
      "\u001b[1;4mValidati 1      - 100    -          0.5574 -           0.8323    | 0.8407   - 47.8182\u001b[0m\n",
      "Training 2      - 43     -          0.5518 -           0.8375    | 0.8450   - 2.1437\r"
     ]
    }
   ],
   "source": [
    "print(header)\n",
    "\n",
    "start_epoch = checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    train(e)\n",
    "    val(e)\n",
    "    \n",
    "    tensorboard.flush()\n",
    "tensorboard.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SummaryWriter' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-02c81df1438b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val/acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val/f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-02c81df1438b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{k} = {max(tensorboard.history[k])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mspp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{k} = {max(tensorboard.history[k])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SummaryWriter' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(checkpoint.epoch_counter))\n",
    "sm = lambda y, w: np.convolve(y, np.ones(w)/w, mode='same')\n",
    "pp = lambda k: plt.plot(x, tensorboard.history[k], label=f\"{k} = {max(tensorboard.history[k])}\")\n",
    "spp = lambda k: plt.plot(x, sm(tensorboard.history[k], 5), label=f\"{k} = {max(tensorboard.history[k])}\")\n",
    "\n",
    "\n",
    "plt.figure(0, figsize=(30, 14))\n",
    "plt.subplot(2, 3, 1)\n",
    "pp(\"val/acc\")\n",
    "pp(\"val/f1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "pp(\"detail_hyperparameters/learning_rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (only for speechcommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/SpeechCommands/speech_commands_v0.02\n",
      "Dataset already download and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cae73283317e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechCommands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-Co-Training/DCT/dataset_loader/speechcommand.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, subset, url, download, transform)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_valid_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-Co-Training/DCT/dataset_loader/speechcommand.py\u001b[0m in \u001b[0;36m_keep_valid_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         }\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_walker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_walker\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-Co-Training/DCT/dataset_loader/speechcommand.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    161\u001b[0m         }\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_walker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_walker\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args.dataset.lower() == \"speechcommand\":\n",
    "    \n",
    "    from DCT.dataset_loader.speechcommand import SpeechCommands\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.nn import Sequential\n",
    "    from DCT.util.transforms import PadUpTo\n",
    "    from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "\n",
    "    transform = Sequential(\n",
    "        PadUpTo(target_length=16000, mode=\"constant\", value=0),\n",
    "        MelSpectrogram(sample_rate=16000, n_fft=2048, hop_length=512, n_mels=64),\n",
    "        AmplitudeToDB(),\n",
    "    )\n",
    "\n",
    "    test_dataset = SpeechCommands(root=args.dataset_root, subset=\"testing\", download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header)\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"\")\n",
    "reset_metrics()\n",
    "model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, (X, y) in enumerate(test_loader):\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_ce(logits, y)\n",
    "\n",
    "        # metrics\n",
    "        pred = torch.softmax(logits, dim=1)\n",
    "        pred_arg = torch.argmax(logits, dim=1)\n",
    "        y_one_hot = F.one_hot(y, num_classes=args.num_classes)\n",
    "\n",
    "        acc = acc_fn(pred_arg, y).mean\n",
    "        fscore = fscore_fn(pred, y_one_hot).mean\n",
    "        avg_ce = avg(loss.item()).mean\n",
    "\n",
    "        # logs\n",
    "        print(val_form.format(\n",
    "            \"Testing: \",\n",
    "            1,\n",
    "            int(100 * (i + 1) / len(val_loader)),\n",
    "            \"\", avg_ce,\n",
    "            \"\", acc, fscore,\n",
    "            time.time() - start_time\n",
    "        ), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
