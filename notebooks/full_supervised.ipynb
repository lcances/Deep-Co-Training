{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from DCT.util.dataset_loader import load_dataset\n",
    "from DCT.util.optimizer_loader import load_optimizer\n",
    "from DCT.util.callbacks_loader import load_callbacks\n",
    "from DCT.util.model_loader import load_model\n",
    "from DCT.util.preprocess_loader import load_preprocesser\n",
    "from DCT.util.checkpoint import CheckPoint\n",
    "from DCT.util.utils import reset_seed, get_datetime, track_maximum\n",
    "\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"SpeechCommand\", type=str, help=\"available [ubs8k | cifar10]\")\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"cnn03\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=256, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=200, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.001, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_m = parser.add_argument_group(\"Model parameters\")\n",
    "group_m.add_argument(\"--num_classes\", default=50, type=int)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Namespace(batch_size=256, checkpoint_path='supervised', checkpoint_root='../model_save/', dataset='SpeechCommand', dataset_root='../datasets', from_config='', learning_rate=0.001, model='cnn03', nb_epoch=200, num_classes=50, resume=False, seed=1234, supervised_ratio=1.0, tensorboard_path='supervised', tensorboard_root='../tensorboard/', tensorboard_sufix='', train_folds=[1, 2, 3, 4], val_folds=[5])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "reset_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'../datasets'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "args.dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = load_preprocesser(args.dataset, \"supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../datasets/SpeechCommands/speech_commands_v0.02\nDataset already download and verified\n"
    }
   ],
   "source": [
    "manager, train_loader, val_loader = load_dataset(\n",
    "    args.dataset,\n",
    "    \"supervised\",\n",
    "    \n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "\n",
    "    train_transform=train_transform,\n",
    "    val_transform=val_transform,\n",
    "\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "144 50\n"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_func = load_model(args.dataset, args.model)\n",
    "# model_func = get_model_from_name(\"esc_wideresnet28_8\")\n",
    "model = model_func(input_shape=(64, 32), num_classes = args.num_classes)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "================================================================================\n                               Kernel Shape     Output Shape   Params  \\\nLayer                                                                   \n0_features.0.Conv2d_0         [1, 24, 3, 3]  [1, 24, 64, 32]    240.0   \n1_features.0.MaxPool2d_1                  -  [1, 24, 16, 16]        -   \n2_features.0.BatchNorm2d_2             [24]  [1, 24, 16, 16]     48.0   \n3_features.0.ReLU6_3                      -  [1, 24, 16, 16]        -   \n4_features.1.Conv2d_0        [24, 48, 3, 3]  [1, 48, 16, 16]  10.416k   \n5_features.1.MaxPool2d_1                  -    [1, 48, 4, 8]        -   \n6_features.1.BatchNorm2d_2             [48]    [1, 48, 4, 8]     96.0   \n7_features.1.ReLU6_3                      -    [1, 48, 4, 8]        -   \n8_features.2.Conv2d_0        [48, 72, 3, 3]    [1, 72, 4, 8]  31.176k   \n9_features.2.MaxPool2d_1                  -    [1, 72, 2, 4]        -   \n10_features.2.BatchNorm2d_2            [72]    [1, 72, 2, 4]    144.0   \n11_features.2.ReLU6_3                     -    [1, 72, 2, 4]        -   \n12_features.3.Conv2d_0       [72, 72, 3, 3]    [1, 72, 2, 4]  46.728k   \n13_features.3.MaxPool2d_1                 -    [1, 72, 1, 2]        -   \n14_features.3.BatchNorm2d_2            [72]    [1, 72, 1, 2]    144.0   \n15_features.3.ReLU6_3                     -    [1, 72, 1, 2]        -   \n16_features.4.Conv2d_0       [72, 72, 3, 3]    [1, 72, 1, 2]  46.728k   \n17_features.4.ReLU6_1                     -    [1, 72, 1, 2]        -   \n18_classifier.Flatten_0                   -         [1, 144]        -   \n19_classifier.Dropout_1                   -         [1, 144]        -   \n20_classifier.Linear_2            [144, 50]          [1, 50]    7.25k   \n\n                             Mult-Adds  \nLayer                                   \n0_features.0.Conv2d_0         442.368k  \n1_features.0.MaxPool2d_1             -  \n2_features.0.BatchNorm2d_2        24.0  \n3_features.0.ReLU6_3                 -  \n4_features.1.Conv2d_0        2.654208M  \n5_features.1.MaxPool2d_1             -  \n6_features.1.BatchNorm2d_2        48.0  \n7_features.1.ReLU6_3                 -  \n8_features.2.Conv2d_0         995.328k  \n9_features.2.MaxPool2d_1             -  \n10_features.2.BatchNorm2d_2       72.0  \n11_features.2.ReLU6_3                -  \n12_features.3.Conv2d_0        373.248k  \n13_features.3.MaxPool2d_1            -  \n14_features.3.BatchNorm2d_2       72.0  \n15_features.3.ReLU6_3                -  \n16_features.4.Conv2d_0         93.312k  \n17_features.4.ReLU6_1                -  \n18_classifier.Flatten_0              -  \n19_classifier.Dropout_1              -  \n20_classifier.Linear_2            7.2k  \n--------------------------------------------------------------------------------\n                        Totals\nTotal params           142.97k\nTrainable params       142.97k\nNon-trainable params       0.0\nMult-Adds             4.56588M\n================================================================================\n"
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((1, 64, 32), dtype=torch.float)\n",
    "input_tensor = input_tensor.cuda()\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5\n"
    }
   ],
   "source": [
    "nb_conv = 0\n",
    "\n",
    "for layer in s.index.values:\n",
    "    if \"Conv\" in layer:\n",
    "        nb_conv += 1\n",
    "print(nb_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../tensorboard/SpeechCommand/supervised/cnn03/1.0S/2020-09-22_16:41:22_cnn03_1.0S\n"
    }
   ],
   "source": [
    "# tensorboard\n",
    "title_element = (args.model, args.supervised_ratio, get_datetime(), model_func.__name__, args.supervised_ratio)\n",
    "tensorboard_title = \"%s/%sS/%s_%s_%.1fS\" % title_element\n",
    "\n",
    "title_element = (model_func.__name__, args.supervised_ratio)\n",
    "checkpoint_title = \"%s_%.1fS\" % title_element\n",
    "\n",
    "tensorboard = SummaryWriter(log_dir=\"%s/%s\" % (tensorboard_path, tensorboard_title), comment=model_func.__name__)\n",
    "print(os.path.join(tensorboard_path, tensorboard_title))\n",
    "\n",
    "# losses\n",
    "loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_params = {}\n",
    "for key, value in args.__dict__.items():\n",
    "    tensorboard_params[key] = str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard.add_hparams(tensorboard_params, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = load_optimizer(args.dataset, \"supervised\", model=model)\n",
    "callbacks = load_callbacks(args.dataset, \"supervised\", optimizer=optimizer, nb_epoch=args.nb_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint = CheckPoint(model, optimizer, mode=\"max\", name=\"%s/%s.torch\" % (checkpoint_path, checkpoint_title))\n",
    "\n",
    "# Metrics\n",
    "fscore_fn = FScore()\n",
    "acc_fn = CategoricalAccuracy()\n",
    "avg = ContinueAverage()\n",
    "maximum_tracker = track_maximum()\n",
    "\n",
    "reset_metrics = lambda : [m.reset() for m in [fscore_fn, acc_fn, avg]]\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Can resume previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "args.resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".        Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n"
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} - {:<9.9} {:<12.12}| {:<9.9}- {:<6.6}\"\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} - {:<9.9} {:<10.4f}| {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "header = header_form.format(\n",
    "    \".               \", \"Epoch\", \"%\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1 \",\"Time\"\n",
    ")\n",
    "\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    reset_metrics()\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(train_loader):        \n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        logits = model(X)        \n",
    "        loss = loss_ce(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=args.num_classes)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(train_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"train/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"train/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"train/acc\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "    reset_metrics()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(val_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = model(X)\n",
    "            loss = loss_ce(logits, y)\n",
    "\n",
    "            # metrics\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=args.num_classes)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"val/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"val/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"val/acc\", acc, epoch)\n",
    "    \n",
    "    tensorboard.add_scalar(\"hyperparameters/learning_rate\", get_lr(optimizer), epoch)\n",
    "    \n",
    "    tensorboard.add_scalar(\"max/acc\", maximum_tracker(\"acc\", acc), epoch )\n",
    "    tensorboard.add_scalar(\"max/f1\", maximum_tracker(\"f1\", fscore), epoch )\n",
    "\n",
    "    checkpoint.step(acc)\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".        Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n",
      "\n",
      "Training 1      - 100    -          1.4359 -           0.5988    | 0.5415   - 92.3807\n",
      "\u001b[1;4mValidati 1      - 100    -          0.6513 -           0.8065    | 0.8182   - 21.4087\u001b[0m\n",
      "Training 2      - 100    -          0.5007 -           0.8533    | 0.8597   - 5.9780\n",
      "\u001b[1;4mValidati 2      - 100    -          0.4471 -           0.8661    | 0.8785   - 0.5101\u001b[0m\n",
      "Training 3      - 100    -          0.3802 -           0.8881    | 0.8958   - 5.3418\n",
      "\u001b[1;4mValidati 3      - 100    -          0.4105 -           0.8796    | 0.8907   - 0.4340\u001b[0m\n",
      "Training 4      - 100    -          0.3187 -           0.9054    | 0.9128   - 5.5625\n",
      "\u001b[1;4mValidati 4      - 100    -          0.4307 -           0.8728    | 0.8861   - 0.4723\u001b[0m\n",
      "Training 5      - 100    -          0.2784 -           0.9162    | 0.9239   - 5.7993\n",
      "\u001b[1;4mValidati 5      - 100    -          0.3812 -           0.8885    | 0.9009   - 0.4695\u001b[0m\n",
      "Training 6      - 100    -          0.2487 -           0.9254    | 0.9317   - 5.5743\n",
      "\u001b[1;4mValidati 6      - 100    -          0.3649 -           0.8957    | 0.9063   - 0.4305\u001b[0m\n",
      "Training 7      - 100    -          0.2281 -           0.9314    | 0.9377   - 5.5606\n",
      "\u001b[1;4mValidati 7      - 100    -          0.3879 -           0.8906    | 0.9023   - 0.4687\u001b[0m\n",
      "Training 8      - 100    -          0.2104 -           0.9371    | 0.9428   - 5.3513\n",
      "\u001b[1;4mValidati 8      - 100    -          0.3438 -           0.9008    | 0.9119   - 0.4175\u001b[0m\n",
      "Training 9      - 100    -          0.1916 -           0.9414    | 0.9465   - 5.5239\n",
      "\u001b[1;4mValidati 9      - 100    -          0.3876 -           0.8937    | 0.9053   - 0.4697\u001b[0m\n",
      "Training 10     - 100    -          0.1798 -           0.9453    | 0.9499   - 5.3853\n",
      "\u001b[1;4mValidati 10     - 100    -          0.3672 -           0.8985    | 0.9098   - 0.4196\u001b[0m\n",
      "Training 11     - 100    -          0.1722 -           0.9477    | 0.9520   - 5.3232\n",
      "\u001b[1;4mValidati 11     - 100    -          0.3575 -           0.9050    | 0.9147   - 0.4297\u001b[0m\n",
      "Training 12     - 100    -          0.1587 -           0.9508    | 0.9558   - 5.3531\n",
      "\u001b[1;4mValidati 12     - 100    -          0.3771 -           0.9010    | 0.9118   - 0.4193\u001b[0m\n",
      "Training 13     - 100    -          0.1508 -           0.9532    | 0.9577   - 5.5194\n",
      "\u001b[1;4mValidati 13     - 100    -          0.3852 -           0.9006    | 0.9105   - 0.4781\u001b[0m\n",
      "Training 14     - 100    -          0.1421 -           0.9559    | 0.9601   - 5.3790\n",
      "\u001b[1;4mValidati 14     - 100    -          0.4094 -           0.8961    | 0.9063   - 0.4296\u001b[0m\n",
      "Training 15     - 100    -          0.1355 -           0.9573    | 0.9612   - 5.3258\n",
      "\u001b[1;4mValidati 15     - 100    -          0.3803 -           0.9033    | 0.9146   - 0.4197\u001b[0m\n",
      "Training 16     - 100    -          0.1310 -           0.9590    | 0.9630   - 5.3388\n",
      "\u001b[1;4mValidati 16     - 100    -          0.3749 -           0.9051    | 0.9151   - 0.4283\u001b[0m\n",
      "Training 17     - 100    -          0.1188 -           0.9629    | 0.9663   - 5.3792\n",
      "\u001b[1;4mValidati 17     - 100    -          0.4281 -           0.9016    | 0.9105   - 0.4301\u001b[0m\n",
      "Training 18     - 100    -          0.1177 -           0.9629    | 0.9666   - 5.4747\n",
      "\u001b[1;4mValidati 18     - 100    -          0.4210 -           0.9040    | 0.9125   - 0.4411\u001b[0m\n",
      "Training 19     - 100    -          0.1113 -           0.9650    | 0.9682   - 5.3991\n",
      "\u001b[1;4mValidati 19     - 100    -          0.4038 -           0.9052    | 0.9149   - 0.4598\u001b[0m\n",
      "Training 20     - 100    -          0.1068 -           0.9664    | 0.9692   - 5.2930\n",
      "\u001b[1;4mValidati 20     - 100    -          0.4208 -           0.9045    | 0.9144   - 0.4159\u001b[0m\n",
      "Training 21     - 100    -          0.1054 -           0.9672    | 0.9702   - 5.2955\n",
      "\u001b[1;4mValidati 21     - 100    -          0.4467 -           0.9011    | 0.9106   - 0.4207\u001b[0m\n",
      "Training 22     - 100    -          0.1013 -           0.9677    | 0.9704   - 5.2889\n",
      "\u001b[1;4mValidati 22     - 100    -          0.4148 -           0.9064    | 0.9152   - 0.4164\u001b[0m\n",
      "Training 23     - 100    -          0.0922 -           0.9705    | 0.9731   - 5.3037\n",
      "\u001b[1;4mValidati 23     - 100    -          0.4226 -           0.9055    | 0.9154   - 0.4160\u001b[0m\n",
      "Training 24     - 100    -          0.0908 -           0.9713    | 0.9739   - 5.3417\n",
      "\u001b[1;4mValidati 24     - 100    -          0.4358 -           0.9069    | 0.9162   - 0.4132\u001b[0m\n",
      "Training 25     - 100    -          0.0894 -           0.9721    | 0.9745   - 5.4053\n",
      "\u001b[1;4mValidati 25     - 100    -          0.4137 -           0.9064    | 0.9159   - 0.4150\u001b[0m\n",
      "Training 26     - 100    -          0.0850 -           0.9729    | 0.9754   - 5.3682\n",
      "\u001b[1;4mValidati 26     - 100    -          0.4525 -           0.9068    | 0.9150   - 0.4548\u001b[0m\n",
      "Training 27     - 100    -          0.0873 -           0.9719    | 0.9743   - 5.3326\n",
      "\u001b[1;4mValidati 27     - 100    -          0.4743 -           0.9040    | 0.9123   - 0.4287\u001b[0m\n",
      "Training 28     - 100    -          0.0762 -           0.9759    | 0.9781   - 5.3526\n",
      "\u001b[1;4mValidati 28     - 100    -          0.4973 -           0.9010    | 0.9101   - 0.4159\u001b[0m\n",
      "Training 29     - 100    -          0.0814 -           0.9744    | 0.9765   - 5.4747\n",
      "\u001b[1;4mValidati 29     - 100    -          0.4658 -           0.9059    | 0.9146   - 0.4650\u001b[0m\n",
      "Training 30     - 100    -          0.0753 -           0.9762    | 0.9783   - 5.7578\n",
      "\u001b[1;4mValidati 30     - 100    -          0.4754 -           0.9057    | 0.9134   - 0.4812\u001b[0m\n",
      "Training 31     - 100    -          0.0715 -           0.9772    | 0.9791   - 6.3438\n",
      "\u001b[1;4mValidati 31     - 100    -          0.5491 -           0.8990    | 0.9065   - 0.5242\u001b[0m\n",
      "Training 32     - 100    -          0.0690 -           0.9782    | 0.9800   - 5.4423\n",
      "\u001b[1;4mValidati 32     - 100    -          0.4926 -           0.9045    | 0.9121   - 0.4239\u001b[0m\n",
      "Training 33     - 100    -          0.0701 -           0.9775    | 0.9794   - 5.5053\n",
      "\u001b[1;4mValidati 33     - 100    -          0.4944 -           0.9040    | 0.9131   - 0.4717\u001b[0m\n",
      "Training 34     - 100    -          0.0704 -           0.9774    | 0.9794   - 5.3932\n",
      "\u001b[1;4mValidati 34     - 100    -          0.5394 -           0.9010    | 0.9085   - 0.4175\u001b[0m\n",
      "Training 35     - 100    -          0.0652 -           0.9791    | 0.9809   - 5.3091\n",
      "\u001b[1;4mValidati 35     - 100    -          0.5053 -           0.9047    | 0.9126   - 0.4465\u001b[0m\n",
      "Training 36     - 100    -          0.0626 -           0.9804    | 0.9820   - 5.3507\n",
      "\u001b[1;4mValidati 36     - 100    -          0.5099 -           0.9052    | 0.9127   - 0.4201\u001b[0m\n",
      "Training 37     - 100    -          0.0620 -           0.9803    | 0.9818   - 5.4044\n",
      "\u001b[1;4mValidati 37     - 100    -          0.5103 -           0.9059    | 0.9136   - 0.4133\u001b[0m\n",
      "Training 38     - 100    -          0.0593 -           0.9808    | 0.9823   - 5.3903\n",
      "\u001b[1;4mValidati 38     - 100    -          0.5317 -           0.9034    | 0.9110   - 0.4653\u001b[0m\n",
      "Training 39     - 100    -          0.0580 -           0.9821    | 0.9835   - 5.2975\n",
      "\u001b[1;4mValidati 39     - 100    -          0.5486 -           0.9050    | 0.9125   - 0.4142\u001b[0m\n",
      "Training 40     - 100    -          0.0553 -           0.9820    | 0.9832   - 5.2925\n",
      "\u001b[1;4mValidati 40     - 100    -          0.5341 -           0.9053    | 0.9130   - 0.4116\u001b[0m\n",
      "Training 41     - 100    -          0.0542 -           0.9829    | 0.9842   - 5.2854\n",
      "\u001b[1;4mValidati 41     - 100    -          0.5724 -           0.9026    | 0.9099   - 0.4119\u001b[0m\n",
      "Training 42     - 100    -          0.0563 -           0.9822    | 0.9835   - 5.2807\n",
      "\u001b[1;4mValidati 42     - 100    -          0.5618 -           0.9031    | 0.9101   - 0.4139\u001b[0m\n",
      "Training 43     - 100    -          0.0547 -           0.9828    | 0.9841   - 5.3444\n",
      "\u001b[1;4mValidati 43     - 100    -          0.5576 -           0.9035    | 0.9105   - 0.4196\u001b[0m\n",
      "Training 44     - 100    -          0.0525 -           0.9834    | 0.9844   - 5.4132\n",
      "\u001b[1;4mValidati 44     - 100    -          0.5781 -           0.9041    | 0.9106   - 0.4175\u001b[0m\n",
      "Training 45     - 100    -          0.0509 -           0.9842    | 0.9855   - 5.3863\n",
      "\u001b[1;4mValidati 45     - 100    -          0.5737 -           0.9044    | 0.9110   - 0.4556\u001b[0m\n",
      "Training 46     - 100    -          0.0481 -           0.9847    | 0.9859   - 5.3239\n",
      "\u001b[1;4mValidati 46     - 100    -          0.5576 -           0.9060    | 0.9129   - 0.4302\u001b[0m\n",
      "Training 47     - 100    -          0.0485 -           0.9844    | 0.9856   - 5.2972\n",
      "\u001b[1;4mValidati 47     - 100    -          0.5415 -           0.9081    | 0.9152   - 0.4125\u001b[0m\n",
      "Training 48     - 100    -          0.0446 -           0.9861    | 0.9871   - 5.2907\n",
      "\u001b[1;4mValidati 48     - 100    -          0.5745 -           0.9075    | 0.9139   - 0.4131\u001b[0m\n",
      "Training 49     - 100    -          0.0439 -           0.9861    | 0.9870   - 5.2848\n",
      "\u001b[1;4mValidati 49     - 100    -          0.5942 -           0.9069    | 0.9132   - 0.4161\u001b[0m\n",
      "Training 50     - 100    -          0.0440 -           0.9857    | 0.9867   - 5.2856\n",
      "\u001b[1;4mValidati 50     - 100    -          0.5870 -           0.9049    | 0.9125   - 0.4099\u001b[0m\n",
      "Training 51     - 100    -          0.0457 -           0.9858    | 0.9868   - 5.2987\n",
      "\u001b[1;4mValidati 51     - 100    -          0.5862 -           0.9041    | 0.9105   - 0.4121\u001b[0m\n",
      "Training 52     - 100    -          0.0465 -           0.9857    | 0.9867   - 5.3105\n",
      "\u001b[1;4mValidati 52     - 100    -          0.6103 -           0.9045    | 0.9108   - 0.4215\u001b[0m\n",
      "Training 53     - 100    -          0.0425 -           0.9870    | 0.9877   - 5.3681\n",
      "\u001b[1;4mValidati 53     - 100    -          0.5834 -           0.9055    | 0.9115   - 0.4187\u001b[0m\n",
      "Training 54     - 100    -          0.0424 -           0.9869    | 0.9880   - 5.4126\n",
      "\u001b[1;4mValidati 54     - 100    -          0.6159 -           0.9025    | 0.9090   - 0.4554\u001b[0m\n",
      "Training 55     - 100    -          0.0384 -           0.9880    | 0.9888   - 5.4534\n",
      "\u001b[1;4mValidati 55     - 100    -          0.6214 -           0.9063    | 0.9121   - 0.4361\u001b[0m\n",
      "Training 56     - 100    -          0.0400 -           0.9876    | 0.9882   - 5.3044\n",
      "\u001b[1;4mValidati 56     - 100    -          0.6360 -           0.9062    | 0.9121   - 0.4144\u001b[0m\n",
      "Training 57     - 100    -          0.0382 -           0.9880    | 0.9889   - 5.4605\n",
      "\u001b[1;4mValidati 57     - 100    -          0.6409 -           0.9069    | 0.9124   - 0.4207\u001b[0m\n",
      "Training 58     - 100    -          0.0429 -           0.9867    | 0.9874   - 5.1466\n",
      "\u001b[1;4mValidati 58     - 100    -          0.6613 -           0.9040    | 0.9101   - 0.4128\u001b[0m\n",
      "Training 59     - 100    -          0.0379 -           0.9885    | 0.9893   - 5.0265\n",
      "\u001b[1;4mValidati 59     - 100    -          0.6738 -           0.9047    | 0.9095   - 0.4503\u001b[0m\n",
      "Training 60     - 100    -          0.0340 -           0.9891    | 0.9899   - 5.0115\n",
      "\u001b[1;4mValidati 60     - 100    -          0.6712 -           0.9038    | 0.9095   - 0.4341\u001b[0m\n",
      "Training 61     - 100    -          0.0384 -           0.9878    | 0.9886   - 4.9740\n",
      "\u001b[1;4mValidati 61     - 100    -          0.6318 -           0.9044    | 0.9099   - 0.4164\u001b[0m\n",
      "Training 62     - 100    -          0.0347 -           0.9892    | 0.9898   - 4.9725\n",
      "\u001b[1;4mValidati 62     - 100    -          0.6365 -           0.9067    | 0.9124   - 0.4202\u001b[0m\n",
      "Training 63     - 100    -          0.0346 -           0.9890    | 0.9899   - 4.9831\n",
      "\u001b[1;4mValidati 63     - 100    -          0.6572 -           0.9063    | 0.9108   - 0.4223\u001b[0m\n",
      "Training 64     - 100    -          0.0330 -           0.9893    | 0.9901   - 5.6760\n",
      "\u001b[1;4mValidati 64     - 100    -          0.6789 -           0.9052    | 0.9102   - 0.4749\u001b[0m\n",
      "Training 65     - 100    -          0.0338 -           0.9895    | 0.9900   - 5.9047\n",
      "\u001b[1;4mValidati 65     - 100    -          0.6537 -           0.9051    | 0.9106   - 0.4762\u001b[0m\n",
      "Training 66     - 100    -          0.0294 -           0.9904    | 0.9909   - 5.8235\n",
      "\u001b[1;4mValidati 66     - 100    -          0.6710 -           0.9069    | 0.9126   - 0.4346\u001b[0m\n",
      "Training 67     - 100    -          0.0302 -           0.9903    | 0.9908   - 5.5240\n",
      "\u001b[1;4mValidati 67     - 100    -          0.6995 -           0.9063    | 0.9117   - 0.4734\u001b[0m\n",
      "Training 68     - 100    -          0.0356 -           0.9888    | 0.9894   - 5.3528\n",
      "\u001b[1;4mValidati 68     - 100    -          0.6542 -           0.9067    | 0.9120   - 0.4215\u001b[0m\n",
      "Training 69     - 100    -          0.0283 -           0.9911    | 0.9916   - 5.5065\n",
      "\u001b[1;4mValidati 69     - 100    -          0.6860 -           0.9052    | 0.9104   - 0.4701\u001b[0m\n",
      "Training 70     - 100    -          0.0253 -           0.9920    | 0.9926   - 5.4540\n",
      "\u001b[1;4mValidati 70     - 100    -          0.7053 -           0.9066    | 0.9111   - 0.4158\u001b[0m\n",
      "Training 71     - 100    -          0.0269 -           0.9916    | 0.9921   - 5.3380\n",
      "\u001b[1;4mValidati 71     - 100    -          0.7151 -           0.9052    | 0.9100   - 0.4144\u001b[0m\n",
      "Training 72     - 100    -          0.0284 -           0.9912    | 0.9917   - 5.4786\n",
      "\u001b[1;4mValidati 72     - 100    -          0.7291 -           0.9047    | 0.9098   - 0.4528\u001b[0m\n",
      "Training 73     - 100    -          0.0297 -           0.9905    | 0.9910   - 5.3817\n",
      "\u001b[1;4mValidati 73     - 100    -          0.7719 -           0.9033    | 0.9075   - 0.4305\u001b[0m\n",
      "Training 74     - 100    -          0.0285 -           0.9912    | 0.9915   - 5.2951\n",
      "\u001b[1;4mValidati 74     - 100    -          0.7194 -           0.9046    | 0.9100   - 0.4158\u001b[0m\n",
      "Training 75     - 100    -          0.0223 -           0.9931    | 0.9935   - 5.3290\n",
      "\u001b[1;4mValidati 75     - 100    -          0.7320 -           0.9060    | 0.9106   - 0.4235\u001b[0m\n",
      "Training 76     - 100    -          0.0231 -           0.9927    | 0.9931   - 5.4701\n",
      "\u001b[1;4mValidati 76     - 100    -          0.7712 -           0.9042    | 0.9090   - 0.4568\u001b[0m\n",
      "Training 77     - 100    -          0.0245 -           0.9921    | 0.9925   - 5.3840\n",
      "\u001b[1;4mValidati 77     - 100    -          0.7719 -           0.9024    | 0.9069   - 0.4323\u001b[0m\n",
      "Training 78     - 100    -          0.0252 -           0.9918    | 0.9921   - 5.2749\n",
      "\u001b[1;4mValidati 78     - 100    -          0.7234 -           0.9049    | 0.9100   - 0.4150\u001b[0m\n",
      "Training 79     - 100    -          0.0255 -           0.9923    | 0.9927   - 5.2457\n",
      "\u001b[1;4mValidati 79     - 100    -          0.7251 -           0.9051    | 0.9096   - 0.4131\u001b[0m\n",
      "Training 80     - 100    -          0.0248 -           0.9919    | 0.9924   - 5.2467\n",
      "\u001b[1;4mValidati 80     - 100    -          0.7167 -           0.9061    | 0.9110   - 0.4131\u001b[0m\n",
      "Training 81     - 100    -          0.0189 -           0.9941    | 0.9944   - 5.3024\n",
      "\u001b[1;4mValidati 81     - 100    -          0.7418 -           0.9069    | 0.9115   - 0.4181\u001b[0m\n",
      "Training 82     - 100    -          0.0230 -           0.9931    | 0.9931   - 5.3067\n",
      "\u001b[1;4mValidati 82     - 100    -          0.7628 -           0.9068    | 0.9116   - 0.4141\u001b[0m\n",
      "Training 83     - 100    -          0.0249 -           0.9921    | 0.9925   - 5.3094\n",
      "\u001b[1;4mValidati 83     - 100    -          0.7358 -           0.9077    | 0.9125   - 0.4132\u001b[0m\n",
      "Training 84     - 100    -          0.0196 -           0.9938    | 0.9941   - 5.2904\n",
      "\u001b[1;4mValidati 84     - 100    -          0.7982 -           0.9062    | 0.9103   - 0.4482\u001b[0m\n",
      "Training 85     - 100    -          0.0201 -           0.9936    | 0.9940   - 5.2792\n",
      "\u001b[1;4mValidati 85     - 100    -          0.7531 -           0.9068    | 0.9110   - 0.4289\u001b[0m\n",
      "Training 86     - 100    -          0.0203 -           0.9936    | 0.9940   - 5.2397\n",
      "\u001b[1;4mValidati 86     - 100    -          0.7729 -           0.9074    | 0.9123   - 0.4152\u001b[0m\n",
      "Training 87     - 100    -          0.0188 -           0.9941    | 0.9944   - 5.2386\n",
      "\u001b[1;4mValidati 87     - 100    -          0.7881 -           0.9051    | 0.9097   - 0.4150\u001b[0m\n",
      "Training 88     - 100    -          0.0198 -           0.9939    | 0.9942   - 5.2352\n",
      "\u001b[1;4mValidati 88     - 100    -          0.7615 -           0.9078    | 0.9117   - 0.4150\u001b[0m\n",
      "Training 89     - 100    -          0.0185 -           0.9942    | 0.9943   - 5.2426\n",
      "\u001b[1;4mValidati 89     - 100    -          0.7877 -           0.9064    | 0.9105   - 0.4111\u001b[0m\n",
      "Training 90     - 100    -          0.0178 -           0.9944    | 0.9947   - 5.2499\n",
      "\u001b[1;4mValidati 90     - 100    -          0.7743 -           0.9060    | 0.9099   - 0.4246\u001b[0m\n",
      "Training 91     - 100    -          0.0205 -           0.9936    | 0.9940   - 5.3563\n",
      "\u001b[1;4mValidati 91     - 100    -          0.7639 -           0.9066    | 0.9112   - 0.4218\u001b[0m\n",
      "Training 92     - 100    -          0.0182 -           0.9943    | 0.9945   - 5.3390\n",
      "\u001b[1;4mValidati 92     - 100    -          0.7863 -           0.9077    | 0.9116   - 0.4214\u001b[0m\n",
      "Training 93     - 100    -          0.0160 -           0.9950    | 0.9952   - 5.3509\n",
      "\u001b[1;4mValidati 93     - 100    -          0.7811 -           0.9070    | 0.9106   - 0.4173\u001b[0m\n",
      "Training 94     - 100    -          0.0158 -           0.9948    | 0.9951   - 5.3446\n",
      "\u001b[1;4mValidati 94     - 100    -          0.7898 -           0.9067    | 0.9108   - 0.4674\u001b[0m\n",
      "Training 95     - 100    -          0.0167 -           0.9945    | 0.9946   - 5.2857\n",
      "\u001b[1;4mValidati 95     - 100    -          0.8183 -           0.9084    | 0.9116   - 0.4153\u001b[0m\n",
      "Training 96     - 100    -          0.0173 -           0.9947    | 0.9948   - 5.2865\n",
      "\u001b[1;4mValidati 96     - 100    -          0.7762 -           0.9062    | 0.9104   - 0.4130\u001b[0m\n",
      "Training 97     - 100    -          0.0155 -           0.9950    | 0.9953   - 5.2381\n",
      "\u001b[1;4mValidati 97     - 100    -          0.7981 -           0.9077    | 0.9117   - 0.4104\u001b[0m\n",
      "Training 98     - 100    -          0.0166 -           0.9952    | 0.9952   - 5.2627\n",
      "\u001b[1;4mValidati 98     - 100    -          0.8004 -           0.9087    | 0.9120   - 0.4216\u001b[0m\n",
      "Training 99     - 100    -          0.0150 -           0.9952    | 0.9954   - 5.2822\n",
      "\u001b[1;4mValidati 99     - 100    -          0.8178 -           0.9064    | 0.9111   - 0.4212\u001b[0m\n",
      "Training 100    - 100    -          0.0155 -           0.9952    | 0.9954   - 5.3194\n",
      "\u001b[1;4mValidati 100    - 100    -          0.8045 -           0.9105    | 0.9140   - 0.4202\u001b[0m\n",
      "Training 101    - 100    -          0.0127 -           0.9960    | 0.9961   - 5.3406\n",
      "\u001b[1;4mValidati 101    - 100    -          0.8236 -           0.9086    | 0.9124   - 0.4547\u001b[0m\n",
      "Training 102    - 100    -          0.0133 -           0.9959    | 0.9961   - 5.3806\n",
      "\u001b[1;4mValidati 102    - 100    -          0.8011 -           0.9092    | 0.9132   - 0.4430\u001b[0m\n",
      "Training 103    - 100    -          0.0123 -           0.9961    | 0.9962   - 5.7742\n",
      "\u001b[1;4mValidati 103    - 100    -          0.8097 -           0.9077    | 0.9113   - 0.4118\u001b[0m\n",
      "Training 104    - 100    -          0.0110 -           0.9968    | 0.9968   - 5.7039\n",
      "\u001b[1;4mValidati 104    - 100    -          0.8303 -           0.9090    | 0.9125   - 0.4682\u001b[0m\n",
      "Training 105    - 100    -          0.0125 -           0.9959    | 0.9961   - 5.7226\n",
      "\u001b[1;4mValidati 105    - 100    -          0.8677 -           0.9065    | 0.9103   - 0.4209\u001b[0m\n",
      "Training 106    - 100    -          0.0120 -           0.9959    | 0.9962   - 5.7857\n",
      "\u001b[1;4mValidati 106    - 100    -          0.8541 -           0.9074    | 0.9111   - 0.4767\u001b[0m\n",
      "Training 107    - 100    -          0.0136 -           0.9959    | 0.9960   - 5.7110\n",
      "\u001b[1;4mValidati 107    - 100    -          0.8361 -           0.9090    | 0.9122   - 0.4267\u001b[0m\n",
      "Training 108    - 100    -          0.0122 -           0.9964    | 0.9965   - 5.9128\n",
      "\u001b[1;4mValidati 108    - 100    -          0.8749 -           0.9079    | 0.9109   - 0.5277\u001b[0m\n",
      "Training 109    - 100    -          0.0107 -           0.9966    | 0.9967   - 5.7799\n",
      "\u001b[1;4mValidati 109    - 100    -          0.8726 -           0.9076    | 0.9113   - 0.4549\u001b[0m\n",
      "Training 110    - 100    -          0.0106 -           0.9968    | 0.9970   - 5.6128\n",
      "\u001b[1;4mValidati 110    - 100    -          0.8764 -           0.9074    | 0.9104   - 0.4484\u001b[0m\n",
      "Training 111    - 100    -          0.0107 -           0.9967    | 0.9968   - 5.7664\n",
      "\u001b[1;4mValidati 111    - 100    -          0.8579 -           0.9096    | 0.9128   - 0.4993\u001b[0m\n",
      "Training 112    - 100    -          0.0088 -           0.9972    | 0.9973   - 5.7494\n",
      "\u001b[1;4mValidati 112    - 100    -          0.8869 -           0.9092    | 0.9124   - 0.4480\u001b[0m\n",
      "Training 113    - 100    -          0.0100 -           0.9970    | 0.9971   - 5.5761\n",
      "\u001b[1;4mValidati 113    - 100    -          0.8804 -           0.9108    | 0.9131   - 0.4467\u001b[0m\n",
      "Training 114    - 100    -          0.0096 -           0.9972    | 0.9973   - 5.6757\n",
      "\u001b[1;4mValidati 114    - 100    -          0.8908 -           0.9087    | 0.9120   - 0.4444\u001b[0m\n",
      "Training 115    - 100    -          0.0096 -           0.9969    | 0.9970   - 5.6155\n",
      "\u001b[1;4mValidati 115    - 100    -          0.8916 -           0.9062    | 0.9096   - 0.4353\u001b[0m\n",
      "Training 116    - 100    -          0.0100 -           0.9970    | 0.9969   - 5.6088\n",
      "\u001b[1;4mValidati 116    - 100    -          0.9190 -           0.9070    | 0.9101   - 0.4798\u001b[0m\n",
      "Training 117    - 100    -          0.0103 -           0.9968    | 0.9968   - 5.6709\n",
      "\u001b[1;4mValidati 117    - 100    -          0.9185 -           0.9076    | 0.9103   - 0.4608\u001b[0m\n",
      "Training 118    - 100    -          0.0110 -           0.9963    | 0.9964   - 5.5861\n",
      "\u001b[1;4mValidati 118    - 100    -          0.8974 -           0.9078    | 0.9107   - 0.4369\u001b[0m\n",
      "Training 119    - 100    -          0.0084 -           0.9973    | 0.9973   - 5.5448\n",
      "\u001b[1;4mValidati 119    - 100    -          0.8763 -           0.9085    | 0.9114   - 0.4391\u001b[0m\n",
      "Training 120    - 100    -          0.0089 -           0.9975    | 0.9975   - 5.9453\n",
      "\u001b[1;4mValidati 120    - 100    -          0.8699 -           0.9105    | 0.9136   - 0.4393\u001b[0m\n",
      "Training 121    - 100    -          0.0071 -           0.9978    | 0.9978   - 5.6306\n",
      "\u001b[1;4mValidati 121    - 100    -          0.9069 -           0.9096    | 0.9128   - 0.5022\u001b[0m\n",
      "Training 122    - 100    -          0.0076 -           0.9977    | 0.9977   - 5.6018\n",
      "\u001b[1;4mValidati 122    - 100    -          0.8831 -           0.9087    | 0.9121   - 0.4518\u001b[0m\n",
      "Training 123    - 100    -          0.0078 -           0.9976    | 0.9977   - 5.9392\n",
      "\u001b[1;4mValidati 123    - 100    -          0.8888 -           0.9086    | 0.9116   - 0.4449\u001b[0m\n",
      "Training 124    - 100    -          0.0065 -           0.9980    | 0.9981   - 5.6078\n",
      "\u001b[1;4mValidati 124    - 100    -          0.9066 -           0.9099    | 0.9133   - 0.4399\u001b[0m\n",
      "Training 125    - 100    -          0.0056 -           0.9982    | 0.9983   - 5.3637\n",
      "\u001b[1;4mValidati 125    - 100    -          0.9266 -           0.9100    | 0.9126   - 0.4460\u001b[0m\n",
      "Training 126    - 100    -          0.0054 -           0.9983    | 0.9984   - 5.1292\n",
      "\u001b[1;4mValidati 126    - 100    -          0.9526 -           0.9084    | 0.9111   - 0.4208\u001b[0m\n",
      "Training 127    - 100    -          0.0063 -           0.9980    | 0.9981   - 5.1048\n",
      "\u001b[1;4mValidati 127    - 100    -          0.9442 -           0.9087    | 0.9113   - 0.4244\u001b[0m\n",
      "Training 128    - 100    -          0.0048 -           0.9986    | 0.9987   - 5.0830\n",
      "\u001b[1;4mValidati 128    - 100    -          0.9745 -           0.9069    | 0.9097   - 0.4209\u001b[0m\n",
      "Training 129    - 100    -          0.0057 -           0.9982    | 0.9983   - 5.1211\n",
      "\u001b[1;4mValidati 129    - 100    -          0.9652 -           0.9087    | 0.9115   - 0.4600\u001b[0m\n",
      "Training 130    - 100    -          0.0067 -           0.9979    | 0.9980   - 5.2058\n",
      "\u001b[1;4mValidati 130    - 100    -          0.9864 -           0.9074    | 0.9102   - 0.4420\u001b[0m\n",
      "Training 131    - 100    -          0.0062 -           0.9980    | 0.9981   - 5.0498\n",
      "\u001b[1;4mValidati 131    - 100    -          0.9678 -           0.9076    | 0.9102   - 0.4233\u001b[0m\n",
      "Training 132    - 100    -          0.0060 -           0.9981    | 0.9981   - 5.0598\n",
      "\u001b[1;4mValidati 132    - 100    -          0.9567 -           0.9094    | 0.9118   - 0.4265\u001b[0m\n",
      "Training 133    - 100    -          0.0054 -           0.9984    | 0.9984   - 5.0533\n",
      "\u001b[1;4mValidati 133    - 100    -          0.9453 -           0.9075    | 0.9108   - 0.4209\u001b[0m\n",
      "Training 134    - 100    -          0.0050 -           0.9985    | 0.9985   - 5.0868\n",
      "\u001b[1;4mValidati 134    - 100    -          0.9304 -           0.9093    | 0.9121   - 0.4314\u001b[0m\n",
      "Training 135    - 100    -          0.0041 -           0.9988    | 0.9987   - 5.1106\n",
      "\u001b[1;4mValidati 135    - 100    -          0.9504 -           0.9110    | 0.9138   - 0.4320\u001b[0m\n",
      "Training 136    - 100    -          0.0048 -           0.9986    | 0.9986   - 5.1779\n",
      "\u001b[1;4mValidati 136    - 100    -          0.9693 -           0.9091    | 0.9117   - 0.4294\u001b[0m\n",
      "Training 137    - 100    -          0.0049 -           0.9984    | 0.9984   - 5.1947\n",
      "\u001b[1;4mValidati 137    - 100    -          0.9420 -           0.9086    | 0.9114   - 0.4828\u001b[0m\n",
      "Training 138    - 100    -          0.0049 -           0.9986    | 0.9986   - 5.6248\n",
      "\u001b[1;4mValidati 138    - 100    -          0.9818 -           0.9092    | 0.9119   - 0.4870\u001b[0m\n",
      "Training 139    - 100    -          0.0042 -           0.9988    | 0.9988   - 5.9658\n",
      "\u001b[1;4mValidati 139    - 100    -          0.9714 -           0.9093    | 0.9120   - 0.5024\u001b[0m\n",
      "Training 140    - 100    -          0.0043 -           0.9988    | 0.9987   - 5.9312\n",
      "\u001b[1;4mValidati 140    - 100    -          0.9705 -           0.9117    | 0.9139   - 0.4418\u001b[0m\n",
      "Training 141    - 100    -          0.0040 -           0.9989    | 0.9988   - 5.6781\n",
      "\u001b[1;4mValidati 141    - 100    -          0.9832 -           0.9086    | 0.9112   - 0.5122\u001b[0m\n",
      "Training 142    - 100    -          0.0040 -           0.9988    | 0.9988   - 5.5801\n",
      "\u001b[1;4mValidati 142    - 100    -          0.9868 -           0.9092    | 0.9115   - 0.4449\u001b[0m\n",
      "Training 143    - 100    -          0.0042 -           0.9987    | 0.9987   - 5.6329\n",
      "\u001b[1;4mValidati 143    - 100    -          1.0016 -           0.9096    | 0.9117   - 0.4793\u001b[0m\n",
      "Training 144    - 100    -          0.0042 -           0.9987    | 0.9987   - 5.5787\n",
      "\u001b[1;4mValidati 144    - 100    -          0.9971 -           0.9084    | 0.9110   - 0.4514\u001b[0m\n",
      "Training 145    - 100    -          0.0040 -           0.9989    | 0.9988   - 6.5330\n",
      "\u001b[1;4mValidati 145    - 100    -          1.0115 -           0.9089    | 0.9112   - 0.5579\u001b[0m\n",
      "Training 146    - 100    -          0.0034 -           0.9990    | 0.9990   - 6.4545\n",
      "\u001b[1;4mValidati 146    - 100    -          0.9972 -           0.9090    | 0.9117   - 0.5527\u001b[0m\n",
      "Training 147    - 100    -          0.0032 -           0.9991    | 0.9991   - 5.7676\n",
      "\u001b[1;4mValidati 147    - 100    -          1.0058 -           0.9086    | 0.9111   - 0.4346\u001b[0m\n",
      "Training 148    - 100    -          0.0038 -           0.9988    | 0.9988   - 5.9100\n",
      "\u001b[1;4mValidati 148    - 100    -          0.9895 -           0.9103    | 0.9130   - 0.4914\u001b[0m\n",
      "Training 149    - 100    -          0.0029 -           0.9991    | 0.9991   - 5.6907\n",
      "\u001b[1;4mValidati 149    - 100    -          1.0105 -           0.9113    | 0.9133   - 0.4394\u001b[0m\n",
      "Training 150    - 100    -          0.0032 -           0.9990    | 0.9991   - 5.6961\n",
      "\u001b[1;4mValidati 150    - 100    -          1.0162 -           0.9101    | 0.9123   - 0.4324\u001b[0m\n",
      "Training 151    - 100    -          0.0029 -           0.9991    | 0.9992   - 5.6566\n",
      "\u001b[1;4mValidati 151    - 100    -          1.0093 -           0.9103    | 0.9123   - 0.4897\u001b[0m\n",
      "Training 152    - 100    -          0.0027 -           0.9992    | 0.9992   - 5.4686\n",
      "\u001b[1;4mValidati 152    - 100    -          1.0115 -           0.9105    | 0.9126   - 0.4368\u001b[0m\n",
      "Training 153    - 100    -          0.0024 -           0.9994    | 0.9994   - 5.4094\n",
      "\u001b[1;4mValidati 153    - 100    -          1.0375 -           0.9086    | 0.9110   - 0.4317\u001b[0m\n",
      "Training 154    - 100    -          0.0028 -           0.9993    | 0.9992   - 5.5786\n",
      "\u001b[1;4mValidati 154    - 100    -          1.0186 -           0.9095    | 0.9117   - 0.4429\u001b[0m\n",
      "Training 155    - 100    -          0.0028 -           0.9993    | 0.9992   - 5.5880\n",
      "\u001b[1;4mValidati 155    - 100    -          1.0242 -           0.9109    | 0.9126   - 0.4860\u001b[0m\n",
      "Training 156    - 100    -          0.0028 -           0.9992    | 0.9993   - 5.3544\n",
      "\u001b[1;4mValidati 156    - 100    -          1.0124 -           0.9081    | 0.9105   - 0.4347\u001b[0m\n",
      "Training 157    - 100    -          0.0020 -           0.9995    | 0.9995   - 5.6766\n",
      "\u001b[1;4mValidati 157    - 100    -          1.0145 -           0.9109    | 0.9129   - 0.4400\u001b[0m\n",
      "Training 158    - 100    -          0.0024 -           0.9992    | 0.9992   - 5.5134\n",
      "\u001b[1;4mValidati 158    - 100    -          1.0147 -           0.9106    | 0.9126   - 0.4405\u001b[0m\n",
      "Training 159    - 100    -          0.0022 -           0.9995    | 0.9994   - 5.5559\n",
      "\u001b[1;4mValidati 159    - 100    -          1.0105 -           0.9103    | 0.9128   - 0.4658\u001b[0m\n",
      "Training 160    - 100    -          0.0021 -           0.9994    | 0.9994   - 5.8163\n",
      "\u001b[1;4mValidati 160    - 100    -          1.0329 -           0.9102    | 0.9123   - 0.4858\u001b[0m\n",
      "Training 161    - 100    -          0.0022 -           0.9994    | 0.9994   - 5.8448\n",
      "\u001b[1;4mValidati 161    - 100    -          1.0432 -           0.9094    | 0.9117   - 0.4648\u001b[0m\n",
      "Training 162    - 100    -          0.0022 -           0.9994    | 0.9994   - 5.5283\n",
      "\u001b[1;4mValidati 162    - 100    -          1.0328 -           0.9104    | 0.9133   - 0.4336\u001b[0m\n",
      "Training 163    - 100    -          0.0023 -           0.9994    | 0.9994   - 5.4289\n",
      "\u001b[1;4mValidati 163    - 100    -          1.0422 -           0.9091    | 0.9110   - 0.4324\u001b[0m\n",
      "Training 164    - 100    -          0.0028 -           0.9991    | 0.9992   - 5.5027\n",
      "\u001b[1;4mValidati 164    - 100    -          1.0588 -           0.9097    | 0.9119   - 0.4303\u001b[0m\n",
      "Training 165    - 100    -          0.0026 -           0.9993    | 0.9993   - 5.5431\n",
      "\u001b[1;4mValidati 165    - 100    -          1.0450 -           0.9109    | 0.9129   - 0.4753\u001b[0m\n",
      "Training 166    - 100    -          0.0017 -           0.9996    | 0.9996   - 5.7952\n",
      "\u001b[1;4mValidati 166    - 100    -          1.0378 -           0.9114    | 0.9133   - 0.4862\u001b[0m\n",
      "Training 167    - 100    -          0.0017 -           0.9996    | 0.9996   - 5.8422\n",
      "\u001b[1;4mValidati 167    - 100    -          1.0403 -           0.9106    | 0.9126   - 0.4894\u001b[0m\n",
      "Training 168    - 100    -          0.0016 -           0.9996    | 0.9996   - 5.8187\n",
      "\u001b[1;4mValidati 168    - 100    -          1.0421 -           0.9104    | 0.9126   - 0.5372\u001b[0m\n",
      "Training 169    - 100    -          0.0017 -           0.9996    | 0.9996   - 5.8578\n",
      "\u001b[1;4mValidati 169    - 100    -          1.0416 -           0.9111    | 0.9132   - 0.4615\u001b[0m\n",
      "Training 170    - 100    -          0.0020 -           0.9995    | 0.9995   - 5.8227\n",
      "\u001b[1;4mValidati 170    - 100    -          1.0419 -           0.9113    | 0.9134   - 0.4857\u001b[0m\n",
      "Training 171    - 100    -          0.0018 -           0.9995    | 0.9995   - 6.0875\n",
      "\u001b[1;4mValidati 171    - 100    -          1.0448 -           0.9111    | 0.9133   - 0.5352\u001b[0m\n",
      "Training 172    - 100    -          0.0014 -           0.9997    | 0.9997   - 6.3375\n",
      "\u001b[1;4mValidati 172    - 100    -          1.0674 -           0.9105    | 0.9125   - 0.5348\u001b[0m\n",
      "Training 173    - 100    -          0.0016 -           0.9996    | 0.9996   - 5.4679\n",
      "\u001b[1;4mValidati 173    - 100    -          1.0546 -           0.9110    | 0.9130   - 0.4571\u001b[0m\n",
      "Training 174    - 100    -          0.0017 -           0.9994    | 0.9995   - 5.5647\n",
      "\u001b[1;4mValidati 174    - 100    -          1.0532 -           0.9112    | 0.9132   - 0.4532\u001b[0m\n",
      "Training 175    - 100    -          0.0017 -           0.9996    | 0.9995   - 5.5674\n",
      "\u001b[1;4mValidati 175    - 100    -          1.0399 -           0.9120    | 0.9140   - 0.4817\u001b[0m\n",
      "Training 176    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.4538\n",
      "\u001b[1;4mValidati 176    - 100    -          1.0449 -           0.9105    | 0.9128   - 0.4443\u001b[0m\n",
      "Training 177    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.5420\n",
      "\u001b[1;4mValidati 177    - 100    -          1.0500 -           0.9105    | 0.9125   - 0.4775\u001b[0m\n",
      "Training 178    - 100    -          0.0015 -           0.9996    | 0.9995   - 5.3861\n",
      "\u001b[1;4mValidati 178    - 100    -          1.0521 -           0.9109    | 0.9126   - 0.4320\u001b[0m\n",
      "Training 179    - 100    -          0.0016 -           0.9996    | 0.9996   - 5.5429\n",
      "\u001b[1;4mValidati 179    - 100    -          1.0674 -           0.9110    | 0.9132   - 0.4796\u001b[0m\n",
      "Training 180    - 100    -          0.0017 -           0.9995    | 0.9995   - 5.3782\n",
      "\u001b[1;4mValidati 180    - 100    -          1.0559 -           0.9107    | 0.9126   - 0.4186\u001b[0m\n",
      "Training 181    - 100    -          0.0016 -           0.9995    | 0.9995   - 5.3190\n",
      "\u001b[1;4mValidati 181    - 100    -          1.0723 -           0.9108    | 0.9128   - 0.4245\u001b[0m\n",
      "Training 182    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.3464\n",
      "\u001b[1;4mValidati 182    - 100    -          1.0839 -           0.9087    | 0.9106   - 0.4314\u001b[0m\n",
      "Training 183    - 100    -          0.0016 -           0.9997    | 0.9996   - 5.4971\n",
      "\u001b[1;4mValidati 183    - 100    -          1.0614 -           0.9112    | 0.9132   - 0.4636\u001b[0m\n",
      "Training 184    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.3675\n",
      "\u001b[1;4mValidati 184    - 100    -          1.0849 -           0.9097    | 0.9117   - 0.4386\u001b[0m\n",
      "Training 185    - 100    -          0.0014 -           0.9996    | 0.9997   - 5.3490\n",
      "\u001b[1;4mValidati 185    - 100    -          1.0650 -           0.9103    | 0.9129   - 0.4225\u001b[0m\n",
      "Training 186    - 100    -          0.0012 -           0.9997    | 0.9997   - 5.5654\n",
      "\u001b[1;4mValidati 186    - 100    -          1.0591 -           0.9110    | 0.9129   - 0.5019\u001b[0m\n",
      "Training 187    - 100    -          0.0016 -           0.9995    | 0.9995   - 5.4738\n",
      "\u001b[1;4mValidati 187    - 100    -          1.0649 -           0.9102    | 0.9122   - 0.4349\u001b[0m\n",
      "Training 188    - 100    -          0.0014 -           0.9997    | 0.9997   - 5.3742\n",
      "\u001b[1;4mValidati 188    - 100    -          1.0628 -           0.9099    | 0.9120   - 0.4316\u001b[0m\n",
      "Training 189    - 100    -          0.0011 -           0.9998    | 0.9997   - 5.5600\n",
      "\u001b[1;4mValidati 189    - 100    -          1.0631 -           0.9108    | 0.9128   - 0.4427\u001b[0m\n",
      "Training 190    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.5387\n",
      "\u001b[1;4mValidati 190    - 100    -          1.0563 -           0.9117    | 0.9137   - 0.4358\u001b[0m\n",
      "Training 191    - 100    -          0.0015 -           0.9996    | 0.9996   - 5.5414\n",
      "\u001b[1;4mValidati 191    - 100    -          1.0802 -           0.9109    | 0.9126   - 0.4948\u001b[0m\n",
      "Training 192    - 100    -          0.0013 -           0.9997    | 0.9997   - 5.4992\n",
      "\u001b[1;4mValidati 192    - 100    -          1.0823 -           0.9106    | 0.9126   - 0.4458\u001b[0m\n",
      "Training 193    - 100    -          0.0013 -           0.9996    | 0.9997   - 5.4723\n",
      "\u001b[1;4mValidati 193    - 100    -          1.0582 -           0.9117    | 0.9135   - 0.4406\u001b[0m\n",
      "Training 194    - 100    -          0.0012 -           0.9997    | 0.9997   - 6.2613\n",
      "\u001b[1;4mValidati 194    - 100    -          1.0591 -           0.9114    | 0.9135   - 0.4962\u001b[0m\n",
      "Training 195    - 100    -          0.0013 -           0.9997    | 0.9997   - 5.4657\n",
      "\u001b[1;4mValidati 195    - 100    -          1.0577 -           0.9120    | 0.9136   - 0.4327\u001b[0m\n",
      "Training 196    - 100    -          0.0011 -           0.9997    | 0.9997   - 5.3844\n",
      "\u001b[1;4mValidati 196    - 100    -          1.0766 -           0.9105    | 0.9123   - 0.4303\u001b[0m\n",
      "Training 197    - 100    -          0.0012 -           0.9996    | 0.9997   - 5.4000\n",
      "\u001b[1;4mValidati 197    - 100    -          1.0608 -           0.9116    | 0.9137   - 0.4309\u001b[0m\n",
      "Training 198    - 100    -          0.0012 -           0.9997    | 0.9997   - 5.4694\n",
      "\u001b[1;4mValidati 198    - 100    -          1.0762 -           0.9114    | 0.9132   - 0.4332\u001b[0m\n",
      "Training 199    - 100    -          0.0014 -           0.9996    | 0.9995   - 5.4727\n",
      "\u001b[1;4mValidati 199    - 100    -          1.0890 -           0.9107    | 0.9125   - 0.4314\u001b[0m\n",
      "Training 200    - 100    -          0.0014 -           0.9996    | 0.9996   - 5.4135\n",
      "\u001b[1;4mValidati 200    - 100    -          1.0613 -           0.9115    | 0.9136   - 0.4718\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "print(header)\n",
    "\n",
    "start_epoch = checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    train(e)\n",
    "    val(e)\n",
    "    \n",
    "    tensorboard.flush()\n",
    "tensorboard.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .llll||=||llll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dct",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}