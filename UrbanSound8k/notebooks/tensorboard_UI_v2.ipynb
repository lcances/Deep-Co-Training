{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lcances/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pprint\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, VBox, Button\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lcances/.miniconda3/envs/tensorboard/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "tag_list = []\n",
    "log_list = []\n",
    "file_stats = dict()\n",
    "stat_list = [\"mean\", \"std\", \"maxi\", \"mini\"]\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "tensorboard_root = \"UrbanSound8k/tensorboard\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_tag(path):\n",
    "    global tag_list\n",
    "    tag_list = []\n",
    "\n",
    "    for e in tf.compat.v1.train.summary_iterator(path):\n",
    "        for value in e.summary.value:\n",
    "            if value.HasField(\"simple_value\"):\n",
    "                if value.tag not in tag_list:\n",
    "                    tag_list.append(value.tag)\n",
    "    \n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Si la list n'est pas vide\n",
    "    - Si le premier element est un fichier: return True\n",
    "    - Si le premier element est un dossier:\n",
    "        - lister le contenue de ce dossier L\n",
    "        - si L n'est pas vide\n",
    "            - Si le premier element est un fichier: return True\n",
    "            - Sinon return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_log(path):\n",
    "    if path:\n",
    "        if os.path.isfile(path[0]):\n",
    "            return True\n",
    "        \n",
    "        if os.path.isdir(path[0]):\n",
    "            if not os.listdir(path[0]): # directory is empty\n",
    "                return False\n",
    "            \n",
    "            sublist = [os.path.join(path[0], p) for p in os.listdir(path[0])]\n",
    "            \n",
    "            if sublist:\n",
    "                if os.path.isfile(sublist[0]):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_list(log_file):\n",
    "    list_file = os.listdir(log_file)\n",
    "    \n",
    "    print(log_file)\n",
    "    print(list_file)\n",
    "    path = os.path.join(log_file, list_file[0])\n",
    "    tag_list = get_all_tag(path)\n",
    "    print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ui_dropdown_dir(directory):\n",
    "    global log_list\n",
    "    \n",
    "    sub_directories = sorted([os.path.join(directory, p) for p in os.listdir(directory) ])\n",
    "        \n",
    "    if not contain_log(sub_directories):\n",
    "        interact(ui_dropdown_dir, directory=sub_directories)\n",
    "        \n",
    "    else:\n",
    "        path_list = [os.path.join(directory, l) for l in os.listdir(directory)]\n",
    "        log_list = path_list\n",
    "        interact_manual(get_tag_list, log_file=path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_stat(stat = \"maxi\"):\n",
    "    global file_stats\n",
    "    \n",
    "    values = [file_stats[l][stat] for l in file_stats.keys()]\n",
    "    \n",
    "    print(\"stat stat\")\n",
    "    print(\"mean: \", np.nanmean(values))\n",
    "    print(\"std : \", np.nanstd(values))\n",
    "    print(\"mini: \", np.nanmin(values))\n",
    "    print(\"maxi: \", np.nanmax(values))\n",
    "    print(\"\")\n",
    "    print(\"%.3f ± %.3f\" % (np.nanmean(values), np.nanstd(values)))\n",
    "    print(\"\")\n",
    "    print(\"detail \")\n",
    "    pprint.pprint(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UrbanSound8k/tensorboard/deep-co-training_aug4adv',\n",
       " 'UrbanSound8k/tensorboard/compound_scaling',\n",
       " 'UrbanSound8k/tensorboard/full_supervised_test',\n",
       " 'UrbanSound8k/tensorboard/deep-co-training',\n",
       " 'UrbanSound8k/tensorboard/deep-co-training_noAdv',\n",
       " 'UrbanSound8k/tensorboard/deep-co-training_independant-loss',\n",
       " 'UrbanSound8k/tensorboard/full_supervised',\n",
       " 'UrbanSound8k/tensorboard/script_tensorboard.Sh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(tensorboard_root + \"/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_dropdown_dir(directory, filters: str = \"\"):\n",
    "    global log_list\n",
    "    \n",
    "    sub_directories = sorted([os.path.join(directory, p) for p in os.listdir(directory) ])\n",
    "        \n",
    "    if not contain_log(sub_directories):\n",
    "        print(\"next\")\n",
    "        ui = interact(ui_dropdown_dir, directory=sub_directories, filters=\"\")\n",
    "        \n",
    "    else:\n",
    "        valid_list, path_list = [], []\n",
    "        \n",
    "        # prepare filters\n",
    "        if filters == \"\":\n",
    "            filters = [\"\"]\n",
    "            need_filters = [\"\"]\n",
    "            avoid_filters = []\n",
    "        else:\n",
    "            filters = filters.split(\",\")\n",
    "            need_filters = [f for f in filters if f[0] != \"~\"]\n",
    "            avoid_filters = [f[1:] for f in filters if f[0] == \"~\"]\n",
    "        if not need_filters:\n",
    "            need_filters = [\"\"]\n",
    "            \n",
    "        print(\"need filters: \", need_filters)\n",
    "        print(\"avoid filters: \", avoid_filters)\n",
    "        # need filters\n",
    "        for l in os.listdir(directory):\n",
    "            valid = 0\n",
    "            for f in need_filters:\n",
    "                if f in l:\n",
    "                    valid += 1\n",
    "                    \n",
    "            if valid == len(need_filters):\n",
    "                valid_list.append(l)\n",
    "                    \n",
    "        # avoid filters\n",
    "        for l in valid_list:\n",
    "            valid = True\n",
    "            \n",
    "            for f in avoid_filters:\n",
    "                if f in l:\n",
    "                    valid = False\n",
    "                    break\n",
    "                    \n",
    "            if valid:\n",
    "                path_list.append(os.path.join(directory, l))\n",
    "            \n",
    "        print(\"valid list: \", valid_list[:2])\n",
    "        print(\"path list: \", path_list[:2])\n",
    "        # path_list = [os.path.join(directory, l) for l in os.listdir(directory) if filters in l]\n",
    "        log_list = path_list\n",
    "        interact_manual(get_tag_list, log_file=path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_stat(stat = \"maxi\"):\n",
    "    global file_stats\n",
    "    \n",
    "    values = [file_stats[l][stat] for l in file_stats.keys()]\n",
    "    \n",
    "    print(\"stat stat\")\n",
    "    print(\"mean: \", np.nanmean(values))\n",
    "    print(\"std : \", np.nanstd(values))\n",
    "    print(\"mini: \", np.nanmin(values))\n",
    "    print(\"maxi: \", np.nanmax(values))\n",
    "    print(\"\")\n",
    "    print(\"%.3f ± %.3f\" % (np.nanmean(values) * 100, np.nanstd(values) * 100))\n",
    "    print(\"\")\n",
    "    print(\"detail \")\n",
    "    pprint.pprint(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_logs(stat = \"maxi\", format_fn = None):\n",
    "    global file_stats\n",
    "    \n",
    "    msg = \"\"\n",
    "    for k, d in file_stats.items():\n",
    "        formated_name = k\n",
    "        \n",
    "        if format_fn is not None:\n",
    "            formated_name = format_fn(k)\n",
    "            \n",
    "        msg += \"%s %.6f\\n\" % (formated_name, d[stat])\n",
    "    return msg.replace(\".\", \",\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(mean=True, std=True, max=False, min=False, tag=tag_list[0]):\n",
    "    global file_stats\n",
    "    \n",
    "    file_log = dict()\n",
    "    \n",
    "    # read all the log files ------------------------------\n",
    "    @functools.lru_cache()\n",
    "    def get_log_data(path):\n",
    "        logs = dict()\n",
    "\n",
    "        for e in tf.compat.v1.train.summary_iterator(path):\n",
    "            for value in e.summary.value:\n",
    "                if value.HasField(\"simple_value\"):\n",
    "                    if value.tag not in logs:\n",
    "                        logs[value.tag] = []\n",
    "                    logs[value.tag].append(value.simple_value)\n",
    "    \n",
    "        return logs\n",
    "    \n",
    "    for l in log_list:\n",
    "        final_path = os.path.join(l, os.listdir(l)[0])\n",
    "        logs = get_log_data(final_path)\n",
    "        \n",
    "        if logs:\n",
    "            file_log[l] = logs\n",
    "        \n",
    "    # compute the statistics ------------------------------\n",
    "    # ---- file wise ----\n",
    "    file_stats = dict()\n",
    "    \n",
    "    for l in file_log.keys():\n",
    "        file_stats[l] = dict(\n",
    "            mean = np.nanmean(file_log[l][tag]),\n",
    "            std = np.nanstd(file_log[l][tag]),\n",
    "            mini = np.nanmin(file_log[l][tag]),\n",
    "            maxi = np.nanmax(file_log[l][tag]),\n",
    "        )\n",
    "        \n",
    "    interact(stat_stat, stat=stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5c29f153804811939d708b898ce845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=('UrbanSound8k/tensorboard/deep-co-training_au…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ui_dropdown_dir(directory, filters:str='')>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(ui_dropdown_dir, directory=glob.glob(tensorboard_root + \"/**\"), filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cca8675d1b4d4abba01df3c2b8e2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='mean'), Checkbox(value=True, description='std'), Check…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.statistics(mean=True, std=True, max=False, min=False, tag='train/total_loss')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(statistics, mean=True, std=True, mini=False, maxi=False, tag=tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:28:49_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:35:24_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:22:01_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_09:55:32_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:15:15_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:08:27_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:22:11_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:11:47_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:41:59_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:51:56_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:38:42_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:08:43_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:28:41_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:45:19_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:58:31_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:05:27_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:32:10_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:45:30_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:05:11_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:01:54_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:48:43_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:12:06_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:18:42_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:15:22_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_16cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:48:33_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:38:58_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:18:39_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_16cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:25:29_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:42:16_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:55:09_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_10s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:51:57_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_16cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:35:31_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_12cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:02:08_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_3beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_11:25:23_cnn03_0.1S_1000e_0.0005lr_weighted-annealing-cosine-rfn_5s_8cycle_1beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_09:58:49_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_10s_8cycle_2beta_0.0m_plsup\n",
      "UrbanSound8k/tensorboard/deep-co-training_independant-loss/1lcm_1ldm/grid_search/2020-08-18_10:32:04_cnn03_0.1S_1000e_0.0005lr_annealing-cosine-rfn_5s_8cycle_3beta_0.0m_plsup\n",
      "\n",
      "cnn03 0,0005lr annealing-cosine 5 8 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 5 12 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 16 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 10 8 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 16 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 12 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 10 16 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 12 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 5 12 3 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 5 16 3 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 5 12 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 10 12 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 8 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 5 16 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 8 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 10 12 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 8 3 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 16 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 12 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 8 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 16 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 10 12 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 10 16 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 10 16 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 5 16 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 12 2 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 16 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 5 8 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 12 3 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 10 8 1 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 16 3 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 12 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 10 8 3 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr weighted-annealing-cosine 5 8 1 0,0 1000e 0,683754\n",
      "cnn03 0,0005lr annealing-cosine 10 8 2 0,0 1000e 0,659640\n",
      "cnn03 0,0005lr annealing-cosine 5 8 3 0,0 1000e 0,683754\n"
     ]
    }
   ],
   "source": [
    "def format_fn(n):\n",
    "    print(n)\n",
    "    base = n.split(\"/\")[5].split(\"_\")\n",
    "#     print(base)\n",
    "    \n",
    "    model_name = base[2]\n",
    "    ratio = base[3]\n",
    "    epoch = base[4]\n",
    "    lr = base[5]\n",
    "    rule = base[6][:-4]\n",
    "    nb_steps = base[7][:-1]\n",
    "    nb_cycle = base[8][:-5]\n",
    "    nb_beta = base[9][:-4]\n",
    "    plsup_mini = base[10][:-1]\n",
    "    \n",
    "    formated = \"%s %s %s %s %s %s %s %s\" % (model_name, lr, rule, nb_steps, nb_cycle, nb_beta, plsup_mini, epoch)\n",
    "    return formated\n",
    "\n",
    "detail = format_logs(\"maxi\", format_fn).split(\"\\n\")\n",
    "detail = sorted(detail, key=lambda x: x.split(\" \")[0])\n",
    "print(\"\\n\".join(detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_log(path):\n",
    "    if path:\n",
    "        \n",
    "        if os.path.isfile(path[0]):\n",
    "            return True\n",
    "        \n",
    "        if os.path.isdir(path[0]):\n",
    "            sublist = [os.path.join(path[0], p) for p in os.listdir(path[0])]\n",
    "            \n",
    "            if sublist:\n",
    "                if os.path.isfile(sublist[0]):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/e/sync/Documents_sync/Projet/UrbanSound8K/tensorboard/osirim_tensorboard\"\n",
    "list_dir = os.listdir(root)\n",
    "\n",
    "for name in list_dir:\n",
    "    path = os.path.join(root, name)\n",
    "    \n",
    "    print(contain_log(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e999da1df1f44846a8a52c3b408efdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='directory', options=(), value=None), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.ui_dropdown_dir(directory)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(ui_dropdown_dir, directory=glob.glob(tensorboard_root + \"/**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorboard",
   "language": "python",
   "name": "tensorboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
