{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ubs8k.datasetManager import DatasetManager\n",
    "from ubs8k.datasets import Dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from util.utils import reset_seed, get_datetime, get_model_from_name\n",
    "from util.checkpoint import CheckPoint\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../../datasets/ubs8k\", type=str)\n",
    "parser.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "parser.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4, 5, 6, 7, 8, 9], type=int)\n",
    "parser.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[10], type=int)\n",
    "\n",
    "parser.add_argument(\"--model\", default=\"cnn0\", type=str)\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int)\n",
    "parser.add_argument(\"--nb_epoch\", default=100, type=int)\n",
    "parser.add_argument(\"--learning_rate\", default=0.003, type=int)\n",
    "\n",
    "parser.add_argument(\"--checkpoint_path\", default=\"../../model_save/ubs8k/full_supervised\", type=str)\n",
    "parser.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--tensorboard_path\", default=\"../../tensorboard/ubs8k/full_supervised\", type=str)\n",
    "parser.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reset_seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dbfe6782af43d3a118e6dfe718e396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_root = os.path.join(args.dataset_root, \"audio\")\n",
    "metadata_root = os.path.join(args.dataset_root, \"metadata\")\n",
    "\n",
    "manager = DatasetManager(\n",
    "    metadata_root, audio_root,\n",
    "    folds=(1,2,3,4,5,6,7,8,9,10),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the sampler with the specified number of supervised file\n",
    "train_dataset = Dataset(manager, folds=(1, 2, 3, 4, 5, 6, 7, 8, 9), cached=True)\n",
    "val_dataset = Dataset(manager, folds=(10, ), cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_func = get_model_from_name(args.model)\n",
    "model = model_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "                               Kernel Shape      Output Shape   Params  \\\n",
      "Layer                                                                    \n",
      "0_features.0.Conv2d_0         [1, 24, 3, 3]  [1, 24, 64, 173]    240.0   \n",
      "1_features.0.MaxPool2d_1                  -   [1, 24, 16, 86]        -   \n",
      "2_features.0.BatchNorm2d_2             [24]   [1, 24, 16, 86]     48.0   \n",
      "3_features.0.ReLU6_3                      -   [1, 24, 16, 86]        -   \n",
      "4_features.1.Conv2d_0        [24, 48, 3, 3]   [1, 48, 16, 86]  10.416k   \n",
      "5_features.1.MaxPool2d_1                  -    [1, 48, 4, 43]        -   \n",
      "6_features.1.BatchNorm2d_2             [48]    [1, 48, 4, 43]     96.0   \n",
      "7_features.1.ReLU6_3                      -    [1, 48, 4, 43]        -   \n",
      "8_features.2.Conv2d_0        [48, 48, 3, 3]    [1, 48, 4, 43]  20.784k   \n",
      "9_features.2.MaxPool2d_1                  -    [1, 48, 1, 21]        -   \n",
      "10_features.2.BatchNorm2d_2            [48]    [1, 48, 1, 21]     96.0   \n",
      "11_features.2.ReLU6_3                     -    [1, 48, 1, 21]        -   \n",
      "12_features.3.Conv2d_0       [48, 48, 3, 3]    [1, 48, 1, 21]  20.784k   \n",
      "13_features.3.ReLU6_1                     -    [1, 48, 1, 21]        -   \n",
      "14_classifier.Flatten_0                   -         [1, 1008]        -   \n",
      "15_classifier.Dropout_1                   -         [1, 1008]        -   \n",
      "16_classifier.Linear_2           [1008, 10]           [1, 10]   10.09k   \n",
      "\n",
      "                              Mult-Adds  \n",
      "Layer                                    \n",
      "0_features.0.Conv2d_0         2.391552M  \n",
      "1_features.0.MaxPool2d_1              -  \n",
      "2_features.0.BatchNorm2d_2         24.0  \n",
      "3_features.0.ReLU6_3                  -  \n",
      "4_features.1.Conv2d_0        14.266368M  \n",
      "5_features.1.MaxPool2d_1              -  \n",
      "6_features.1.BatchNorm2d_2         48.0  \n",
      "7_features.1.ReLU6_3                  -  \n",
      "8_features.2.Conv2d_0         3.566592M  \n",
      "9_features.2.MaxPool2d_1              -  \n",
      "10_features.2.BatchNorm2d_2        48.0  \n",
      "11_features.2.ReLU6_3                 -  \n",
      "12_features.3.Conv2d_0         435.456k  \n",
      "13_features.3.ReLU6_1                 -  \n",
      "14_classifier.Flatten_0               -  \n",
      "15_classifier.Dropout_1               -  \n",
      "16_classifier.Linear_2           10.08k  \n",
      "----------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params             62.554k\n",
      "Trainable params         62.554k\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             20.670168M\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "input_tensor = torch.zeros((1, 64, 173), dtype=torch.float)\n",
    "\n",
    "s = summary(model, input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn0(\n",
       "  (features): Sequential(\n",
       "    (0): ConvPoolReLU(\n",
       "      (0): Conv2d(1, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): ConvPoolReLU(\n",
       "      (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (2): ConvPoolReLU(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(4, 2), stride=(4, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU6(inplace=True)\n",
       "    )\n",
       "    (3): ConvReLU(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=1008, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model_func()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s_idx, u_idx = train_dataset.split_s_u(args.supervised_ratio)\n",
    "S_sampler = torch.utils.data.SubsetRandomSampler(s_idx)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, sampler=S_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "title = \"%s_%s_%.1f\" % (get_datetime(), model_func.__name__, args.supervised_ratio)\n",
    "tensorboard = SummaryWriter(log_dir=\"%s/%s\" % (args.tensorboard_path, title), comment=model_func.__name__)\n",
    "\n",
    "# losses\n",
    "loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "# callbacks\n",
    "lr_lambda = lambda epoch: (1.0 + numpy.cos((epoch-1)*numpy.pi/args.nb_epoch))\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = CheckPoint(model, optimizer, mode=\"max\", name=\"%s_%s.torch\" % (args.checkpoint_path, title))\n",
    "\n",
    "# Metrics\n",
    "fscore_fn = FScore()\n",
    "acc_fn = CategoricalAccuracy()\n",
    "avg = ContinueAverage()\n",
    "\n",
    "reset_metrics = lambda : [m.reset() for m in [fscore_fn, acc_fn, avg]]\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can resume previous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n"
     ]
    }
   ],
   "source": [
    "UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "\n",
    "header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} - {:<9.9} {:<12.12}| {:<9.9}- {:<6.6}\"\n",
    "value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} - {:<9.9} {:<10.4f}| {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "header = header_form.format(\n",
    "    \"\", \"Epoch\", \"%\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1 \",\"Time\"\n",
    ")\n",
    "\n",
    "\n",
    "train_form = value_form\n",
    "val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    reset_metrics()\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(training_loader):\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_ce(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=10)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(training_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"train/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"train/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"train/acc\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "    reset_metrics()\n",
    "    model.eval()\n",
    "\n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_ce(logits, y)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=10)\n",
    "\n",
    "            acc = acc_fn(pred_arg, y).mean\n",
    "            fscore = fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = avg(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / len(val_loader)),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    tensorboard.add_scalar(\"val/Lce\", avg_ce, epoch)\n",
    "    tensorboard.add_scalar(\"val/f1\", fscore, epoch)\n",
    "    tensorboard.add_scalar(\"val/acc\", acc, epoch)\n",
    "    \n",
    "    tensorboard.add_scalar(\"hyperparameters/learning_rate\", get_lr(optimizer), epoch)\n",
    "\n",
    "    checkpoint.step(acc)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n",
      "\n",
      "Training 2      - 100    -          1.1508 -           0.6005    | 0.5559   - 3.1111\n",
      "\u001b[1;4mValidati 2      - 100    -          1.3436 -           0.5620    | 0.5206   - 0.1170\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 3      - 100    -          0.9514 -           0.6865    | 0.6666   - 2.9283\n",
      "\u001b[1;4mValidati 3      - 100    -          1.0552 -           0.6787    | 0.6693   - 0.1118\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 4      - 100    -          0.8031 -           0.7365    | 0.7289   - 3.1884\n",
      "\u001b[1;4mValidati 4      - 100    -          1.8476 -           0.4785    | 0.4863   - 0.1242\u001b[0m\n",
      "Training 5      - 100    -          0.7018 -           0.7730    | 0.7658   - 3.1048\n",
      "\u001b[1;4mValidati 5      - 100    -          1.4411 -           0.5468    | 0.5525   - 0.1102\u001b[0m\n",
      "Training 6      - 100    -          0.6408 -           0.7943    | 0.7900   - 3.0933\n",
      "\u001b[1;4mValidati 6      - 100    -          1.3577 -           0.6558    | 0.6712   - 0.1284\u001b[0m\n",
      "Training 7      - 100    -          0.5786 -           0.8111    | 0.8094   - 3.0406\n",
      "\u001b[1;4mValidati 7      - 100    -          1.1600 -           0.6588    | 0.6576   - 0.1228\u001b[0m\n",
      "Training 8      - 100    -          0.5310 -           0.8251    | 0.8256   - 3.0174\n",
      "\u001b[1;4mValidati 8      - 100    -          1.5716 -           0.6391    | 0.6353   - 0.1078\u001b[0m\n",
      "Training 9      - 100    -          0.5295 -           0.8323    | 0.8283   - 2.8743\n",
      "\u001b[1;4mValidati 9      - 100    -          1.1476 -           0.6819    | 0.6840   - 0.1056\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 10     - 100    -          0.4729 -           0.8475    | 0.8478   - 2.9276\n",
      "\u001b[1;4mValidati 10     - 100    -          1.1624 -           0.6812    | 0.6612   - 0.1168\u001b[0m\n",
      "Training 11     - 100    -          0.4394 -           0.8577    | 0.8584   - 2.9176\n",
      "\u001b[1;4mValidati 11     - 100    -          0.9134 -           0.7294    | 0.7319   - 0.1104\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 12     - 100    -          0.4157 -           0.8643    | 0.8661   - 3.0454\n",
      "\u001b[1;4mValidati 12     - 100    -          1.2642 -           0.6755    | 0.6872   - 0.1173\u001b[0m\n",
      "Training 13     - 100    -          0.4190 -           0.8652    | 0.8646   - 2.9733\n",
      "\u001b[1;4mValidati 13     - 100    -          1.3955 -           0.6812    | 0.7057   - 0.1089\u001b[0m\n",
      "Training 14     - 100    -          0.4063 -           0.8682    | 0.8702   - 3.0659\n",
      "\u001b[1;4mValidati 14     - 100    -          1.7549 -           0.6519    | 0.6726   - 0.1121\u001b[0m\n",
      "Training 15     - 100    -          0.3805 -           0.8794    | 0.8814   - 3.1110\n",
      "\u001b[1;4mValidati 15     - 100    -          1.2648 -           0.7236    | 0.7264   - 0.1158\u001b[0m\n",
      "Training 16     - 100    -          0.3826 -           0.8744    | 0.8760   - 2.9658\n",
      "\u001b[1;4mValidati 16     - 100    -          1.2917 -           0.6933    | 0.7070   - 0.1142\u001b[0m\n",
      "Training 17     - 100    -          0.3479 -           0.8898    | 0.8877   - 3.0553\n",
      "\u001b[1;4mValidati 17     - 100    -          1.1267 -           0.7558    | 0.7518   - 0.1491\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 18     - 100    -          0.3416 -           0.8898    | 0.8900   - 2.9935\n",
      "\u001b[1;4mValidati 18     - 100    -          1.3071 -           0.7229    | 0.7278   - 0.1203\u001b[0m\n",
      "Training 19     - 100    -          0.3224 -           0.8952    | 0.8958   - 2.9348\n",
      "\u001b[1;4mValidati 19     - 100    -          1.4705 -           0.6597    | 0.6447   - 0.1155\u001b[0m\n",
      "Training 20     - 100    -          0.3234 -           0.8957    | 0.8973   - 3.1060\n",
      "\u001b[1;4mValidati 20     - 100    -          1.1890 -           0.7368    | 0.7375   - 0.1088\u001b[0m\n",
      "Training 21     - 100    -          0.2984 -           0.9035    | 0.9044   - 2.9681\n",
      "\u001b[1;4mValidati 21     - 100    -          2.1678 -           0.5940    | 0.5915   - 0.1107\u001b[0m\n",
      "Training 22     - 100    -          0.2959 -           0.9062    | 0.9070   - 2.9564\n",
      "\u001b[1;4mValidati 22     - 100    -          1.5554 -           0.7141    | 0.7122   - 0.1164\u001b[0m\n",
      "Training 23     - 100    -          0.3263 -           0.9004    | 0.9011   - 3.0283\n",
      "\u001b[1;4mValidati 23     - 100    -          1.3071 -           0.7190    | 0.7087   - 0.1162\u001b[0m\n",
      "Training 24     - 100    -          0.2774 -           0.9115    | 0.9111   - 2.9451\n",
      "\u001b[1;4mValidati 24     - 100    -          2.0128 -           0.6650    | 0.6720   - 0.1054\u001b[0m\n",
      "Training 25     - 100    -          0.2801 -           0.9095    | 0.9110   - 3.0041\n",
      "\u001b[1;4mValidati 25     - 100    -          1.5101 -           0.7345    | 0.7420   - 0.1184\u001b[0m\n",
      "Training 26     - 100    -          0.2972 -           0.9059    | 0.9043   - 3.0887\n",
      "\u001b[1;4mValidati 26     - 100    -          1.2881 -           0.7542    | 0.7531   - 0.1090\u001b[0m\n",
      "Training 27     - 100    -          0.2261 -           0.9268    | 0.9278   - 2.9149\n",
      "\u001b[1;4mValidati 27     - 100    -          2.1354 -           0.7222    | 0.7247   - 0.1106\u001b[0m\n",
      "Training 28     - 100    -          0.2347 -           0.9220    | 0.9253   - 2.9730\n",
      "\u001b[1;4mValidati 28     - 100    -          2.8468 -           0.5843    | 0.5924   - 0.1077\u001b[0m\n",
      "Training 29     - 100    -          0.2512 -           0.9211    | 0.9203   - 2.9242\n",
      "\u001b[1;4mValidati 29     - 100    -          1.6764 -           0.7306    | 0.7375   - 0.1026\u001b[0m\n",
      "Training 30     - 100    -          0.2266 -           0.9256    | 0.9244   - 2.9543\n",
      "\u001b[1;4mValidati 30     - 100    -          1.4702 -           0.7299    | 0.7344   - 0.1076\u001b[0m\n",
      "Training 31     - 100    -          0.2378 -           0.9269    | 0.9268   - 2.8911\n",
      "\u001b[1;4mValidati 31     - 100    -          2.4832 -           0.6704    | 0.6732   - 0.1061\u001b[0m\n",
      "Training 32     - 100    -          0.2201 -           0.9284    | 0.9288   - 2.8562\n",
      "\u001b[1;4mValidati 32     - 100    -          1.9742 -           0.6847    | 0.6921   - 0.1051\u001b[0m\n",
      "Training 33     - 100    -          0.1973 -           0.9360    | 0.9364   - 3.1259\n",
      "\u001b[1;4mValidati 33     - 100    -          1.9888 -           0.6935    | 0.7124   - 0.1194\u001b[0m\n",
      "Training 34     - 100    -          0.2040 -           0.9343    | 0.9337   - 2.9248\n",
      "\u001b[1;4mValidati 34     - 100    -          1.6349 -           0.7201    | 0.7175   - 0.1069\u001b[0m\n",
      "Training 35     - 100    -          0.2133 -           0.9295    | 0.9307   - 2.9823\n",
      "\u001b[1;4mValidati 35     - 100    -          2.6139 -           0.6785    | 0.6859   - 0.1140\u001b[0m\n",
      "Training 36     - 100    -          0.1976 -           0.9389    | 0.9383   - 3.0645\n",
      "\u001b[1;4mValidati 36     - 100    -          1.9447 -           0.7280    | 0.7286   - 0.1345\u001b[0m\n",
      "Training 37     - 100    -          0.1777 -           0.9449    | 0.9450   - 2.9937\n",
      "\u001b[1;4mValidati 37     - 100    -          1.3891 -           0.7604    | 0.7673   - 0.1019\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 38     - 100    -          0.1759 -           0.9425    | 0.9440   - 3.0192\n",
      "\u001b[1;4mValidati 38     - 100    -          2.2021 -           0.7106    | 0.7226   - 0.1184\u001b[0m\n",
      "Training 39     - 100    -          0.1672 -           0.9453    | 0.9463   - 3.0498\n",
      "\u001b[1;4mValidati 39     - 100    -          2.0793 -           0.6970    | 0.7065   - 0.1205\u001b[0m\n",
      "Training 40     - 100    -          0.1800 -           0.9397    | 0.9407   - 3.1321\n",
      "\u001b[1;4mValidati 40     - 100    -          2.8634 -           0.6137    | 0.6083   - 0.1169\u001b[0m\n",
      "Training 41     - 100    -          0.1664 -           0.9473    | 0.9464   - 3.0399\n",
      "\u001b[1;4mValidati 41     - 100    -          1.5311 -           0.7512    | 0.7575   - 0.1161\u001b[0m\n",
      "Training 42     - 100    -          0.1591 -           0.9493    | 0.9488   - 2.9785\n",
      "\u001b[1;4mValidati 42     - 100    -          1.8223 -           0.7081    | 0.7082   - 0.1067\u001b[0m\n",
      "Training 43     - 100    -          0.1573 -           0.9506    | 0.9499   - 2.9368\n",
      "\u001b[1;4mValidati 43     - 100    -          1.5855 -           0.7410    | 0.7464   - 0.1100\u001b[0m\n",
      "Training 44     - 100    -          0.1356 -           0.9531    | 0.9543   - 3.1250\n",
      "\u001b[1;4mValidati 44     - 100    -          1.5689 -           0.7495    | 0.7552   - 0.1146\u001b[0m\n",
      "Training 45     - 100    -          0.1552 -           0.9507    | 0.9513   - 2.9679\n",
      "\u001b[1;4mValidati 45     - 100    -          1.7423 -           0.7322    | 0.7356   - 0.1060\u001b[0m\n",
      "Training 46     - 100    -          0.1472 -           0.9515    | 0.9521   - 2.9886\n",
      "\u001b[1;4mValidati 46     - 100    -          1.9745 -           0.7023    | 0.7075   - 0.1161\u001b[0m\n",
      "Training 47     - 100    -          0.1595 -           0.9489    | 0.9495   - 3.0367\n",
      "\u001b[1;4mValidati 47     - 100    -          1.6729 -           0.7394    | 0.7419   - 0.1078\u001b[0m\n",
      "Training 48     - 100    -          0.1137 -           0.9638    | 0.9634   - 2.9852\n",
      "\u001b[1;4mValidati 48     - 100    -          2.2871 -           0.7299    | 0.7351   - 0.1181\u001b[0m\n",
      "Training 49     - 100    -          0.1087 -           0.9634    | 0.9638   - 3.0659\n",
      "\u001b[1;4mValidati 49     - 100    -          2.1244 -           0.6972    | 0.6967   - 0.1094\u001b[0m\n",
      "Training 50     - 100    -          0.1251 -           0.9587    | 0.9591   - 3.0247\n",
      "\u001b[1;4mValidati 50     - 100    -          2.2079 -           0.7090    | 0.7124   - 0.1094\u001b[0m\n",
      "Training 51     - 100    -          0.1217 -           0.9587    | 0.9597   - 2.9028\n",
      "\u001b[1;4mValidati 51     - 100    -          1.7449 -           0.7380    | 0.7397   - 0.1146\u001b[0m\n",
      "Training 52     - 100    -          0.1152 -           0.9644    | 0.9635   - 3.0521\n",
      "\u001b[1;4mValidati 52     - 100    -          1.8099 -           0.7553    | 0.7604   - 0.1090\u001b[0m\n",
      "Training 53     - 100    -          0.1125 -           0.9643    | 0.9643   - 2.9896\n",
      "\u001b[1;4mValidati 53     - 100    -          1.8138 -           0.7410    | 0.7429   - 0.1126\u001b[0m\n",
      "Training 54     - 100    -          0.0992 -           0.9662    | 0.9671   - 3.0482\n",
      "\u001b[1;4mValidati 54     - 100    -          1.7148 -           0.7773    | 0.7774   - 0.1231\u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 55     - 100    -          0.1023 -           0.9663    | 0.9666   - 2.9464\n",
      "\u001b[1;4mValidati 55     - 100    -          2.6082 -           0.7090    | 0.7121   - 0.1199\u001b[0m\n",
      "Training 56     - 100    -          0.1035 -           0.9682    | 0.9676   - 2.9882\n",
      "\u001b[1;4mValidati 56     - 100    -          1.7432 -           0.7639    | 0.7638   - 0.1020\u001b[0m\n",
      "Training 57     - 100    -          0.1016 -           0.9674    | 0.9678   - 2.9789\n",
      "\u001b[1;4mValidati 57     - 100    -          1.8093 -           0.7380    | 0.7382   - 0.1130\u001b[0m\n",
      "Training 58     - 100    -          0.0891 -           0.9707    | 0.9714   - 2.9524\n",
      "\u001b[1;4mValidati 58     - 100    -          2.2005 -           0.7451    | 0.7446   - 0.1073\u001b[0m\n",
      "Training 59     - 100    -          0.0851 -           0.9724    | 0.9724   - 2.9531\n",
      "\u001b[1;4mValidati 59     - 100    -          1.9034 -           0.7639    | 0.7641   - 0.1172\u001b[0m\n",
      "Training 60     - 100    -          0.0877 -           0.9700    | 0.9698   - 2.9988\n",
      "\u001b[1;4mValidati 60     - 100    -          2.5129 -           0.7201    | 0.7262   - 0.1204\u001b[0m\n",
      "Training 61     - 100    -          0.0867 -           0.9712    | 0.9711   - 2.9281\n",
      "\u001b[1;4mValidati 61     - 100    -          2.0271 -           0.7326    | 0.7362   - 0.1087\u001b[0m\n",
      "Training 62     - 100    -          0.0864 -           0.9703    | 0.9710   - 3.1492\n",
      "\u001b[1;4mValidati 62     - 100    -          2.2383 -           0.7363    | 0.7403   - 0.1343\u001b[0m\n",
      "Training 63     - 100    -          0.0844 -           0.9721    | 0.9723   - 2.9669\n",
      "\u001b[1;4mValidati 63     - 100    -          1.9231 -           0.7442    | 0.7537   - 0.1140\u001b[0m\n",
      "Training 64     - 100    -          0.0715 -           0.9767    | 0.9773   - 2.9180\n",
      "\u001b[1;4mValidati 64     - 100    -          2.4474 -           0.7340    | 0.7396   - 0.1220\u001b[0m\n",
      "Training 65     - 100    -          0.0743 -           0.9748    | 0.9748   - 3.1278\n",
      "\u001b[1;4mValidati 65     - 100    -          2.1113 -           0.7604    | 0.7635   - 0.1114\u001b[0m\n",
      "Training 66     - 100    -          0.0668 -           0.9789    | 0.9792   - 2.8978\n",
      "\u001b[1;4mValidati 66     - 100    -          2.1585 -           0.7600    | 0.7596   - 0.1126\u001b[0m\n",
      "Training 67     - 100    -          0.0695 -           0.9762    | 0.9769   - 2.9464\n",
      "\u001b[1;4mValidati 67     - 100    -          2.2109 -           0.7495    | 0.7528   - 0.1045\u001b[0m\n",
      "Training 68     - 100    -          0.0630 -           0.9789    | 0.9790   - 2.9088\n",
      "\u001b[1;4mValidati 68     - 100    -          2.4027 -           0.7634    | 0.7647   - 0.1253\u001b[0m\n",
      "Training 69     - 100    -          0.0526 -           0.9835    | 0.9831   - 3.0902\n",
      "\u001b[1;4mValidati 69     - 100    -          2.3386 -           0.7657    | 0.7645   - 0.1162\u001b[0m\n",
      "Training 70     - 100    -          0.0591 -           0.9810    | 0.9808   - 3.0018\n",
      "\u001b[1;4mValidati 70     - 100    -          2.4536 -           0.7611    | 0.7632   - 0.1114\u001b[0m\n",
      "Training 71     - 10     -          0.0239 -           0.9931    | 0.9931   - 0.2784\r"
     ]
    }
   ],
   "source": [
    "print(header)\n",
    "\n",
    "start_epoch = checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    train(e)\n",
    "    val(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dct",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
